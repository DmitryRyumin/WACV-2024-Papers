# WACV-2024-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/computational_photography_image_and_video_synthesis.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/explainable_fair_accountable-privacy-preserving.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Datasets and Evaluations

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [IKEA Ego 3D Dataset: Understanding Furniture Assembly Actions from Ego-View 3D Point Clouds](https://openaccess.thecvf.com/content/WACV2024/html/Ben-Shabat_IKEA_Ego_3D_Dataset_Understanding_Furniture_Assembly_Actions_From_Ego-View_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sitzikbs.github.io/IKEAEgo3D.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Ben-Shabat_IKEA_Ego_3D_Dataset_Understanding_Furniture_Assembly_Actions_From_Ego-View_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8e3WeMv6vJY) |
| [IndustReal: A Dataset for Procedure Step Recognition Handling Execution Errors in Egocentric Videos in an Industrial-Like Setting](https://openaccess.thecvf.com/content/WACV2024/html/Schoonbeek_IndustReal_A_Dataset_for_Procedure_Step_Recognition_Handling_Execution_Errors_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://timschoonbeek.github.io/industreal.html) <br /> [![GitHub](https://img.shields.io/github/stars/TimSchoonbeek/IndustReal?style=flat)](https://github.com/TimSchoonbeek/IndustReal) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Schoonbeek_IndustReal_A_Dataset_for_Procedure_Step_Recognition_Handling_Execution_Errors_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.17323-b31b1b.svg)](http://arxiv.org/abs/2310.17323) | :heavy_minus_sign: |
| [Ego2HandsPose: A Dataset for Egocentric Two-Hand 3D Global Pose Estimation](https://openaccess.thecvf.com/content/WACV2024/html/Lin_Ego2HandsPose_A_Dataset_for_Egocentric_Two-Hand_3D_Global_Pose_Estimation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lin_Ego2HandsPose_A_Dataset_for_Egocentric_Two-Hand_3D_Global_Pose_Estimation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.04927-b31b1b.svg)](http://arxiv.org/abs/2206.04927) | :heavy_minus_sign: |
| [ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation and Re-Identification](https://openaccess.thecvf.com/content/WACV2024/html/Gorlo_ISAR_A_Benchmark_for_Single-_and_Few-Shot_Object_Instance_Segmentation_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://nicogorlo.github.io/isar_wacv24/) <br /> [![GitHub](https://img.shields.io/github/stars/nicogorlo/isar?style=flat)](https://github.com/nicogorlo/isar) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gorlo_ISAR_A_Benchmark_for_Single-_and_Few-Shot_Object_Instance_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.02734-b31b1b.svg)](http://arxiv.org/abs/2311.02734) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vMuwoziD3qc) |
| [Towards Addressing the Misalignment of Object Proposal Evaluation for Vision-Language Tasks via Semantic Grounding](https://openaccess.thecvf.com/content/WACV2024/html/Feinglass_Towards_Addressing_the_Misalignment_of_Object_Proposal_Evaluation_for_Vision-Language_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/JoshuaFeinglass/VL-detector-eval?style=flat)](https://github.com/JoshuaFeinglass/VL-detector-eval) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Feinglass_Towards_Addressing_the_Misalignment_of_Object_Proposal_Evaluation_for_Vision-Language_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.00215-b31b1b.svg)](http://arxiv.org/abs/2309.00215) | :heavy_minus_sign: |
| [SphereCraft: A Dataset for Spherical Keypoint Detection, Matching and Camera Pose Estimation](https://openaccess.thecvf.com/content/WACV2024/html/Gava_SphereCraft_A_Dataset_for_Spherical_Keypoint_Detection_Matching_and_Camera_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dfki.github.io/spherecraftweb/) <br /> [![GitHub](https://img.shields.io/github/stars/DFKI/spherecrafthub?style=flat)](https://github.com/DFKI/spherecrafthub) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gava_SphereCraft_A_Dataset_for_Spherical_Keypoint_Detection_Matching_and_Camera_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Benchmark Generation Framework with Customizable Distortions for Image Classifier Robustness](Sarkar_Benchmark_Generation_Framework_With_Customizable_Distortions_for_Image_Classifier_Robustness_WACV_2024_paper) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sarkar_Benchmark_Generation_Framework_With_Customizable_Distortions_for_Image_Classifier_Robustness_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.18626-b31b1b.svg)](http://arxiv.org/abs/2310.18626) | :heavy_minus_sign: |
| [UOW-Vessel: A Benchmark Dataset of High-Resolution Optical Satellite Images for Vessel Detection and Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Bui_UOW-Vessel_A_Benchmark_Dataset_of_High-Resolution_Optical_Satellite_Images_for_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/yangdi-cv/UOW-Vessel?style=flat)](https://github.com/yangdi-cv/UOW-Vessel) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bui_UOW-Vessel_A_Benchmark_Dataset_of_High-Resolution_Optical_Satellite_Images_for_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [NITEC: Versatile Hand-Annotated Eye Contact Dataset for Ego-Vision Interaction](https://openaccess.thecvf.com/content/WACV2024/html/Hempel_NITEC_Versatile_Hand-Annotated_Eye_Contact_Dataset_for_Ego-Vision_Interaction_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/thohemp/nitec?style=flat)](https://github.com/thohemp/nitec) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hempel_NITEC_Versatile_Hand-Annotated_Eye_Contact_Dataset_for_Ego-Vision_Interaction_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.04505-b31b1b.svg)](http://arxiv.org/abs/2311.04505) | :heavy_minus_sign: |
| [Time to Shine: Fine-Tuning Object Detection Models with Synthetic Adverse Weather Images](https://openaccess.thecvf.com/content/WACV2024/html/Rothmeier_Time_To_Shine_Fine-Tuning_Object_Detection_Models_With_Synthetic_Adverse_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Rothmeier_Time_To_Shine_Fine-Tuning_Object_Detection_Models_With_Synthetic_Adverse_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Effects of Markers in Training Datasets on the Accuracy of 6D Pose Estimation](https://openaccess.thecvf.com/content/WACV2024/html/Rosskamp_Effects_of_Markers_in_Training_Datasets_on_the_Accuracy_of_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/JHRosskamp/6DPoseDataGenTools?style=flat)](https://github.com/JHRosskamp/6DPoseDataGenTools) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Rosskamp_Effects_of_Markers_in_Training_Datasets_on_the_Accuracy_of_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [VEATIC: Video-based Emotion and Affect Tracking in Context Dataset](https://openaccess.thecvf.com/content/WACV2024/html/Ren_VEATIC_Video-Based_Emotion_and_Affect_Tracking_in_Context_Dataset_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://veatic.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/AlbusPeter/VEATIC?style=flat)](https://github.com/AlbusPeter/VEATIC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Ren_VEATIC_Video-Based_Emotion_and_Affect_Tracking_in_Context_Dataset_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.06745-b31b1b.svg)](http://arxiv.org/abs/2309.06745) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xHq9K5PT888) |
| Tackling Data Bias in MUSIC-AVQA: Crafting a Balanced Dataset for Unbiased Question-Answering |  |  |  |
| An Empirical Investigation Into Benchmarking Model Multiplicity for Trustworthy Machine Learning: A Case Study on Image Classification |  |  |  |
| Can You Even Tell Left from Right? Presenting a New Challenge for VQA |  |  |  |
| MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction and Novel View Synthesis |  |  |  |
| RobustCLEVR: A Benchmark and Framework for Evaluating Robustness in Object-Centric Learning |  |  |  |
| So You Think You Can Track? |  |  |  |
| Estimating Blood Alcohol Level through Facial Features for Driver Impairment Assessment |  |  |  |
| ENIGMA-51: Towards a Fine-Grained Understanding of Human Behavior in Industrial Scenarios |  |  |  |
| SciOL and MuLMS-Img: Introducing a Large-Scale Multimodal Scientific Dataset and Models for Image-Text Tasks in the Scientific Domain |  |  |  |
| HaGRID — HAnd Gesture Recognition Image Dataset |  |  |  |
| Identifying Label Errors in Object Detection Datasets by Loss Inspection |  |  |  |
| Exploring the Impact of Rendering Method and Motion Quality on Model Performance when using Multi-View Synthetic Data for Action Recognition |  |  |  |
| PsyMo: A Dataset for Estimating Self-Reported Psychological Traits from Gait |  |  |  |
| IDD-AW: A Benchmark for Safe and Robust Segmentation of Drive Scenes in Unstructured Traffic and Adverse Weather |  |  |  |
| CrashCar101: Procedural Generation for Damage Assessment |  |  |  |
| ZRG: A Dataset for Multimodal 3D Residential Rooftop Understanding |  |  |  |
