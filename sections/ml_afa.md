# WACV-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/low-level-and-physics-based-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/3d_cv.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Machine Learning: Architectures, Formulations, Algorithms

![Section Papers](https://img.shields.io/badge/Section%20Papers-117-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-73-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-61-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-109-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Efficient Transferability Assessment for Selection of Pre-Trained Detectors](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Efficient_Transferability_Assessment_for_Selection_of_Pre-Trained_Detectors_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Efficient_Transferability_Assessment_for_Selection_of_Pre-Trained_Detectors_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Qo4FZg-5LZA) |
| [Plasticity-Optimized Complementary Networks for Unsupervised Continual Learning](https://openaccess.thecvf.com/content/WACV2024/html/Gomez-Villa_Plasticity-Optimized_Complementary_Networks_for_Unsupervised_Continual_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/alviur/pocon_wacv2024?style=flat)](https://github.com/alviur/pocon_wacv2024) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gomez-Villa_Plasticity-Optimized_Complementary_Networks_for_Unsupervised_Continual_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.06086-b31b1b.svg)](http://arxiv.org/abs/2309.06086) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fgAD5bFrKXU) |
| [Continual Test-Time Domain Adaptation via Dynamic Sample Selection](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Continual_Test-Time_Domain_Adaptation_via_Dynamic_Sample_Selection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Continual_Test-Time_Domain_Adaptation_via_Dynamic_Sample_Selection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.03335-b31b1b.svg)](http://arxiv.org/abs/2310.03335) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RcPXINRk9hA) |
| [Source-Guided Similarity Preservation for Online Person Re-Identification](https://openaccess.thecvf.com/content/WACV2024/html/Rami_Source-Guided_Similarity_Preservation_for_Online_Person_Re-Identification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ramiMMhamza/S2P?style=flat)](https://github.com/ramiMMhamza/S2P) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Rami_Source-Guided_Similarity_Preservation_for_Online_Person_Re-Identification_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=qBq003ItWTM) |
| [CAILA: Concept-Aware Intra-Layer Adapters for Compositional Zero-Shot Learning](https://openaccess.thecvf.com/content/WACV2024/html/Zheng_CAILA_Concept-Aware_Intra-Layer_Adapters_for_Compositional_Zero-Shot_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/zhaohengz/CAILA?style=flat)](https://github.com/zhaohengz/CAILA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zheng_CAILA_Concept-Aware_Intra-Layer_Adapters_for_Compositional_Zero-Shot_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.16681-b31b1b.svg)](http://arxiv.org/abs/2305.16681) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=q57WhSt30G0) |
| [Mini but Mighty: Finetuning ViTs with Mini Adapters](https://openaccess.thecvf.com/content/WACV2024/html/Marouf_Mini_but_Mighty_Finetuning_ViTs_With_Mini_Adapters_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/IemProg/MiMi?style=flat)](https://github.com/IemProg/MiMi) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Marouf_Mini_but_Mighty_Finetuning_ViTs_With_Mini_Adapters_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03873-b31b1b.svg)](http://arxiv.org/abs/2311.03873) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LLBMI49Z-Zg) |
| [Recognition of Unseen Bird Species by Learning from Field Guides](https://openaccess.thecvf.com/content/WACV2024/html/Rodriguez_Recognition_of_Unseen_Bird_Species_by_Learning_From_Field_Guides_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ac-rodriguez/zsl_billow?style=flat)](https://github.com/ac-rodriguez/zsl_billow) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Rodriguez_Recognition_of_Unseen_Bird_Species_by_Learning_From_Field_Guides_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.01466-b31b1b.svg)](http://arxiv.org/abs/2206.01466) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0Yjnm19VejM) |
| [Single Domain Generalization via Normalised Cross-Correlation based Convolutions](https://openaccess.thecvf.com/content/WACV2024/html/Chuah_Single_Domain_Generalization_via_Normalised_Cross-Correlation_Based_Convolutions_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/waychin-weiqin/XCNorm?style=flat)](https://github.com/waychin-weiqin/XCNorm) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chuah_Single_Domain_Generalization_via_Normalised_Cross-Correlation_Based_Convolutions_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.05901-b31b1b.svg)](http://arxiv.org/abs/2307.05901) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=19arKkVfG-M) |
| [MoP-CLIP: A Mixture of Prompt-Tuned CLIP Models for Domain Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Nicolas_MoP-CLIP_A_Mixture_of_Prompt-Tuned_CLIP_Models_for_Domain_Incremental_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nicolas_MoP-CLIP_A_Mixture_of_Prompt-Tuned_CLIP_Models_for_Domain_Incremental_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.05707-b31b1b.svg)](http://arxiv.org/abs/2307.05707) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZM1ZWDXT80Q) |
| [Self-Supervised Representation Learning with Cross-Context Learning between Global and Hypercolumn Features](https://openaccess.thecvf.com/content/WACV2024/html/Gao_Self-Supervised_Representation_Learning_With_Cross-Context_Learning_Between_Global_and_Hypercolumn_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/zaczgao/CGH-Hypercolumn?style=flat)](https://github.com/zaczgao/CGH-Hypercolumn) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gao_Self-Supervised_Representation_Learning_With_Cross-Context_Learning_Between_Global_and_Hypercolumn_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13392-b31b1b.svg)](http://arxiv.org/abs/2308.13392) | :heavy_minus_sign: |
| [Revisiting Pixel-Level Contrastive Pre-Training on Scene Images](https://openaccess.thecvf.com/content/WACV2024/html/Pang_Revisiting_Pixel-Level_Contrastive_Pre-Training_on_Scene_Images_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/pangzss/PixCon?style=flat)](https://github.com/pangzss/PixCon) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Pang_Revisiting_Pixel-Level_Contrastive_Pre-Training_on_Scene_Images_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=tH2tW50S5Nw) |
| [Improving Graph Networks through Selection-based Convolution](https://openaccess.thecvf.com/content/WACV2024/html/Hart_Improving_Graph_Networks_Through_Selection-Based_Convolution_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/davidmhart/SelectionGCN?style=flat)](https://github.com/davidmhart/SelectionGCN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hart_Improving_Graph_Networks_Through_Selection-Based_Convolution_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=X4CpTgs0KSA) |
| [Exploiting CLIP for Zero-Shot HOI Detection Requires Knowledge Distillation at Multiple Levels](https://openaccess.thecvf.com/content/WACV2024/html/Wan_Exploiting_CLIP_for_Zero-Shot_HOI_Detection_Requires_Knowledge_Distillation_at_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/bobwan1995/Zeroshot-HOI-with-CLIP?style=flat)](https://github.com/bobwan1995/Zeroshot-HOI-with-CLIP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wan_Exploiting_CLIP_for_Zero-Shot_HOI_Detection_Requires_Knowledge_Distillation_at_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.05069-b31b1b.svg)](http://arxiv.org/abs/2309.05069) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pSWQLW_Q4Hg) |
| [Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization](https://openaccess.thecvf.com/content/WACV2024/html/Bele_Learning_Class_and_Domain_Augmentations_for_Single-Source_Open-Domain_Generalization_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bele_Learning_Class_and_Domain_Augmentations_for_Single-Source_Open-Domain_Generalization_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.02599-b31b1b.svg)](http://arxiv.org/abs/2311.02599) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ms9b5lfHbIc) |
| [Dynamic Token-Pass Transformers for Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Liu_Dynamic_Token-Pass_Transformers_for_Semantic_Segmentation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/FLHonker/DoViT-code?style=flat)](https://github.com/FLHonker/DoViT-code) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Dynamic_Token-Pass_Transformers_for_Semantic_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.01944-b31b1b.svg)](http://arxiv.org/abs/2308.01944) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pHkm14X5_aI) |
| [An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Petit_An_Analysis_of_Initial_Training_Strategies_for_Exemplar-Free_Class-Incremental_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Petit_An_Analysis_of_Initial_Training_Strategies_for_Exemplar-Free_Class-Incremental_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11677-b31b1b.svg)](http://arxiv.org/abs/2308.11677) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=b9EDDFS64xQ) |
| [Few-Shot Shape Recognition by Learning Deep Shape-Aware Features](https://openaccess.thecvf.com/content/WACV2024/html/Shi_Few-Shot_Shape_Recognition_by_Learning_Deep_Shape-Aware_Features_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shi_Few-Shot_Shape_Recognition_by_Learning_Deep_Shape-Aware_Features_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.01315-b31b1b.svg)](http://arxiv.org/abs/2312.01315) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wxsVYqxi7Tc) |
| [Active Learning for Single-Stage Object Detection in UAV Images](https://openaccess.thecvf.com/content/WACV2024/html/Yamani_Active_Learning_for_Single-Stage_Object_Detection_in_UAV_Images_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/asmayamani/DUA?style=flat)](https://github.com/asmayamani/DUA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yamani_Active_Learning_for_Single-Stage_Object_Detection_in_UAV_Images_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=EZ4hLR_UkLg) |
| [Learning Intra-Class Multimodal Distributions with Orthonormal Matrices](https://openaccess.thecvf.com/content/WACV2024/html/Goto_Learning_Intra-Class_Multimodal_Distributions_With_Orthonormal_Matrices_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Goto_Learning_Intra-Class_Multimodal_Distributions_With_Orthonormal_Matrices_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PqqQAb1I0yg) |
| [Active Transfer Learning for Efficient Video-Specific Human Pose Estimation](https://openaccess.thecvf.com/content/WACV2024/html/Taketsugu_Active_Transfer_Learning_for_Efficient_Video-Specific_Human_Pose_Estimation_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://iminthemiddle.github.io/VATL4Pose-Page/) <br /> [![GitHub](https://img.shields.io/github/stars/ImIntheMiddle/VATL4Pose-WACV2024?style=flat)](https://github.com/ImIntheMiddle/VATL4Pose-WACV2024) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Taketsugu_Active_Transfer_Learning_for_Efficient_Video-Specific_Human_Pose_Estimation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.05041-b31b1b.svg)](http://arxiv.org/abs/2311.05041) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Mm5LfGH6A1I) |
| [Understanding Hyperbolic Metric Learning through Hard Negative Sampling](https://openaccess.thecvf.com/content/WACV2024/html/Yue_Understanding_Hyperbolic_Metric_Learning_Through_Hard_Negative_Sampling_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/YunYunY/HypMix?style=flat)](https://github.com/YunYunY/HypMix) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yue_Understanding_Hyperbolic_Metric_Learning_Through_Hard_Negative_Sampling_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=o22cbCvALUc) |
| [Aligning Non-Causal Factors for Transformer-based Source-Free Domain Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Sanyal_Aligning_Non-Causal_Factors_for_Transformer-Based_Source-Free_Domain_Adaptation_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://val.cds.iisc.ac.in/C-SFTrans/) <br /> [![GitHub](https://img.shields.io/github/stars/val-iisc/C-SFTrans?style=flat)](https://github.com/val-iisc/C-SFTrans) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sanyal_Aligning_Non-Causal_Factors_for_Transformer-Based_Source-Free_Domain_Adaptation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.16294-b31b1b.svg)](http://arxiv.org/abs/2311.16294) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SzPMgCfPnQk) |
| [Diverse Imagenet Models Transfer Better](https://openaccess.thecvf.com/content/WACV2024/html/Nayman_Diverse_Imagenet_Models_Transfer_Better_WACV_2024_paper.html) | :heavy_minus_sign:  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nayman_Diverse_Imagenet_Models_Transfer_Better_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.09134-b31b1b.svg)](http://arxiv.org/abs/2204.09134) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GEOzWwjv_mo) |
| [Design Choices for Enhancing Noisy Student Self-Training](https://openaccess.thecvf.com/content/WACV2024/html/Radhakrishnan_Design_Choices_for_Enhancing_Noisy_Student_Self-Training_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Radhakrishnan_Design_Choices_for_Enhancing_Noisy_Student_Self-Training_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GjAdAiEhKnI) |
| [Bag of Tricks for Fully Test-Time Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Mounsaveng_Bag_of_Tricks_for_Fully_Test-Time_Adaptation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/smounsav/tta_bot?style=flat)](https://github.com/smounsav/tta_bot) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Mounsaveng_Bag_of_Tricks_for_Fully_Test-Time_Adaptation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.02416-b31b1b.svg)](http://arxiv.org/abs/2310.02416) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=970GFqBwSOI) |
| [Gradual Source Domain Expansion for Unsupervised Domain Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Westfechtel_Gradual_Source_Domain_Expansion_for_Unsupervised_Domain_Adaptation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ThomasWestfechtel/GSDE?style=flat)](https://github.com/ThomasWestfechtel/GSDE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Westfechtel_Gradual_Source_Domain_Expansion_for_Unsupervised_Domain_Adaptation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.09599-b31b1b.svg)](http://arxiv.org/abs/2311.09599) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XJsfzHVdMwY) |
| [OOD Aware Supervised Contrastive Learning](https://openaccess.thecvf.com/content/WACV2024/html/Seifi_OOD_Aware_Supervised_Contrastive_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Seifi_OOD_Aware_Supervised_Contrastive_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.01942-b31b1b.svg)](http://arxiv.org/abs/2310.01942) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vGs13aALiz8) |
| [Expanding Hyperspherical Space for Few-Shot Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Deng_Expanding_Hyperspherical_Space_for_Few-Shot_Class-Incremental_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Deng_Expanding_Hyperspherical_Space_for_Few-Shot_Class-Incremental_Learning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kWDS1Wf-WK0) |
| [Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-Free Continual Learning](https://openaccess.thecvf.com/content/WACV2024/html/Szatkowski_Adapt_Your_Teacher_Improving_Knowledge_Distillation_for_Exemplar-Free_Continual_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/fszatkowski/cl-teacher-adaptation?style=flat)](https://github.com/fszatkowski/cl-teacher-adaptation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Szatkowski_Adapt_Your_Teacher_Improving_Knowledge_Distillation_for_Exemplar-Free_Continual_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09544-b31b1b.svg)](http://arxiv.org/abs/2308.09544) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VAZb1ZNtiuY) |
| [Tunable Hybrid Proposal Networks for the Open World](https://openaccess.thecvf.com/content/WACV2024/html/Inkawhich_Tunable_Hybrid_Proposal_Networks_for_the_Open_World_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Inkawhich_Tunable_Hybrid_Proposal_Networks_for_the_Open_World_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Sg_O51fmemo) |
| [Domain Generalization with Correlated Style Uncertainty](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Domain_Generalization_With_Correlated_Style_Uncertainty_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/freshman97/CSU?style=flat)](https://github.com/freshman97/CSU) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_Domain_Generalization_With_Correlated_Style_Uncertainty_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.09950-b31b1b.svg)](http://arxiv.org/abs/2212.09950) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AC1u06WLbfM) |
| [Correlation-Aware Active Learning for Surgery Video Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Wu_Correlation-Aware_Active_Learning_for_Surgery_Video_Segmentation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wu_Correlation-Aware_Active_Learning_for_Surgery_Video_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.08811-b31b1b.svg)](http://arxiv.org/abs/2311.08811) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oudmmeouDwI) |
| [A Multimodal Benchmark and Improved Architecture for Zero Shot Learning](https://openaccess.thecvf.com/content/WACV2024/html/Doshi_A_Multimodal_Benchmark_and_Improved_Architecture_for_Zero_Shot_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Doshi_A_Multimodal_Benchmark_and_Improved_Architecture_for_Zero_Shot_Learning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LN3600FZPi4) |
| [TCP: Triplet Contrastive-Relationship Preserving for Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Li_TCP_Triplet_Contrastive-Relationship_Preserving_for_Class-Incremental_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Li_TCP_Triplet_Contrastive-Relationship_Preserving_for_Class-Incremental_Learning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ay59C_juJog) |
| [Improving Normalization with the James-Stein Estimator](https://openaccess.thecvf.com/content/WACV2024/html/Khoshsirat_Improving_Normalization_With_the_James-Stein_Estimator_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Khoshsirat_Improving_Normalization_With_the_James-Stein_Estimator_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.00313-b31b1b.svg)](http://arxiv.org/abs/2312.00313) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mI9dq1wxcfE) |
| [ReConPatch: Contrastive Patch Representation Learning for Industrial Anomaly Detection](https://openaccess.thecvf.com/content/WACV2024/html/Hyun_ReConPatch_Contrastive_Patch_Representation_Learning_for_Industrial_Anomaly_Detection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hyun_ReConPatch_Contrastive_Patch_Representation_Learning_for_Industrial_Anomaly_Detection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.16713-b31b1b.svg)](http://arxiv.org/abs/2305.16713) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=s_HAcsJIO3g) |
| [REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Seto_REALM_Robust_Entropy_Adaptive_Loss_Minimization_for_Improved_Single-Sample_Test-Time_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Seto_REALM_Robust_Entropy_Adaptive_Loss_Minimization_for_Improved_Single-Sample_Test-Time_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03964-b31b1b.svg)](http://arxiv.org/abs/2309.03964) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JF49PgLYP0s) |
| [On the Quantification of Image Reconstruction Uncertainty without Training Data](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_On_the_Quantification_of_Image_Reconstruction_Uncertainty_Without_Training_Data_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_On_the_Quantification_of_Image_Reconstruction_Uncertainty_Without_Training_Data_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.09639-b31b1b.svg)](http://arxiv.org/abs/2311.09639) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=wBi55qhG3To) |
| [Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin](https://openaccess.thecvf.com/content/WACV2024/html/Moreira_Hyperbolic_vs_Euclidean_Embeddings_in_Few-Shot_Learning_Two_Sides_of_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/gabmoreira/hyper?style=flat)](https://github.com/gabmoreira/hyper) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Moreira_Hyperbolic_vs_Euclidean_Embeddings_in_Few-Shot_Learning_Two_Sides_of_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.10013-b31b1b.svg)](http://arxiv.org/abs/2309.10013) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=A7Czn9wNsIs) |
| [Effective Restoration of Source Knowledge in Continual Test Time Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Niloy_Effective_Restoration_of_Source_Knowledge_in_Continual_Test_Time_Adaptation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Niloy_Effective_Restoration_of_Source_Knowledge_in_Continual_Test_Time_Adaptation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.04991-b31b1b.svg)](http://arxiv.org/abs/2311.04991) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gbaBaiG3Ofk) |
| [AMEND: Adaptive Margin and Expanded Neighborhood for Efficient Generalized Category Discovery](https://openaccess.thecvf.com/content/WACV2024/html/Banerjee_AMEND_Adaptive_Margin_and_Expanded_Neighborhood_for_Efficient_Generalized_Category_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Banerjee_AMEND_Adaptive_Margin_and_Expanded_Neighborhood_for_Efficient_Generalized_Category_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Q4COf1IjDqQ) |
| [Optical Flow Domain Adaptation via Target Style Transfer](https://openaccess.thecvf.com/content/WACV2024/html/Yoon_Optical_Flow_Domain_Adaptation_via_Target_Style_Transfer_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yoon_Optical_Flow_Domain_Adaptation_via_Target_Style_Transfer_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=b3siGLI2MV0) |
| [Out-of-Distribution Detection with Logical Reasoning](https://openaccess.thecvf.com/content/WACV2024/html/Kirchheim_Out-of-Distribution_Detection_With_Logical_Reasoning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/kkirchheim/logic-ood?style=flat)](https://github.com/kkirchheim/logic-ood) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kirchheim_Out-of-Distribution_Detection_With_Logical_Reasoning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_Twt6lpq6zQ) |
| [Evidential Uncertainty Quantification: A Variance-based Perspective](https://openaccess.thecvf.com/content/WACV2024/html/Duan_Evidential_Uncertainty_Quantification_A_Variance-Based_Perspective_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/KerryDRX/EvidentialADA?style=flat)](https://github.com/KerryDRX/EvidentialADA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Duan_Evidential_Uncertainty_Quantification_A_Variance-Based_Perspective_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.11367-b31b1b.svg)](http://arxiv.org/abs/2311.11367) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=420Q4xNX_IM) |
| [Self-Supervised Learning of Semantic Correspondence using Web Videos](https://openaccess.thecvf.com/content/WACV2024/html/Kwon_Self-Supervised_Learning_of_Semantic_Correspondence_Using_Web_Videos_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/kinux98/SSSCWEB?style=flat)](https://github.com/kinux98/SSSCWEB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kwon_Self-Supervised_Learning_of_Semantic_Correspondence_Using_Web_Videos_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cXR5zFXhV6c) |
| [Opinion Unaware Image Quality Assessment via Adversarial Convolutional Variational Autoencoder](https://openaccess.thecvf.com/content/WACV2024/html/Shukla_Opinion_Unaware_Image_Quality_Assessment_via_Adversarial_Convolutional_Variational_Autoencoder_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shukla_Opinion_Unaware_Image_Quality_Assessment_via_Adversarial_Convolutional_Variational_Autoencoder_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1LkIkMTHZ2A) |
| [Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth Simulation](https://openaccess.thecvf.com/content/WACV2024/html/Zavrtanik_Cheating_Depth_Enhancing_3D_Surface_Anomaly_Detection_via_Depth_Simulation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/VitjanZ/3DSR?style=flat)](https://github.com/VitjanZ/3DSR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zavrtanik_Cheating_Depth_Enhancing_3D_Surface_Anomaly_Detection_via_Depth_Simulation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.01117-b31b1b.svg)](http://arxiv.org/abs/2311.01117) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nJFRgiMRWmU) |
| [HELA-VFA: A Hellinger Distance-Attention-based Feature Aggregation Network for Few-Shot Classification](https://openaccess.thecvf.com/content/WACV2024/html/Lee_HELA-VFA_A_Hellinger_Distance-Attention-Based_Feature_Aggregation_Network_for_Few-Shot_Classification_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lee_HELA-VFA_A_Hellinger_Distance-Attention-Based_Feature_Aggregation_Network_for_Few-Shot_Classification_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Late to the Party? On-Demand Unlabeled Personalized Federated Learning](https://openaccess.thecvf.com/content/WACV2024/html/Amosy_Late_to_the_Party_On-Demand_Unlabeled_Personalized_Federated_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Amosy_Late_to_the_Party_On-Demand_Unlabeled_Personalized_Federated_Learning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=SJ-h6tU8L3w) |
| [GazeGNN: A Gaze-Guided Graph Neural Network for Chest X-Ray Classification](https://openaccess.thecvf.com/content/WACV2024/html/Wang_GazeGNN_A_Gaze-Guided_Graph_Neural_Network_for_Chest_X-Ray_Classification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ukaukaaaa/GazeGNN?style=flat)](https://github.com/ukaukaaaa/GazeGNN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_GazeGNN_A_Gaze-Guided_Graph_Neural_Network_for_Chest_X-Ray_Classification_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.18221-b31b1b.svg)](http://arxiv.org/abs/2305.18221) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jGSBemQG8tI) |
| [Towards Better Structured Pruning Saliency by Reorganizing Convolution](https://openaccess.thecvf.com/content/WACV2024/html/Sun_Towards_Better_Structured_Pruning_Saliency_by_Reorganizing_Convolution_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/AlexSunNik/SPSRC?style=flat)](https://github.com/AlexSunNik/SPSRC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sun_Towards_Better_Structured_Pruning_Saliency_by_Reorganizing_Convolution_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OhysmBg_oIc) |
| [Domain Generalization by Rejecting Extreme Augmentations](https://openaccess.thecvf.com/content/WACV2024/html/Aminbeidokhti_Domain_Generalization_by_Rejecting_Extreme_Augmentations_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Masseeh/DCAug?style=flat)](https://github.com/Masseeh/DCAug) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Aminbeidokhti_Domain_Generalization_by_Rejecting_Extreme_Augmentations_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.06670-b31b1b.svg)](http://arxiv.org/abs/2310.06670) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=F2IX5w2VayA) |
| [Wakening Past Concepts without Past Data: Class-Incremental Learning from Online Placebos](https://openaccess.thecvf.com/content/WACV2024/html/Liu_Wakening_Past_Concepts_Without_Past_Data_Class-Incremental_Learning_From_Online_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/yaoyao-liu/online-placebos?style=flat)](https://github.com/yaoyao-liu/online-placebos) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Wakening_Past_Concepts_Without_Past_Data_Class-Incremental_Learning_From_Online_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16115-b31b1b.svg)](http://arxiv.org/abs/2310.16115) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kQCaac5l21o) |
| [MICS: Midpoint Interpolation to Learn Compact and Separated Representations for Few-Shot Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Kim_MICS_Midpoint_Interpolation_To_Learn_Compact_and_Separated_Representations_for_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/solangii/MICS?style=flat)](https://github.com/solangii/MICS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_MICS_Midpoint_Interpolation_To_Learn_Compact_and_Separated_Representations_for_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Group-Wise Contrastive Bottleneck for Weakly-Supervised Visual Representation Learning](https://openaccess.thecvf.com/content/WACV2024/html/Yap_Group-Wise_Contrastive_Bottleneck_for_Weakly-Supervised_Visual_Representation_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/BPYap/CLRC?style=flat)](https://github.com/BPYap/CLRC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yap_Group-Wise_Contrastive_Bottleneck_for_Weakly-Supervised_Visual_Representation_Learning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2Z8IoFSyZi4) |
| [Training-based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection](https://openaccess.thecvf.com/content/WACV2024/html/Marvasti-Zadeh_Training-Based_Model_Refinement_and_Representation_Disagreement_for_Semi-Supervised_Object_Detection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Marvasti-Zadeh_Training-Based_Model_Refinement_and_Representation_Disagreement_for_Semi-Supervised_Object_Detection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13755-b31b1b.svg)](http://arxiv.org/abs/2307.13755) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JrRuW0oKZsg) |
| [DPPMask: Masked Image Modeling with Determinantal Point Processes](https://openaccess.thecvf.com/content/WACV2024/html/Xu_DPPMask_Masked_Image_Modeling_With_Determinantal_Point_Processes_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Xu_DPPMask_Masked_Image_Modeling_With_Determinantal_Point_Processes_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12736-b31b1b.svg)](http://arxiv.org/abs/2303.12736) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RhdSoJRv_Vw) |
| [Frequency Attention for Knowledge Distillation](https://openaccess.thecvf.com/content/WACV2024/html/Pham_Frequency_Attention_for_Knowledge_Distillation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Pham_Frequency_Attention_for_Knowledge_Distillation_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=EoSwZDLGRrQ) |
| [Minimizing Layerwise Activation Norm Improves Generalization in Federated Learning](https://openaccess.thecvf.com/content/WACV2024/html/Yashwanth_Minimizing_Layerwise_Activation_Norm_Improves_Generalization_in_Federated_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/vcl-iisc/fedMAN?style=flat)](https://github.com/vcl-iisc/fedMAN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yashwanth_Minimizing_Layerwise_Activation_Norm_Improves_Generalization_in_Federated_Learning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AGJ8IEQ6FV0) |
| [Adaptive Manifold for Imbalanced Transductive Few-Shot Learning](https://openaccess.thecvf.com/content/WACV2024/html/Lazarou_Adaptive_Manifold_for_Imbalanced_Transductive_Few-Shot_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/MichalisLazarou/AM?style=flat)](https://github.com/MichalisLazarou/AM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lazarou_Adaptive_Manifold_for_Imbalanced_Transductive_Few-Shot_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14281-b31b1b.svg)](http://arxiv.org/abs/2304.14281) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5my_re6zWDc) |
| [Cross-Domain Few-Shot Incremental Learning for Point-Cloud Recognition](https://openaccess.thecvf.com/content/WACV2024/html/Tan_Cross-Domain_Few-Shot_Incremental_Learning_for_Point-Cloud_Recognition_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tan_Cross-Domain_Few-Shot_Incremental_Learning_for_Point-Cloud_Recognition_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=12a2-KmoIZ4) |
| [Randomized Adversarial Style Perturbations for Domain Generalization](https://openaccess.thecvf.com/content/WACV2024/html/Kim_Randomized_Adversarial_Style_Perturbations_for_Domain_Generalization_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_Randomized_Adversarial_Style_Perturbations_for_Domain_Generalization_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01959-b31b1b.svg)](http://arxiv.org/abs/2304.01959) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xiiE17nJHo8) |
| [Shape-Biased CNNs are Not Always Superior in Out-of-Distribution Robustness](https://openaccess.thecvf.com/content/WACV2024/html/Qiu_Shape-Biased_CNNs_Are_Not_Always_Superior_in_Out-of-Distribution_Robustness_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Qiu_Shape-Biased_CNNs_Are_Not_Always_Superior_in_Out-of-Distribution_Robustness_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CETRK2b24ak) |
| [Partial Binarization of Neural Networks for Budget-Aware Efficient Learning](https://openaccess.thecvf.com/content/WACV2024/html/Bamba_Partial_Binarization_of_Neural_Networks_for_Budget-Aware_Efficient_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bamba_Partial_Binarization_of_Neural_Networks_for_Budget-Aware_Efficient_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.06739-b31b1b.svg)](http://arxiv.org/abs/2211.06739) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ymuodKH__0c) |
| [Monocular 3D Object Detection with LiDAR Guided Semi Supervised Active Learning](https://openaccess.thecvf.com/content/WACV2024/html/Hekimoglu_Monocular_3D_Object_Detection_With_LiDAR_Guided_Semi_Supervised_Active_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hekimoglu_Monocular_3D_Object_Detection_With_LiDAR_Guided_Semi_Supervised_Active_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08415-b31b1b.svg)](http://arxiv.org/abs/2307.08415) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cikgQ5GM5UA) |
| [Improving Open-Set Semi-Supervised Learning with Self-Supervision](https://openaccess.thecvf.com/content/WACV2024/html/Wallin_Improving_Open-Set_Semi-Supervised_Learning_With_Self-Supervision_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/walline/ssl-tf2-sefoss?style=flat)](https://github.com/walline/ssl-tf2-sefoss) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wallin_Improving_Open-Set_Semi-Supervised_Learning_With_Self-Supervision_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.10127-b31b1b.svg)](http://arxiv.org/abs/2301.10127) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zJcUV_kgwKk) |
| [EVOLVE: Enhancing Unsupervised Continual Learning with Multiple Experts](https://openaccess.thecvf.com/content/WACV2024/html/Yu_Evolve_Enhancing_Unsupervised_Continual_Learning_With_Multiple_Experts_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Orienfish/Evolve?style=flat)](https://github.com/Orienfish/Evolve) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yu_Evolve_Enhancing_Unsupervised_Continual_Learning_With_Multiple_Experts_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kH2KT6lvxF4) |
| [Masked Event Modeling: Self-Supervised Pretraining for Event Cameras](https://openaccess.thecvf.com/content/WACV2024/html/Klenk_Masked_Event_Modeling_Self-Supervised_Pretraining_for_Event_Cameras_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/tum-vision/mem?style=flat)](https://github.com/tum-vision/mem) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Klenk_Masked_Event_Modeling_Self-Supervised_Pretraining_for_Event_Cameras_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.10368-b31b1b.svg)](http://arxiv.org/abs/2212.10368) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=dgG9EK5EVGk) |
| [Overcoming Catastrophic Forgetting for Multi-Label Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Song_Overcoming_Catastrophic_Forgetting_for_Multi-Label_Class-Incremental_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Song_Overcoming_Catastrophic_Forgetting_for_Multi-Label_Class-Incremental_Learning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CmRcsg2-Vv4) |
| [Unsupervised Domain Adaptation for Semantic Segmentation with Pseudo Label Self-Refinement](https://openaccess.thecvf.com/content/WACV2024/html/Zhao_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_With_Pseudo_Label_Self-Refinement_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhao_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_With_Pseudo_Label_Self-Refinement_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16979-b31b1b.svg)](http://arxiv.org/abs/2310.16979) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=sPa-gBIQSbA) |
| [HyperMix: Out-of-Distribution Detection and Classification in Few-Shot Settings](https://openaccess.thecvf.com/content/WACV2024/html/Mehta_HyperMix_Out-of-Distribution_Detection_and_Classification_in_Few-Shot_Settings_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Mehta_HyperMix_Out-of-Distribution_Detection_and_Classification_in_Few-Shot_Settings_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.15086-b31b1b.svg)](http://arxiv.org/abs/2312.15086) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rw6zvH-EKQY) |
| [PrivObfNet: A Weakly Supervised Semantic Segmentation Model for Data Protection](https://openaccess.thecvf.com/content/WACV2024/html/Tay_PrivObfNet_A_Weakly_Supervised_Semantic_Segmentation_Model_for_Data_Protection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tay_PrivObfNet_A_Weakly_Supervised_Semantic_Segmentation_Model_for_Data_Protection_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pRbXPoGIA2Y) |
| [DISCO: Distributed Inference with Sparse Communications](https://openaccess.thecvf.com/content/WACV2024/html/Qin_DISCO_Distributed_Inference_With_Sparse_Communications_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Qin_DISCO_Distributed_Inference_With_Sparse_Communications_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.11180-b31b1b.svg)](http://arxiv.org/abs/2302.11180) | :heavy_minus_sign: |
| [Debiasing, Calibrating, and Improving Semi-Supervised Learning Performance via Simple Ensemble Projector](https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_Debiasing_Calibrating_and_Improving_Semi-Supervised_Learning_Performance_via_Simple_Ensemble_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nguyen_Debiasing_Calibrating_and_Improving_Semi-Supervised_Learning_Performance_via_Simple_Ensemble_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.15764-b31b1b.svg)](http://arxiv.org/abs/2310.15764) | :heavy_minus_sign: |
| [Reducing the Side-Effects of Oscillations in Training of Quantized YOLO Networks](https://openaccess.thecvf.com/content/WACV2024/html/Gupta_Reducing_the_Side-Effects_of_Oscillations_in_Training_of_Quantized_YOLO_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gupta_Reducing_the_Side-Effects_of_Oscillations_in_Training_of_Quantized_YOLO_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.05109-b31b1b.svg)](http://arxiv.org/abs/2311.05109) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=StEqQN7A_rA) |
| [Robust Unsupervised Domain Adaptation through Negative-View Regularization](https://openaccess.thecvf.com/content/WACV2024/html/Jang_Robust_Unsupervised_Domain_Adaptation_Through_Negative-View_Regularization_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/JoonHyeokJ/NVC?style=flat)](https://github.com/JoonHyeokJ/NVC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Jang_Robust_Unsupervised_Domain_Adaptation_Through_Negative-View_Regularization_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=z2soJdywyQY) |
| [Link Prediction for Flow-Driven Spatial Networks](https://openaccess.thecvf.com/content/WACV2024/html/Wittmann_Link_Prediction_for_Flow-Driven_Spatial_Networks_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/bwittmann/GAV?style=flat)](https://github.com/bwittmann/GAV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wittmann_Link_Prediction_for_Flow-Driven_Spatial_Networks_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14501-b31b1b.svg)](http://arxiv.org/abs/2303.14501) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_Fn6xxBSH4c) |
| [FLORA: Fine-Grained Low-Rank Architecture Search for Vision Transformer](https://openaccess.thecvf.com/content/WACV2024/html/Chang_FLORA_Fine-Grained_Low-Rank_Architecture_Search_for_Vision_Transformer_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/shadowpa0327/FLORA?style=flat)](https://github.com/shadowpa0327/FLORA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chang_FLORA_Fine-Grained_Low-Rank_Architecture_Search_for_Vision_Transformer_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03912-b31b1b.svg)](http://arxiv.org/abs/2311.03912) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=CTHVBR9OjZA) |
| [CL-MAE: Curriculum-Learned Masked Autoencoders](https://openaccess.thecvf.com/content/WACV2024/html/Madan_CL-MAE_Curriculum-Learned_Masked_Autoencoders_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ristea/cl-mae?style=flat)](https://github.com/ristea/cl-mae) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Madan_CL-MAE_Curriculum-Learned_Masked_Autoencoders_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16572-b31b1b.svg)](http://arxiv.org/abs/2308.16572) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IAtY34XhsdA) |
| [Active Learning with Task Consistency and Diversity in Multi-Task Networks](https://openaccess.thecvf.com/content/WACV2024/html/Hekimoglu_Active_Learning_With_Task_Consistency_and_Diversity_in_Multi-Task_Networks_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/aralhekimoglu/mtal?style=flat)](https://github.com/aralhekimoglu/mtal) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hekimoglu_Active_Learning_With_Task_Consistency_and_Diversity_in_Multi-Task_Networks_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2JGEUFftJ1I) |
| [Enhancing Diverse Intra-Identity Representation for Visible-Infrared Person Re-Identification](https://openaccess.thecvf.com/content/WACV2024/html/Kim_Enhancing_Diverse_Intra-Identity_Representation_for_Visible-Infrared_Person_Re-Identification_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_Enhancing_Diverse_Intra-Identity_Representation_for_Visible-Infrared_Person_Re-Identification_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-UJA0ORJ7tA) |
| [Steering Prototypes with Prompt-Tuning for Rehearsal-Free Continual Learning](https://openaccess.thecvf.com/content/WACV2024/html/Li_Steering_Prototypes_With_Prompt-Tuning_for_Rehearsal-Free_Continual_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/LzVv123456/Contrastive-Prototypical-Prompt?style=flat)](https://github.com/LzVv123456/Contrastive-Prototypical-Prompt) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Li_Steering_Prototypes_With_Prompt-Tuning_for_Rehearsal-Free_Continual_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09447-b31b1b.svg)](http://arxiv.org/abs/2303.09447) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_DDX9tdPVyQ) |
| [Active Batch Sampling for Multi-Label Classification with Binary User Feedback](https://openaccess.thecvf.com/content/WACV2024/html/Goswami_Active_Batch_Sampling_for_Multi-Label_Classification_With_Binary_User_Feedback_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Goswami_Active_Batch_Sampling_for_Multi-Label_Classification_With_Binary_User_Feedback_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IKJIPha2bp8) |
| [M<sup>3</sup>3D: Learning 3D Priors using Multi-Modal Masked Autoencoders for 2D Image and Video Understanding](https://openaccess.thecvf.com/content/WACV2024/html/Jamal_M33D_Learning_3D_Priors_Using_Multi-Modal_Masked_Autoencoders_for_2D_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Jamal_M33D_Learning_3D_Priors_Using_Multi-Modal_Masked_Autoencoders_for_2D_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.15313-b31b1b.svg)](http://arxiv.org/abs/2309.15313) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=GS-zOTFwhmw) |
| [Universal Test-Time Adaptation through Weight Ensembling, Diversity Weighting, and Prior Correction](https://openaccess.thecvf.com/content/WACV2024/html/Marsden_Universal_Test-Time_Adaptation_Through_Weight_Ensembling_Diversity_Weighting_and_Prior_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/mariodoebler/test-time-adaptation?style=flat)](https://github.com/mariodoebler/test-time-adaptation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Marsden_Universal_Test-Time_Adaptation_Through_Weight_Ensembling_Diversity_Weighting_and_Prior_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.00650-b31b1b.svg)](http://arxiv.org/abs/2306.00650) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=YmKSxjVWg8o) |
| [SLoSH: Set Locality Sensitive Hashing via Sliced-Wasserstein Embeddings](https://openaccess.thecvf.com/content/WACV2024/html/Lu_SLoSH_Set_Locality_Sensitive_Hashing_via_Sliced-Wasserstein_Embeddings_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/mint-vu/SLOSH?style=flat)](https://github.com/mint-vu/SLOSH) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lu_SLoSH_Set_Locality_Sensitive_Hashing_via_Sliced-Wasserstein_Embeddings_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2112.05872-b31b1b.svg)](http://arxiv.org/abs/2112.05872) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=pa2ktN4u5TU) |
| [D<sup>3</sup>GU: Multi-Target Active Domain Adaptation via Enhancing Domain Alignment](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_D3GU_Multi-Target_Active_Domain_Adaptation_via_Enhancing_Domain_Alignment_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/lzhangbj/D3GU?style=flat)](https://github.com/lzhangbj/D3GU) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_D3GU_Multi-Target_Active_Domain_Adaptation_via_Enhancing_Domain_Alignment_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.05465-b31b1b.svg)](http://arxiv.org/abs/2401.05465) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=sVfgqIknem8) |
| [MetaVers: Meta-Learned Versatile Representations for Personalized Federated Learning](https://openaccess.thecvf.com/content/WACV2024/html/Lim_MetaVers_Meta-Learned_Versatile_Representations_for_Personalized_Federated_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/eepLearning/MetaVers?style=flat)](https://github.com/eepLearning/MetaVers) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lim_MetaVers_Meta-Learned_Versatile_Representations_for_Personalized_Federated_Learning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5KpGj5E6nN0) |
| [Instruct Me More! Random Prompting for Visual In-Context Learning](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Instruct_Me_More_Random_Prompting_for_Visual_In-Context_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Jackieam/InMeMo?style=flat)](https://github.com/Jackieam/InMeMo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_Instruct_Me_More_Random_Prompting_for_Visual_In-Context_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03648-b31b1b.svg)](http://arxiv.org/abs/2311.03648) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=6_xjjbaKwjA) |
| [SimA: Simple Softmax-Free Attention for Vision Transformers](https://openaccess.thecvf.com/content/WACV2024/html/Koohpayegani_SimA_Simple_Softmax-Free_Attention_for_Vision_Transformers_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/UCDvision/sima?style=flat)](https://github.com/UCDvision/sima) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Koohpayegani_SimA_Simple_Softmax-Free_Attention_for_Vision_Transformers_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.08898-b31b1b.svg)](http://arxiv.org/abs/2206.08898) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=domJnGB6pdA) |
| [Guided Cluster Aggregation: A Hierarchical Approach to Generalized Category Discovery](https://openaccess.thecvf.com/content/WACV2024/html/Otholt_Guided_Cluster_Aggregation_A_Hierarchical_Approach_to_Generalized_Category_Discovery_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/J-L-O/guided-cluster-aggregation?style=flat)](https://github.com/J-L-O/guided-cluster-aggregation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Otholt_Guided_Cluster_Aggregation_A_Hierarchical_Approach_to_Generalized_Category_Discovery_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_Ft5xxmTzck) |
| [Hardware Aware Evolutionary Neural Architecture Search using Representation Similarity Metric](https://openaccess.thecvf.com/content/WACV2024/html/Sinha_Hardware_Aware_Evolutionary_Neural_Architecture_Search_Using_Representation_Similarity_Metric_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sinha_Hardware_Aware_Evolutionary_Neural_Architecture_Search_Using_Representation_Similarity_Metric_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03923-b31b1b.svg)](http://arxiv.org/abs/2311.03923) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NSPXW9v2_EQ) |
| [Using Early Readouts to Mediate Featural Bias in Distillation](https://openaccess.thecvf.com/content/WACV2024/html/Tiwari_Using_Early_Readouts_To_Mediate_Featural_Bias_in_Distillation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tiwari_Using_Early_Readouts_To_Mediate_Featural_Bias_in_Distillation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.18590-b31b1b.svg)](http://arxiv.org/abs/2310.18590) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=S7AG7i01KNc) |
| [Gradient Coreset for Federated Learning](https://openaccess.thecvf.com/content/WACV2024/html/Sivasubramanian_Gradient_Coreset_for_Federated_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/nlokeshiisc/GCFL_Release?style=flat)](https://github.com/nlokeshiisc/GCFL_Release) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sivasubramanian_Gradient_Coreset_for_Federated_Learning_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8h7ZXkKcbWs) |
| [Revisiting Token Pruning for Object Detection and Instance Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Liu_Revisiting_Token_Pruning_for_Object_Detection_and_Instance_Segmentation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/uzh-rpg/svit?style=flat)](https://github.com/uzh-rpg/svit) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Revisiting_Token_Pruning_for_Object_Detection_and_Instance_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.07050-b31b1b.svg)](http://arxiv.org/abs/2306.07050) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zfJCGn4SNXA) |
| [LatentDR: Improving Model Generalization through Sample-Aware Latent Degradation and Restoration](https://openaccess.thecvf.com/content/WACV2024/html/Liu_LatentDR_Improving_Model_Generalization_Through_Sample-Aware_Latent_Degradation_and_Restoration_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/nerdslab/LatentDR?style=flat)](https://github.com/nerdslab/LatentDR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_LatentDR_Improving_Model_Generalization_Through_Sample-Aware_Latent_Degradation_and_Restoration_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.14596-b31b1b.svg)](http://arxiv.org/abs/2308.14596) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=W2P3My0xfbY) |
| [Fixing Overconfidence in Dynamic Neural Networks](https://openaccess.thecvf.com/content/WACV2024/html/Meronen_Fixing_Overconfidence_in_Dynamic_Neural_Networks_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/AaltoML/calibrated-dnn?style=flat)](https://github.com/AaltoML/calibrated-dnn) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Meronen_Fixing_Overconfidence_in_Dynamic_Neural_Networks_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.06359-b31b1b.svg)](http://arxiv.org/abs/2302.06359) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=X65NK88Fwvc) |
| [Empowering Unsupervised Domain Adaptation with Large-Scale Pre-Trained Vision-Language Models](https://openaccess.thecvf.com/content/WACV2024/html/Lai_Empowering_Unsupervised_Domain_Adaptation_With_Large-Scale_Pre-Trained_Vision-Language_Models_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lai_Empowering_Unsupervised_Domain_Adaptation_With_Large-Scale_Pre-Trained_Vision-Language_Models_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=uax0yXNjIUQ) |
| [pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Sreenivas_pSTarC_Pseudo_Source_Guided_Target_Clustering_for_Fully_Test-Time_Adaptation_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://manogna-s.github.io/pstarc/) <br /> [![GitHub](https://img.shields.io/github/stars/manogna-s/pSTarC?style=flat)](https://github.com/manogna-s/pSTarC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sreenivas_pSTarC_Pseudo_Source_Guided_Target_Clustering_for_Fully_Test-Time_Adaptation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.00846-b31b1b.svg)](http://arxiv.org/abs/2309.00846) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Wsuz4MQNLcw) |
| [Torque based Structured Pruning for Deep Neural Network](https://openaccess.thecvf.com/content/WACV2024/html/Gupta_Torque_Based_Structured_Pruning_for_Deep_Neural_Network_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gupta_Torque_Based_Structured_Pruning_for_Deep_Neural_Network_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=rA_Nz3l8y4Y) |
| [Meta-Learned Attribute Self-Interaction Network for Continual and Generalized Zero-Shot Learning](https://openaccess.thecvf.com/content/WACV2024/html/Verma_Meta-Learned_Attribute_Self-Interaction_Network_for_Continual_and_Generalized_Zero-Shot_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Verma_Meta-Learned_Attribute_Self-Interaction_Network_for_Continual_and_Generalized_Zero-Shot_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.01167-b31b1b.svg)](http://arxiv.org/abs/2312.01167) | :heavy_minus_sign: |
| [Letting 3D Guide the Way: 3D Guided 2D Few-Shot Image Classification](https://openaccess.thecvf.com/content/WACV2024/html/Chen_Letting_3D_Guide_the_Way_3D_Guided_2D_Few-Shot_Image_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/jiajingchen113322/3DG2D?style=flat)](https://github.com/jiajingchen113322/3DG2D) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_Letting_3D_Guide_the_Way_3D_Guided_2D_Few-Shot_Image_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MPmSE0Hi29M) |
| [Robust Learning via Conditional Prevalence Adjustment](https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_Robust_Learning_via_Conditional_Prevalence_Adjustment_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nguyen_Robust_Learning_via_Conditional_Prevalence_Adjustment_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.15766-b31b1b.svg)](http://arxiv.org/abs/2310.15766) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AKk7nLMT-Lw) |
| [Learning to Compose SuperWeights for Neural Parameter Allocation Search](https://openaccess.thecvf.com/content/WACV2024/html/Teterwak_Learning_To_Compose_SuperWeights_for_Neural_Parameter_Allocation_Search_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/piotr-teterwak/SuperWeights?style=flat)](https://github.com/piotr-teterwak/SuperWeights) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Teterwak_Learning_To_Compose_SuperWeights_for_Neural_Parameter_Allocation_Search_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.01274-b31b1b.svg)](http://arxiv.org/abs/2312.01274) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=65CVtv01lCw) |
| [Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where](https://openaccess.thecvf.com/content/WACV2024/html/Chin_Masking_Improves_Contrastive_Self-Supervised_Learning_for_ConvNets_and_Saliency_Tells_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/joycenerd/Saliency-Guided-Masking-for-ConvNets?style=flat)](https://github.com/joycenerd/Saliency-Guided-Masking-for-ConvNets) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chin_Masking_Improves_Contrastive_Self-Supervised_Learning_for_ConvNets_and_Saliency_Tells_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.12757-b31b1b.svg)](http://arxiv.org/abs/2309.12757) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=nULYZqYK40o) |
| [Critical Gap between Generalization Error and Empirical Error in Active Learning](https://openaccess.thecvf.com/content/WACV2024/html/Kanebako_Critical_Gap_Between_Generalization_Error_and_Empirical_Error_in_Active_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kanebako_Critical_Gap_Between_Generalization_Error_and_Empirical_Error_in_Active_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zeUMsI8_knA) |
| [Appearance-based Curriculum for Semi-Supervised Learning with Multi-Angle Unlabeled Data](https://openaccess.thecvf.com/content/WACV2024/html/Tanaka_Appearance-Based_Curriculum_for_Semi-Supervised_Learning_With_Multi-Angle_Unlabeled_Data_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tanaka_Appearance-Based_Curriculum_for_Semi-Supervised_Learning_With_Multi-Angle_Unlabeled_Data_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JWGuZD6bS4k) |
| [Domain Generalisation via Risk Distribution Matching](https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_Domain_Generalisation_via_Risk_Distribution_Matching_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/nktoan/risk-distribution-matching?style=flat)](https://github.com/nktoan/risk-distribution-matching) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nguyen_Domain_Generalisation_via_Risk_Distribution_Matching_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.18598-b31b1b.svg)](http://arxiv.org/abs/2310.18598) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=UCk0-nYO5qA) |
| [MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters](https://openaccess.thecvf.com/content/WACV2024/html/Pham_MixtureGrowth_Growing_Neural_Networks_by_Recombining_Learned_Parameters_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/chaudatascience/mixturegrowth?style=flat)](https://github.com/chaudatascience/mixturegrowth) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Pham_MixtureGrowth_Growing_Neural_Networks_by_Recombining_Learned_Parameters_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.04251-b31b1b.svg)](http://arxiv.org/abs/2311.04251) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lRFrHg16PBk) |
| [Increasing Biases Can Be more Efficient than Increasing Weights](https://openaccess.thecvf.com/content/WACV2024/html/Metta_Increasing_Biases_Can_Be_More_Efficient_Than_Increasing_Weights_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Metta_Increasing_Biases_Can_Be_More_Efficient_Than_Increasing_Weights_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LmZdK1BwYGU) |
| [Deep Subdomain Alignment for Cross-Domain Image Classification](https://openaccess.thecvf.com/content/WACV2024/html/Zhao_Deep_Subdomain_Alignment_for_Cross-Domain_Image_Classification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/zhaoyewei/DSACDIC?style=flat)](https://github.com/zhaoyewei/DSACDIC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhao_Deep_Subdomain_Alignment_for_Cross-Domain_Image_Classification_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AM63h2LzFY8) |
| [Generalization by Adaptation: Diffusion-based Domain Extension for Domain-Generalized Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Niemeijer_Generalization_by_Adaptation_Diffusion-Based_Domain_Extension_for_Domain-Generalized_Semantic_Segmentation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/JNiemeijer/DIDEX?style=flat)](https://github.com/JNiemeijer/DIDEX) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Niemeijer_Generalization_by_Adaptation_Diffusion-Based_Domain_Extension_for_Domain-Generalized_Semantic_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.01850-b31b1b.svg)](http://arxiv.org/abs/2312.01850) | :heavy_minus_sign: |
| [Kaizen: Practical Self-Supervised Continual Learning with Continual Fine-Tuning](https://openaccess.thecvf.com/content/WACV2024/html/Tang_Kaizen_Practical_Self-Supervised_Continual_Learning_With_Continual_Fine-Tuning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tang_Kaizen_Practical_Self-Supervised_Continual_Learning_With_Continual_Fine-Tuning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17235-b31b1b.svg)](http://arxiv.org/abs/2303.17235) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QGQh-9d13K8) |
| [Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder: Theoretical and Empirical Insights](https://openaccess.thecvf.com/content/WACV2024/html/Mazumder_Learning_Low-Rank_Latent_Spaces_With_Simple_Deterministic_Autoencoder_Theoretical_and_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Mazumder_Learning_Low-Rank_Latent_Spaces_With_Simple_Deterministic_Autoencoder_Theoretical_and_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16194-b31b1b.svg)](http://arxiv.org/abs/2310.16194) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=TUUpPQN6700) |
| [CycleCL: Self-Supervised Learning for Periodic Videos](https://openaccess.thecvf.com/content/WACV2024/html/Destro_CycleCL_Self-Supervised_Learning_for_Periodic_Videos_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Destro_CycleCL_Self-Supervised_Learning_for_Periodic_Videos_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03402-b31b1b.svg)](http://arxiv.org/abs/2311.03402) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=q8g-nkdHEVE) |
| [Textron: Weakly Supervised Multilingual Text Detection through Data Programming](https://openaccess.thecvf.com/content/WACV2024/html/Kudale_Textron_Weakly_Supervised_Multilingual_Text_Detection_Through_Data_Programming_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/IITB-LEAP-OCR/TEXTRON?style=flat)](https://github.com/IITB-LEAP-OCR/TEXTRON) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kudale_Textron_Weakly_Supervised_Multilingual_Text_Detection_Through_Data_Programming_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QxEKrfpfCzI) |
| [Beyond Active Learning: Leveraging the Full Potential of Human Interaction via Auto-Labeling, Human Correction, and Human Verification](https://openaccess.thecvf.com/content/WACV2024/html/Beck_Beyond_Active_Learning_Leveraging_the_Full_Potential_of_Human_Interaction_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Beck_Beyond_Active_Learning_Leveraging_the_Full_Potential_of_Human_Interaction_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.01277-b31b1b.svg)](http://arxiv.org/abs/2306.01277) | :heavy_minus_sign: |
