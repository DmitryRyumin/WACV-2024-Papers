# WACV-2024-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/low-level_and_physics-based-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/3d_cv.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Machine Learning: Architectures, Formulations, Algorithms

![Section Papers](https://img.shields.io/badge/Section%20Papers-74-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-44-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-35-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-2-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Efficient Transferability Assessment for Selection of Pre-Trained Detectors](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Efficient_Transferability_Assessment_for_Selection_of_Pre-Trained_Detectors_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Efficient_Transferability_Assessment_for_Selection_of_Pre-Trained_Detectors_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Plasticity-Optimized Complementary Networks for Unsupervised Continual Learning](https://openaccess.thecvf.com/content/WACV2024/html/Gomez-Villa_Plasticity-Optimized_Complementary_Networks_for_Unsupervised_Continual_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/alviur/pocon_wacv2024?style=flat)](https://github.com/alviur/pocon_wacv2024) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gomez-Villa_Plasticity-Optimized_Complementary_Networks_for_Unsupervised_Continual_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.06086-b31b1b.svg)](http://arxiv.org/abs/2309.06086) | :heavy_minus_sign: |
| [Continual Test-Time Domain Adaptation via Dynamic Sample Selection](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Continual_Test-Time_Domain_Adaptation_via_Dynamic_Sample_Selection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Continual_Test-Time_Domain_Adaptation_via_Dynamic_Sample_Selection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.03335-b31b1b.svg)](http://arxiv.org/abs/2310.03335) | :heavy_minus_sign: |
| [Source-Guided Similarity Preservation for Online Person Re-Identification](https://openaccess.thecvf.com/content/WACV2024/html/Rami_Source-Guided_Similarity_Preservation_for_Online_Person_Re-Identification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ramiMMhamza/S2P?style=flat)](https://github.com/ramiMMhamza/S2P) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Rami_Source-Guided_Similarity_Preservation_for_Online_Person_Re-Identification_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [CAILA: Concept-Aware Intra-Layer Adapters for Compositional Zero-Shot Learning](https://openaccess.thecvf.com/content/WACV2024/html/Zheng_CAILA_Concept-Aware_Intra-Layer_Adapters_for_Compositional_Zero-Shot_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/zhaohengz/CAILA?style=flat)](https://github.com/zhaohengz/CAILA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zheng_CAILA_Concept-Aware_Intra-Layer_Adapters_for_Compositional_Zero-Shot_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.16681-b31b1b.svg)](http://arxiv.org/abs/2305.16681) | :heavy_minus_sign: |
| [Mini but Mighty: Finetuning ViTs with Mini Adapters](https://openaccess.thecvf.com/content/WACV2024/html/Marouf_Mini_but_Mighty_Finetuning_ViTs_With_Mini_Adapters_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/IemProg/MiMi?style=flat)](https://github.com/IemProg/MiMi) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Marouf_Mini_but_Mighty_Finetuning_ViTs_With_Mini_Adapters_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03873-b31b1b.svg)](http://arxiv.org/abs/2311.03873) | :heavy_minus_sign: |
| [Recognition of Unseen Bird Species by Learning from Field Guides](https://openaccess.thecvf.com/content/WACV2024/html/Rodriguez_Recognition_of_Unseen_Bird_Species_by_Learning_From_Field_Guides_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ac-rodriguez/zsl_billow?style=flat)](https://github.com/ac-rodriguez/zsl_billow) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Rodriguez_Recognition_of_Unseen_Bird_Species_by_Learning_From_Field_Guides_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.01466-b31b1b.svg)](http://arxiv.org/abs/2206.01466) | :heavy_minus_sign: |
| [Single Domain Generalization via Normalised Cross-Correlation based Convolutions](https://openaccess.thecvf.com/content/WACV2024/html/Chuah_Single_Domain_Generalization_via_Normalised_Cross-Correlation_Based_Convolutions_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/waychin-weiqin/XCNorm?style=flat)](https://github.com/waychin-weiqin/XCNorm) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chuah_Single_Domain_Generalization_via_Normalised_Cross-Correlation_Based_Convolutions_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.05901-b31b1b.svg)](http://arxiv.org/abs/2307.05901) | :heavy_minus_sign: |
| [MoP-CLIP: A Mixture of Prompt-Tuned CLIP Models for Domain Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Nicolas_MoP-CLIP_A_Mixture_of_Prompt-Tuned_CLIP_Models_for_Domain_Incremental_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nicolas_MoP-CLIP_A_Mixture_of_Prompt-Tuned_CLIP_Models_for_Domain_Incremental_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.05707-b31b1b.svg)](http://arxiv.org/abs/2307.05707) | :heavy_minus_sign: |
| [Self-Supervised Representation Learning with Cross-Context Learning between Global and Hypercolumn Features](https://openaccess.thecvf.com/content/WACV2024/html/Gao_Self-Supervised_Representation_Learning_With_Cross-Context_Learning_Between_Global_and_Hypercolumn_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/zaczgao/CGH-Hypercolumn?style=flat)](https://github.com/zaczgao/CGH-Hypercolumn) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gao_Self-Supervised_Representation_Learning_With_Cross-Context_Learning_Between_Global_and_Hypercolumn_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.13392-b31b1b.svg)](http://arxiv.org/abs/2308.13392) | :heavy_minus_sign: |
| [Revisiting Pixel-Level Contrastive Pre-Training on Scene Images](https://openaccess.thecvf.com/content/WACV2024/html/Pang_Revisiting_Pixel-Level_Contrastive_Pre-Training_on_Scene_Images_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/pangzss/PixCon?style=flat)](https://github.com/pangzss/PixCon) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Pang_Revisiting_Pixel-Level_Contrastive_Pre-Training_on_Scene_Images_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Improving Graph Networks through Selection-based Convolution](https://openaccess.thecvf.com/content/WACV2024/html/Hart_Improving_Graph_Networks_Through_Selection-Based_Convolution_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/davidmhart/SelectionGCN?style=flat)](https://github.com/davidmhart/SelectionGCN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hart_Improving_Graph_Networks_Through_Selection-Based_Convolution_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Exploiting CLIP for Zero-Shot HOI Detection Requires Knowledge Distillation at Multiple Levels](https://openaccess.thecvf.com/content/WACV2024/html/Wan_Exploiting_CLIP_for_Zero-Shot_HOI_Detection_Requires_Knowledge_Distillation_at_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/bobwan1995/Zeroshot-HOI-with-CLIP?style=flat)](https://github.com/bobwan1995/Zeroshot-HOI-with-CLIP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wan_Exploiting_CLIP_for_Zero-Shot_HOI_Detection_Requires_Knowledge_Distillation_at_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.05069-b31b1b.svg)](http://arxiv.org/abs/2309.05069) | :heavy_minus_sign: |
| [Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization](https://openaccess.thecvf.com/content/WACV2024/html/Bele_Learning_Class_and_Domain_Augmentations_for_Single-Source_Open-Domain_Generalization_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bele_Learning_Class_and_Domain_Augmentations_for_Single-Source_Open-Domain_Generalization_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.02599-b31b1b.svg)](http://arxiv.org/abs/2311.02599) | :heavy_minus_sign: |
| [Dynamic Token-Pass Transformers for Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Liu_Dynamic_Token-Pass_Transformers_for_Semantic_Segmentation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/FLHonker/DoViT-code?style=flat)](https://github.com/FLHonker/DoViT-code) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Dynamic_Token-Pass_Transformers_for_Semantic_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.01944-b31b1b.svg)](http://arxiv.org/abs/2308.01944) | :heavy_minus_sign: |
| [An Analysis of Initial Training Strategies for Exemplar-Free Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Petit_An_Analysis_of_Initial_Training_Strategies_for_Exemplar-Free_Class-Incremental_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Petit_An_Analysis_of_Initial_Training_Strategies_for_Exemplar-Free_Class-Incremental_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.11677-b31b1b.svg)](http://arxiv.org/abs/2308.11677) | :heavy_minus_sign: |
| [Few-Shot Shape Recognition by Learning Deep Shape-Aware Features](https://openaccess.thecvf.com/content/WACV2024/html/Shi_Few-Shot_Shape_Recognition_by_Learning_Deep_Shape-Aware_Features_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shi_Few-Shot_Shape_Recognition_by_Learning_Deep_Shape-Aware_Features_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.01315-b31b1b.svg)](http://arxiv.org/abs/2312.01315) | :heavy_minus_sign: |
| [Active Learning for Single-Stage Object Detection in UAV Images](https://openaccess.thecvf.com/content/WACV2024/html/Yamani_Active_Learning_for_Single-Stage_Object_Detection_in_UAV_Images_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/asmayamani/DUA?style=flat)](https://github.com/asmayamani/DUA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yamani_Active_Learning_for_Single-Stage_Object_Detection_in_UAV_Images_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Learning Intra-Class Multimodal Distributions with Orthonormal Matrices](https://openaccess.thecvf.com/content/WACV2024/html/Goto_Learning_Intra-Class_Multimodal_Distributions_With_Orthonormal_Matrices_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Goto_Learning_Intra-Class_Multimodal_Distributions_With_Orthonormal_Matrices_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Active Transfer Learning for Efficient Video-Specific Human Pose Estimation](https://openaccess.thecvf.com/content/WACV2024/html/Taketsugu_Active_Transfer_Learning_for_Efficient_Video-Specific_Human_Pose_Estimation_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://iminthemiddle.github.io/VATL4Pose-Page/) <br /> [![GitHub](https://img.shields.io/github/stars/ImIntheMiddle/VATL4Pose-WACV2024?style=flat)](https://github.com/ImIntheMiddle/VATL4Pose-WACV2024) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Taketsugu_Active_Transfer_Learning_for_Efficient_Video-Specific_Human_Pose_Estimation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.05041-b31b1b.svg)](http://arxiv.org/abs/2311.05041) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=O3RBjwkGxyA) |
| [Understanding Hyperbolic Metric Learning through Hard Negative Sampling](https://openaccess.thecvf.com/content/WACV2024/html/Yue_Understanding_Hyperbolic_Metric_Learning_Through_Hard_Negative_Sampling_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/YunYunY/HypMix?style=flat)](https://github.com/YunYunY/HypMix) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yue_Understanding_Hyperbolic_Metric_Learning_Through_Hard_Negative_Sampling_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Aligning Non-Causal Factors for Transformer-based Source-Free Domain Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Sanyal_Aligning_Non-Causal_Factors_for_Transformer-Based_Source-Free_Domain_Adaptation_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://val.cds.iisc.ac.in/C-SFTrans/) <br /> [![GitHub](https://img.shields.io/github/stars/val-iisc/C-SFTrans?style=flat)](https://github.com/val-iisc/C-SFTrans) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sanyal_Aligning_Non-Causal_Factors_for_Transformer-Based_Source-Free_Domain_Adaptation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.16294-b31b1b.svg)](http://arxiv.org/abs/2311.16294) | :heavy_minus_sign: |
| [Diverse Imagenet Models Transfer Better](https://openaccess.thecvf.com/content/WACV2024/html/Nayman_Diverse_Imagenet_Models_Transfer_Better_WACV_2024_paper.html) | :heavy_minus_sign:  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nayman_Diverse_Imagenet_Models_Transfer_Better_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.09134-b31b1b.svg)](http://arxiv.org/abs/2204.09134) | :heavy_minus_sign: |
| [Design Choices for Enhancing Noisy Student Self-Training](https://openaccess.thecvf.com/content/WACV2024/html/Radhakrishnan_Design_Choices_for_Enhancing_Noisy_Student_Self-Training_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Radhakrishnan_Design_Choices_for_Enhancing_Noisy_Student_Self-Training_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Bag of Tricks for Fully Test-Time Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Mounsaveng_Bag_of_Tricks_for_Fully_Test-Time_Adaptation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/smounsav/tta_bot?style=flat)](https://github.com/smounsav/tta_bot) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Mounsaveng_Bag_of_Tricks_for_Fully_Test-Time_Adaptation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.02416-b31b1b.svg)](http://arxiv.org/abs/2310.02416) | :heavy_minus_sign: |
| [Gradual Source Domain Expansion for Unsupervised Domain Adaptation](https://openaccess.thecvf.com/WACV2024#:~:text=Gradual%20Source%20Domain%20Expansion%20for%20Unsupervised%20Domain%20Adaptation) | [![GitHub](https://img.shields.io/github/stars/ThomasWestfechtel/GSDE?style=flat)](https://github.com/ThomasWestfechtel/GSDE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Westfechtel_Gradual_Source_Domain_Expansion_for_Unsupervised_Domain_Adaptation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.09599-b31b1b.svg)](http://arxiv.org/abs/2311.09599) | :heavy_minus_sign: |
| [OOD Aware Supervised Contrastive Learning](https://openaccess.thecvf.com/content/WACV2024/html/Seifi_OOD_Aware_Supervised_Contrastive_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Seifi_OOD_Aware_Supervised_Contrastive_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.01942-b31b1b.svg)](http://arxiv.org/abs/2310.01942) | :heavy_minus_sign: |
| [Expanding Hyperspherical Space for Few-Shot Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Deng_Expanding_Hyperspherical_Space_for_Few-Shot_Class-Incremental_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Deng_Expanding_Hyperspherical_Space_for_Few-Shot_Class-Incremental_Learning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-Free Continual Learning](https://openaccess.thecvf.com/content/WACV2024/html/Szatkowski_Adapt_Your_Teacher_Improving_Knowledge_Distillation_for_Exemplar-Free_Continual_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/fszatkowski/cl-teacher-adaptation?style=flat)](https://github.com/fszatkowski/cl-teacher-adaptation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Szatkowski_Adapt_Your_Teacher_Improving_Knowledge_Distillation_for_Exemplar-Free_Continual_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09544-b31b1b.svg)](http://arxiv.org/abs/2308.09544) | :heavy_minus_sign: |
| [Tunable Hybrid Proposal Networks for the Open World](https://openaccess.thecvf.com/content/WACV2024/html/Inkawhich_Tunable_Hybrid_Proposal_Networks_for_the_Open_World_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Inkawhich_Tunable_Hybrid_Proposal_Networks_for_the_Open_World_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Domain Generalization with Correlated Style Uncertainty](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Domain_Generalization_With_Correlated_Style_Uncertainty_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/freshman97/CSU?style=flat)](https://github.com/freshman97/CSU) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_Domain_Generalization_With_Correlated_Style_Uncertainty_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.09950-b31b1b.svg)](http://arxiv.org/abs/2212.09950) | :heavy_minus_sign: |
| [Correlation-Aware Active Learning for Surgery Video Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Wu_Correlation-Aware_Active_Learning_for_Surgery_Video_Segmentation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wu_Correlation-Aware_Active_Learning_for_Surgery_Video_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.08811-b31b1b.svg)](http://arxiv.org/abs/2311.08811) | :heavy_minus_sign: |
| [A Multimodal Benchmark and Improved Architecture for Zero Shot Learning](https://openaccess.thecvf.com/content/WACV2024/html/Doshi_A_Multimodal_Benchmark_and_Improved_Architecture_for_Zero_Shot_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Doshi_A_Multimodal_Benchmark_and_Improved_Architecture_for_Zero_Shot_Learning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [TCP: Triplet Contrastive-Relationship Preserving for Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Li_TCP_Triplet_Contrastive-Relationship_Preserving_for_Class-Incremental_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Li_TCP_Triplet_Contrastive-Relationship_Preserving_for_Class-Incremental_Learning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Improving Normalization with the James-Stein Estimator](https://openaccess.thecvf.com/content/WACV2024/html/Khoshsirat_Improving_Normalization_With_the_James-Stein_Estimator_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Khoshsirat_Improving_Normalization_With_the_James-Stein_Estimator_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.00313-b31b1b.svg)](http://arxiv.org/abs/2312.00313) | :heavy_minus_sign: |
| [ReConPatch: Contrastive Patch Representation Learning for Industrial Anomaly Detection](https://openaccess.thecvf.com/content/WACV2024/html/Hyun_ReConPatch_Contrastive_Patch_Representation_Learning_for_Industrial_Anomaly_Detection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hyun_ReConPatch_Contrastive_Patch_Representation_Learning_for_Industrial_Anomaly_Detection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.16713-b31b1b.svg)](http://arxiv.org/abs/2305.16713) | :heavy_minus_sign: |
| [REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Seto_REALM_Robust_Entropy_Adaptive_Loss_Minimization_for_Improved_Single-Sample_Test-Time_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Seto_REALM_Robust_Entropy_Adaptive_Loss_Minimization_for_Improved_Single-Sample_Test-Time_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03964-b31b1b.svg)](http://arxiv.org/abs/2309.03964) | :heavy_minus_sign: |
| [On the Quantification of Image Reconstruction Uncertainty without Training Data](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_On_the_Quantification_of_Image_Reconstruction_Uncertainty_Without_Training_Data_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_On_the_Quantification_of_Image_Reconstruction_Uncertainty_Without_Training_Data_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.09639-b31b1b.svg)](http://arxiv.org/abs/2311.09639) | :heavy_minus_sign: |
| [Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin](https://openaccess.thecvf.com/content/WACV2024/html/Moreira_Hyperbolic_vs_Euclidean_Embeddings_in_Few-Shot_Learning_Two_Sides_of_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/gabmoreira/hyper?style=flat)](https://github.com/gabmoreira/hyper) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Moreira_Hyperbolic_vs_Euclidean_Embeddings_in_Few-Shot_Learning_Two_Sides_of_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.10013-b31b1b.svg)](http://arxiv.org/abs/2309.10013) | :heavy_minus_sign: |
| [Effective Restoration of Source Knowledge in Continual Test Time Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Niloy_Effective_Restoration_of_Source_Knowledge_in_Continual_Test_Time_Adaptation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Niloy_Effective_Restoration_of_Source_Knowledge_in_Continual_Test_Time_Adaptation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.04991-b31b1b.svg)](http://arxiv.org/abs/2311.04991) | :heavy_minus_sign: |
| [AMEND: Adaptive Margin and Expanded Neighborhood for Efficient Generalized Category Discovery](https://openaccess.thecvf.com/content/WACV2024/html/Banerjee_AMEND_Adaptive_Margin_and_Expanded_Neighborhood_for_Efficient_Generalized_Category_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Banerjee_AMEND_Adaptive_Margin_and_Expanded_Neighborhood_for_Efficient_Generalized_Category_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Optical Flow Domain Adaptation via Target Style Transfer](https://openaccess.thecvf.com/content/WACV2024/html/Yoon_Optical_Flow_Domain_Adaptation_via_Target_Style_Transfer_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yoon_Optical_Flow_Domain_Adaptation_via_Target_Style_Transfer_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Out-of-Distribution Detection with Logical Reasoning](https://openaccess.thecvf.com/content/WACV2024/html/Kirchheim_Out-of-Distribution_Detection_With_Logical_Reasoning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/kkirchheim/logic-ood?style=flat)](https://github.com/kkirchheim/logic-ood) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kirchheim_Out-of-Distribution_Detection_With_Logical_Reasoning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Evidential Uncertainty Quantification: A Variance-based Perspective](https://openaccess.thecvf.com/content/WACV2024/html/Duan_Evidential_Uncertainty_Quantification_A_Variance-Based_Perspective_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/KerryDRX/EvidentialADA?style=flat)](https://github.com/KerryDRX/EvidentialADA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Duan_Evidential_Uncertainty_Quantification_A_Variance-Based_Perspective_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.11367-b31b1b.svg)](http://arxiv.org/abs/2311.11367) | :heavy_minus_sign: |
| [Self-Supervised Learning of Semantic Correspondence using Web Videos](https://openaccess.thecvf.com/content/WACV2024/html/Kwon_Self-Supervised_Learning_of_Semantic_Correspondence_Using_Web_Videos_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/kinux98/SSSCWEB?style=flat)](https://github.com/kinux98/SSSCWEB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kwon_Self-Supervised_Learning_of_Semantic_Correspondence_Using_Web_Videos_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Opinion Unaware Image Quality Assessment via Adversarial Convolutional Variational Autoencoder](https://openaccess.thecvf.com/content/WACV2024/html/Shukla_Opinion_Unaware_Image_Quality_Assessment_via_Adversarial_Convolutional_Variational_Autoencoder_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shukla_Opinion_Unaware_Image_Quality_Assessment_via_Adversarial_Convolutional_Variational_Autoencoder_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth Simulation](https://openaccess.thecvf.com/content/WACV2024/html/Zavrtanik_Cheating_Depth_Enhancing_3D_Surface_Anomaly_Detection_via_Depth_Simulation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/VitjanZ/3DSR?style=flat)](https://github.com/VitjanZ/3DSR) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zavrtanik_Cheating_Depth_Enhancing_3D_Surface_Anomaly_Detection_via_Depth_Simulation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.01117-b31b1b.svg)](http://arxiv.org/abs/2311.01117) | :heavy_minus_sign: |
| [HELA-VFA: A Hellinger Distance-Attention-based Feature Aggregation Network for Few-Shot Classification](https://openaccess.thecvf.com/content/WACV2024/html/Lee_HELA-VFA_A_Hellinger_Distance-Attention-Based_Feature_Aggregation_Network_for_Few-Shot_Classification_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lee_HELA-VFA_A_Hellinger_Distance-Attention-Based_Feature_Aggregation_Network_for_Few-Shot_Classification_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Late to the Party? On-Demand Unlabeled Personalized Federated Learning](https://openaccess.thecvf.com/content/WACV2024/html/Amosy_Late_to_the_Party_On-Demand_Unlabeled_Personalized_Federated_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Amosy_Late_to_the_Party_On-Demand_Unlabeled_Personalized_Federated_Learning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [GazeGNN: A Gaze-Guided Graph Neural Network for Chest X-Ray Classification](https://openaccess.thecvf.com/content/WACV2024/html/Wang_GazeGNN_A_Gaze-Guided_Graph_Neural_Network_for_Chest_X-Ray_Classification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ukaukaaaa/GazeGNN?style=flat)](https://github.com/ukaukaaaa/GazeGNN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_GazeGNN_A_Gaze-Guided_Graph_Neural_Network_for_Chest_X-Ray_Classification_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.18221-b31b1b.svg)](http://arxiv.org/abs/2305.18221) | :heavy_minus_sign: |
| [Towards Better Structured Pruning Saliency by Reorganizing Convolution](https://openaccess.thecvf.com/content/WACV2024/html/Sun_Towards_Better_Structured_Pruning_Saliency_by_Reorganizing_Convolution_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/AlexSunNik/SPSRC?style=flat)](https://github.com/AlexSunNik/SPSRC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sun_Towards_Better_Structured_Pruning_Saliency_by_Reorganizing_Convolution_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Domain Generalization by Rejecting Extreme Augmentations](https://openaccess.thecvf.com/content/WACV2024/html/Aminbeidokhti_Domain_Generalization_by_Rejecting_Extreme_Augmentations_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Masseeh/DCAug?style=flat)](https://github.com/Masseeh/DCAug) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Aminbeidokhti_Domain_Generalization_by_Rejecting_Extreme_Augmentations_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.06670-b31b1b.svg)](http://arxiv.org/abs/2310.06670) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zO4rPBwsZOw) |
| [Wakening Past Concepts without Past Data: Class-Incremental Learning from Online Placebos](https://openaccess.thecvf.com/content/WACV2024/html/Liu_Wakening_Past_Concepts_Without_Past_Data_Class-Incremental_Learning_From_Online_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/yaoyao-liu/online-placebos?style=flat)](https://github.com/yaoyao-liu/online-placebos) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Wakening_Past_Concepts_Without_Past_Data_Class-Incremental_Learning_From_Online_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16115-b31b1b.svg)](http://arxiv.org/abs/2310.16115) | :heavy_minus_sign: |
| [MICS: Midpoint Interpolation to Learn Compact and Separated Representations for Few-Shot Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Kim_MICS_Midpoint_Interpolation_To_Learn_Compact_and_Separated_Representations_for_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/solangii/MICS?style=flat)](https://github.com/solangii/MICS) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_MICS_Midpoint_Interpolation_To_Learn_Compact_and_Separated_Representations_for_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Group-Wise Contrastive Bottleneck for Weakly-Supervised Visual Representation Learning](https://openaccess.thecvf.com/content/WACV2024/html/Yap_Group-Wise_Contrastive_Bottleneck_for_Weakly-Supervised_Visual_Representation_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/BPYap/CLRC?style=flat)](https://github.com/BPYap/CLRC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yap_Group-Wise_Contrastive_Bottleneck_for_Weakly-Supervised_Visual_Representation_Learning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Training-based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection](https://openaccess.thecvf.com/content/WACV2024/html/Marvasti-Zadeh_Training-Based_Model_Refinement_and_Representation_Disagreement_for_Semi-Supervised_Object_Detection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Marvasti-Zadeh_Training-Based_Model_Refinement_and_Representation_Disagreement_for_Semi-Supervised_Object_Detection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13755-b31b1b.svg)](http://arxiv.org/abs/2307.13755) | :heavy_minus_sign: |
| [DPPMask: Masked Image Modeling with Determinantal Point Processes](https://openaccess.thecvf.com/content/WACV2024/html/Xu_DPPMask_Masked_Image_Modeling_With_Determinantal_Point_Processes_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Xu_DPPMask_Masked_Image_Modeling_With_Determinantal_Point_Processes_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.12736-b31b1b.svg)](http://arxiv.org/abs/2303.12736) | :heavy_minus_sign: |
| [Frequency Attention for Knowledge Distillation](https://openaccess.thecvf.com/content/WACV2024/html/Pham_Frequency_Attention_for_Knowledge_Distillation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Pham_Frequency_Attention_for_Knowledge_Distillation_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Minimizing Layerwise Activation Norm Improves Generalization in Federated Learning](https://openaccess.thecvf.com/content/WACV2024/html/Yashwanth_Minimizing_Layerwise_Activation_Norm_Improves_Generalization_in_Federated_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/vcl-iisc/fedMAN?style=flat)](https://github.com/vcl-iisc/fedMAN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yashwanth_Minimizing_Layerwise_Activation_Norm_Improves_Generalization_in_Federated_Learning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Adaptive Manifold for Imbalanced Transductive Few-Shot Learning](https://openaccess.thecvf.com/content/WACV2024/html/Lazarou_Adaptive_Manifold_for_Imbalanced_Transductive_Few-Shot_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/MichalisLazarou/AM?style=flat)](https://github.com/MichalisLazarou/AM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lazarou_Adaptive_Manifold_for_Imbalanced_Transductive_Few-Shot_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.14281-b31b1b.svg)](http://arxiv.org/abs/2304.14281) | :heavy_minus_sign: |
| [Cross-Domain Few-Shot Incremental Learning for Point-Cloud Recognition](https://openaccess.thecvf.com/content/WACV2024/html/Tan_Cross-Domain_Few-Shot_Incremental_Learning_for_Point-Cloud_Recognition_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tan_Cross-Domain_Few-Shot_Incremental_Learning_for_Point-Cloud_Recognition_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Randomized Adversarial Style Perturbations for Domain Generalization](https://openaccess.thecvf.com/content/WACV2024/html/Kim_Randomized_Adversarial_Style_Perturbations_for_Domain_Generalization_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_Randomized_Adversarial_Style_Perturbations_for_Domain_Generalization_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.01959-b31b1b.svg)](http://arxiv.org/abs/2304.01959) | :heavy_minus_sign: |
| [Shape-Biased CNNs are Not Always Superior in Out-of-Distribution Robustness](https://openaccess.thecvf.com/content/WACV2024/html/Qiu_Shape-Biased_CNNs_Are_Not_Always_Superior_in_Out-of-Distribution_Robustness_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Qiu_Shape-Biased_CNNs_Are_Not_Always_Superior_in_Out-of-Distribution_Robustness_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Partial Binarization of Neural Networks for Budget-Aware Efficient Learning](https://openaccess.thecvf.com/content/WACV2024/html/Bamba_Partial_Binarization_of_Neural_Networks_for_Budget-Aware_Efficient_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bamba_Partial_Binarization_of_Neural_Networks_for_Budget-Aware_Efficient_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.06739-b31b1b.svg)](http://arxiv.org/abs/2211.06739) | :heavy_minus_sign: |
| [Monocular 3D Object Detection with LiDAR Guided Semi Supervised Active Learning](https://openaccess.thecvf.com/content/WACV2024/html/Hekimoglu_Monocular_3D_Object_Detection_With_LiDAR_Guided_Semi_Supervised_Active_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hekimoglu_Monocular_3D_Object_Detection_With_LiDAR_Guided_Semi_Supervised_Active_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08415-b31b1b.svg)](http://arxiv.org/abs/2307.08415) | :heavy_minus_sign: |
| [Improving Open-Set Semi-Supervised Learning with Self-Supervision](https://openaccess.thecvf.com/content/WACV2024/html/Wallin_Improving_Open-Set_Semi-Supervised_Learning_With_Self-Supervision_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/walline/ssl-tf2-sefoss?style=flat)](https://github.com/walline/ssl-tf2-sefoss) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wallin_Improving_Open-Set_Semi-Supervised_Learning_With_Self-Supervision_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.10127-b31b1b.svg)](http://arxiv.org/abs/2301.10127) | :heavy_minus_sign: |
| [EVOLVE: Enhancing Unsupervised Continual Learning with Multiple Experts](https://openaccess.thecvf.com/content/WACV2024/html/Yu_Evolve_Enhancing_Unsupervised_Continual_Learning_With_Multiple_Experts_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Orienfish/Evolve?style=flat)](https://github.com/Orienfish/Evolve) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yu_Evolve_Enhancing_Unsupervised_Continual_Learning_With_Multiple_Experts_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Masked Event Modeling: Self-Supervised Pretraining for Event Cameras](https://openaccess.thecvf.com/content/WACV2024/html/Klenk_Masked_Event_Modeling_Self-Supervised_Pretraining_for_Event_Cameras_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/tum-vision/mem?style=flat)](https://github.com/tum-vision/mem) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Klenk_Masked_Event_Modeling_Self-Supervised_Pretraining_for_Event_Cameras_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.10368-b31b1b.svg)](http://arxiv.org/abs/2212.10368) | :heavy_minus_sign: |
| [Overcoming Catastrophic Forgetting for Multi-Label Class-Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Song_Overcoming_Catastrophic_Forgetting_for_Multi-Label_Class-Incremental_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Song_Overcoming_Catastrophic_Forgetting_for_Multi-Label_Class-Incremental_Learning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Unsupervised Domain Adaptation for Semantic Segmentation with Pseudo Label Self-Refinement](https://openaccess.thecvf.com/content/WACV2024/html/Zhao_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_With_Pseudo_Label_Self-Refinement_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhao_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_With_Pseudo_Label_Self-Refinement_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16979-b31b1b.svg)](http://arxiv.org/abs/2310.16979) | :heavy_minus_sign: |
| [HyperMix: Out-of-Distribution Detection and Classification in Few-Shot Settings](https://openaccess.thecvf.com/content/WACV2024/html/Mehta_HyperMix_Out-of-Distribution_Detection_and_Classification_in_Few-Shot_Settings_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Mehta_HyperMix_Out-of-Distribution_Detection_and_Classification_in_Few-Shot_Settings_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.15086-b31b1b.svg)](http://arxiv.org/abs/2312.15086) | :heavy_minus_sign: |
| [PrivObfNet: A Weakly Supervised Semantic Segmentation Model for Data Protection](https://openaccess.thecvf.com/content/WACV2024/html/Tay_PrivObfNet_A_Weakly_Supervised_Semantic_Segmentation_Model_for_Data_Protection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tay_PrivObfNet_A_Weakly_Supervised_Semantic_Segmentation_Model_for_Data_Protection_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [DISCO: Distributed Inference with Sparse Communications](https://openaccess.thecvf.com/content/WACV2024/html/Qin_DISCO_Distributed_Inference_With_Sparse_Communications_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Qin_DISCO_Distributed_Inference_With_Sparse_Communications_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.11180-b31b1b.svg)](http://arxiv.org/abs/2302.11180) | :heavy_minus_sign: |
| [Debiasing, Calibrating, and Improving Semi-Supervised Learning Performance via Simple Ensemble Projector](https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_Debiasing_Calibrating_and_Improving_Semi-Supervised_Learning_Performance_via_Simple_Ensemble_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nguyen_Debiasing_Calibrating_and_Improving_Semi-Supervised_Learning_Performance_via_Simple_Ensemble_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.15764-b31b1b.svg)](http://arxiv.org/abs/2310.15764) | :heavy_minus_sign: |
| [Reducing the Side-Effects of Oscillations in Training of Quantized YOLO Networks](https://openaccess.thecvf.com/content/WACV2024/html/Gupta_Reducing_the_Side-Effects_of_Oscillations_in_Training_of_Quantized_YOLO_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gupta_Reducing_the_Side-Effects_of_Oscillations_in_Training_of_Quantized_YOLO_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.05109-b31b1b.svg)](http://arxiv.org/abs/2311.05109) | :heavy_minus_sign: |
| [Robust Unsupervised Domain Adaptation through Negative-View Regularization](https://openaccess.thecvf.com/content/WACV2024/html/Jang_Robust_Unsupervised_Domain_Adaptation_Through_Negative-View_Regularization_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/JoonHyeokJ/NVC?style=flat)](https://github.com/JoonHyeokJ/NVC) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Jang_Robust_Unsupervised_Domain_Adaptation_Through_Negative-View_Regularization_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Link Prediction for Flow-Driven Spatial Networks](https://openaccess.thecvf.com/content/WACV2024/html/Wittmann_Link_Prediction_for_Flow-Driven_Spatial_Networks_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/bwittmann/GAV?style=flat)](https://github.com/bwittmann/GAV) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wittmann_Link_Prediction_for_Flow-Driven_Spatial_Networks_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.14501-b31b1b.svg)](http://arxiv.org/abs/2303.14501) | :heavy_minus_sign: |
| [FLORA: Fine-Grained Low-Rank Architecture Search for Vision Transformer](https://openaccess.thecvf.com/content/WACV2024/html/Chang_FLORA_Fine-Grained_Low-Rank_Architecture_Search_for_Vision_Transformer_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/shadowpa0327/FLORA?style=flat)](https://github.com/shadowpa0327/FLORA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chang_FLORA_Fine-Grained_Low-Rank_Architecture_Search_for_Vision_Transformer_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03912-b31b1b.svg)](http://arxiv.org/abs/2311.03912) | :heavy_minus_sign: |
| [CL-MAE: Curriculum-Learned Masked Autoencoders](https://openaccess.thecvf.com/content/WACV2024/html/Madan_CL-MAE_Curriculum-Learned_Masked_Autoencoders_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ristea/cl-mae?style=flat)](https://github.com/ristea/cl-mae) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Madan_CL-MAE_Curriculum-Learned_Masked_Autoencoders_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16572-b31b1b.svg)](http://arxiv.org/abs/2308.16572) | :heavy_minus_sign: |
| [Active Learning with Task Consistency and Diversity in Multi-Task Networks](https://openaccess.thecvf.com/content/WACV2024/html/Hekimoglu_Active_Learning_With_Task_Consistency_and_Diversity_in_Multi-Task_Networks_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/aralhekimoglu/mtal?style=flat)](https://github.com/aralhekimoglu/mtal) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hekimoglu_Active_Learning_With_Task_Consistency_and_Diversity_in_Multi-Task_Networks_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Enhancing Diverse Intra-Identity Representation for Visible-Infrared Person Re-Identification](https://openaccess.thecvf.com/content/WACV2024/html/Kim_Enhancing_Diverse_Intra-Identity_Representation_for_Visible-Infrared_Person_Re-Identification_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_Enhancing_Diverse_Intra-Identity_Representation_for_Visible-Infrared_Person_Re-Identification_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Steering Prototypes with Prompt-Tuning for Rehearsal-Free Continual Learning](https://openaccess.thecvf.com/content/WACV2024/html/Li_Steering_Prototypes_With_Prompt-Tuning_for_Rehearsal-Free_Continual_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/LzVv123456/Contrastive-Prototypical-Prompt?style=flat)](https://github.com/LzVv123456/Contrastive-Prototypical-Prompt) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Li_Steering_Prototypes_With_Prompt-Tuning_for_Rehearsal-Free_Continual_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09447-b31b1b.svg)](http://arxiv.org/abs/2303.09447) | :heavy_minus_sign: |
| [Active Batch Sampling for Multi-Label Classification with Binary User Feedback](https://openaccess.thecvf.com/content/WACV2024/html/Goswami_Active_Batch_Sampling_for_Multi-Label_Classification_With_Binary_User_Feedback_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Goswami_Active_Batch_Sampling_for_Multi-Label_Classification_With_Binary_User_Feedback_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [M<sub>3</sub>3D: Learning 3D Priors using Multi-Modal Masked Autoencoders for 2D Image and Video Understanding](https://openaccess.thecvf.com/content/WACV2024/html/Jamal_M33D_Learning_3D_Priors_Using_Multi-Modal_Masked_Autoencoders_for_2D_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Jamal_M33D_Learning_3D_Priors_Using_Multi-Modal_Masked_Autoencoders_for_2D_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.15313-b31b1b.svg)](http://arxiv.org/abs/2309.15313) | :heavy_minus_sign: |
| [Universal Test-Time Adaptation through Weight Ensembling, Diversity Weighting, and Prior Correction](https://openaccess.thecvf.com/content/WACV2024/html/Marsden_Universal_Test-Time_Adaptation_Through_Weight_Ensembling_Diversity_Weighting_and_Prior_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/mariodoebler/test-time-adaptation?style=flat)](https://github.com/mariodoebler/test-time-adaptation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Marsden_Universal_Test-Time_Adaptation_Through_Weight_Ensembling_Diversity_Weighting_and_Prior_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.00650-b31b1b.svg)](http://arxiv.org/abs/2306.00650) | :heavy_minus_sign: |
| [SLoSH: Set Locality Sensitive Hashing via Sliced-Wasserstein Embeddings](https://openaccess.thecvf.com/content/WACV2024/html/Lu_SLoSH_Set_Locality_Sensitive_Hashing_via_Sliced-Wasserstein_Embeddings_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/mint-vu/SLOSH?style=flat)](https://github.com/mint-vu/SLOSH) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lu_SLoSH_Set_Locality_Sensitive_Hashing_via_Sliced-Wasserstein_Embeddings_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2112.05872-b31b1b.svg)](http://arxiv.org/abs/2112.05872) | :heavy_minus_sign: |
| [D<sup>3</sup>GU: Multi-Target Active Domain Adaptation via Enhancing Domain Alignment](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_D3GU_Multi-Target_Active_Domain_Adaptation_via_Enhancing_Domain_Alignment_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/lzhangbj/D3GU?style=flat)](https://github.com/lzhangbj/D3GU) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_D3GU_Multi-Target_Active_Domain_Adaptation_via_Enhancing_Domain_Alignment_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.05465-b31b1b.svg)](http://arxiv.org/abs/2401.05465) | :heavy_minus_sign: |
| [MetaVers: Meta-Learned Versatile Representations for Personalized Federated Learning](https://openaccess.thecvf.com/content/WACV2024/html/Lim_MetaVers_Meta-Learned_Versatile_Representations_for_Personalized_Federated_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/eepLearning/MetaVers?style=flat)](https://github.com/eepLearning/MetaVers) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lim_MetaVers_Meta-Learned_Versatile_Representations_for_Personalized_Federated_Learning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Instruct Me More! Random Prompting for Visual In-Context Learning](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Instruct_Me_More_Random_Prompting_for_Visual_In-Context_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Jackieam/InMeMo?style=flat)](https://github.com/Jackieam/InMeMo) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_Instruct_Me_More_Random_Prompting_for_Visual_In-Context_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03648-b31b1b.svg)](http://arxiv.org/abs/2311.03648) | :heavy_minus_sign: |
| [SimA: Simple Softmax-Free Attention for Vision Transformers](https://openaccess.thecvf.com/content/WACV2024/html/Koohpayegani_SimA_Simple_Softmax-Free_Attention_for_Vision_Transformers_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/UCDvision/sima?style=flat)](https://github.com/UCDvision/sima) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Koohpayegani_SimA_Simple_Softmax-Free_Attention_for_Vision_Transformers_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.08898-b31b1b.svg)](http://arxiv.org/abs/2206.08898) | :heavy_minus_sign: |
| [Guided Cluster Aggregation: A Hierarchical Approach to Generalized Category Discovery](https://openaccess.thecvf.com/content/WACV2024/html/Otholt_Guided_Cluster_Aggregation_A_Hierarchical_Approach_to_Generalized_Category_Discovery_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/J-L-O/guided-cluster-aggregation?style=flat)](https://github.com/J-L-O/guided-cluster-aggregation) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Otholt_Guided_Cluster_Aggregation_A_Hierarchical_Approach_to_Generalized_Category_Discovery_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Hardware Aware Evolutionary Neural Architecture Search using Representation Similarity Metric](https://openaccess.thecvf.com/content/WACV2024/html/Sinha_Hardware_Aware_Evolutionary_Neural_Architecture_Search_Using_Representation_Similarity_Metric_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sinha_Hardware_Aware_Evolutionary_Neural_Architecture_Search_Using_Representation_Similarity_Metric_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03923-b31b1b.svg)](http://arxiv.org/abs/2311.03923) | :heavy_minus_sign: |
| [Using Early Readouts to Mediate Featural Bias in Distillation](https://openaccess.thecvf.com/content/WACV2024/html/Tiwari_Using_Early_Readouts_To_Mediate_Featural_Bias_in_Distillation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tiwari_Using_Early_Readouts_To_Mediate_Featural_Bias_in_Distillation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.18590-b31b1b.svg)](http://arxiv.org/abs/2310.18590) | :heavy_minus_sign: |
| Gradient Coreset for Federated Learning |  |  |  |
| Revisiting Token Pruning for Object Detection and Instance Segmentation |  |  |  |
| LatentDR: Improving Model Generalization through Sample-Aware Latent Degradation and Restoration |  |  |  |
| Fixing Overconfidence in Dynamic Neural Networks |  |  |  |
| Empowering Unsupervised Domain Adaptation with Large-Scale Pre-Trained Vision-Language Models |  |  |  |
| pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time Adaptation |  |  |  |
| [Torque based Structured Pruning for Deep Neural Network](https://openaccess.thecvf.com/content/WACV2024/html/Gupta_Torque_Based_Structured_Pruning_for_Deep_Neural_Network_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gupta_Torque_Based_Structured_Pruning_for_Deep_Neural_Network_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| Meta-Learned Attribute Self-Interaction Network for Continual and Generalized Zero-Shot Learning |  |  |  |
| Letting 3D Guide the Way: 3D Guided 2D Few-Shot Image Classification |  |  |  |
| Robust Learning via Conditional Prevalence Adjustment |  |  |  |
| Learning to Compose SuperWeights for Neural Parameter Allocation Search |  |  |  |
| Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where |  |  |  |
| Critical Gap between Generalization Error and Empirical Error in Active Learning |  |  |  |
| Appearance-based Curriculum for Semi-Supervised Learning with Multi-Angle Unlabeled Data |  |  |  |
| Domain Generalisation via Risk Distribution Matching |  |  |  |
| MixtureGrowth: Growing Neural Networks by Recombining Learned Parameters |  |  |  |
| Increasing Biases Can Be more Efficient than Increasing Weights |  |  |  |
| Deep Subdomain Alignment for Cross-Domain Image Classification |  |  |  |
| Generalization by Adaptation: Diffusion-based Domain Extension for Domain-Generalized Semantic Segmentation |  |  |  |
| Kaizen: Practical Self-Supervised Continual Learning with Continual Fine-Tuning |  |  |  |
| Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder: Theoretical and Empirical Insights |  |  |  |
| CycleCL: Self-Supervised Learning for Periodic Videos |  |  |  |
| TEXTRON: Weakly Supervised Multilingual Text Detection through Data Programming |  |  |  |
| Beyond Active Learning: Leveraging the Full Potential of Human Interaction via Auto-Labeling, Human Correction, and Human Verification |  |  |  |
