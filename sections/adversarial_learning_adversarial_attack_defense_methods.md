# WACV-2024-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/3d_cv.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/biometrics_face_gesture_body_pose.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Adversarial Learning, Adversarial Attack & Defense Methods

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Adversarial Likelihood Estimation with One-Way Flows |  |  |  |
| NCIS: Neural Contextual Iterative Smoothing for Purifying Adversarial Perturbations |  |  |  |
| On the Fly Neural Style Smoothing for Risk-Averse Domain Generalization |  |  |  |
| D4: Detection of Adversarial Diffusion Deepfakes using Disjoint Ensembles |  |  |  |
| Army of Thieves: Enhancing Black-Box Model Extraction via Ensemble based Sample Selection |  |  |  |
| Assist is Just as Important as the Goal: Image Resurfacing to aid Model's Robust Prediction |  |  |  |
| CLIPAG: Towards Generator-Free Text-to-Image Generation |  |  |  |
| Defending Object Detection Models Against Image Distortions |  |  |  |
| ATS: Adaptive Temperature Scaling for Enhancing Out-of-Distribution Detection Methods |  |  |  |
| A Closer Look at Robustness of Vision Transformers to Backdoor Attacks |  |  |  |
| Maximum Knowledge Orthogonality Reconstruction with Gradients in Federated Learning |  |  |  |
| Learning to Generate Training Datasets for Robust Semantic Segmentation |  |  |  |
| Uncertainty-Weighted Loss Functions for Improved Adversarial Attacks on Semantic Segmentation |  |  |  |
| Natural Light can also be Dangerous: Traffic Sign Misinterpretation Under Adversarial Natural Light Attacks |  |  |  |
| Diffusion Models Meet Image Counter-Forensics |  |  |  |
| Discriminator-Free Unsupervised Domain Adaptation for Multi-Label Image Classification |  |  |  |
| Few-Shot Generative Model for Skeleton-based Human Action Synthesis using Cross-Domain Adversarial Learning |  |  |  |
| Mixing Gradients in Neural Networks as a Strategy to Enhance Privacy in Federated Learning |  |  |  |
| Neural Style Protection: Counteracting Unauthorized Neural Style Transfer |  |  |  |
| Exploring Adversarial Robustness of Vision Transformers in the Spectral Perspective |  |  |  |
| Hard-Label based Small Query Black-Box Adversarial Attack |  |  |  |
| Simple Post-Training Robustness using Test Time Augmentations and Random Forest |  |  |  |
