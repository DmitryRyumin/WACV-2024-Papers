# WACVW-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/2024/workshops/w_rw_s.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/2024/workshops/w_pretraining.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Image / Video / Audio Quality in Computer Vision and Generative AI

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [RealPixVSR: Pixel-Level Visual Representation Informed Super-Resolution of Real-World Videos](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Park_RealPixVSR_Pixel-Level_Visual_Representation_Informed_Super-Resolution_of_Real-World_Videos_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Park_RealPixVSR_Pixel-Level_Visual_Representation_Informed_Super-Resolution_of_Real-World_Videos_WACVW_2024_paper.pdf) | :heavy_minus_sign: |
| [HIDRO-VQA: High Dynamic Range Oracle for Video Quality Assessment](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Saini_HIDRO-VQA_High_Dynamic_Range_Oracle_for_Video_Quality_Assessment_WACVW_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/avinabsaha/HIDRO-VQA?style=flat)](https://github.com/avinabsaha/HIDRO-VQA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Saini_HIDRO-VQA_High_Dynamic_Range_Oracle_for_Video_Quality_Assessment_WACVW_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.11059-b31b1b.svg)](http://arxiv.org/abs/2311.11059) | :heavy_minus_sign: |
| [Consolidating Separate Degradations Model via Weights Fusion and Distillation](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Daultani_Consolidating_Separate_Degradations_Model_via_Weights_Fusion_and_Distillation_WACVW_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/dineshdaultani/FusionDistill?style=flat)](https://github.com/dineshdaultani/FusionDistill) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Daultani_Consolidating_Separate_Degradations_Model_via_Weights_Fusion_and_Distillation_WACVW_2024_paper.pdf) | :heavy_minus_sign: |
| [DeepLIR: Attention-based Approach for Mask-based Lensless Image Reconstruction](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Poudel_DeepLIR_Attention-Based_Approach_for_Mask-Based_Lensless_Image_Reconstruction_WACVW_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/arpanpoudel/lenslessimaging?style=flat)](https://github.com/arpanpoudel/lenslessimaging) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Poudel_DeepLIR_Attention-Based_Approach_for_Mask-Based_Lensless_Image_Reconstruction_WACVW_2024_paper.pdf) | :heavy_minus_sign: |
| [Noise-Free Audio Signal Processing in Noisy Environment: A Hardware and Algorithm Solution](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Feng_Noise-Free_Audio_Signal_Processing_in_Noisy_Environment_A_Hardware_and_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Feng_Noise-Free_Audio_Signal_Processing_in_Noisy_Environment_A_Hardware_and_WACVW_2024_paper.pdf) | :heavy_minus_sign: |
| [A Lightweight Generalizable Evaluation and Enhancement Framework for Generative Models and Generated Samples](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Zhao_A_Lightweight_Generalizable_Evaluation_and_Enhancement_Framework_for_Generative_Models_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Zhao_A_Lightweight_Generalizable_Evaluation_and_Enhancement_Framework_for_Generative_Models_WACVW_2024_paper.pdf) | :heavy_minus_sign: |
| [Impact of Blur and Resolution on Demographic Disparities in 1-to-Many Facial Identification](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Bhatta_Impact_of_Blur_and_Resolution_on_Demographic_Disparities_in_1-to-Many_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Bhatta_Impact_of_Blur_and_Resolution_on_Demographic_Disparities_in_1-to-Many_WACVW_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.04447-b31b1b.svg)](http://arxiv.org/abs/2309.04447) | :heavy_minus_sign: |
| [Generating Point Cloud Augmentations via Class-Conditioned Diffusion Model](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Sharma_Generating_Point_Cloud_Augmentations_via_Class-Conditioned_Diffusion_Model_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Sharma_Generating_Point_Cloud_Augmentations_via_Class-Conditioned_Diffusion_Model_WACVW_2024_paper.pdf) | :heavy_minus_sign: |
| [Perceptual Synchronization Scoring of Dubbed Content using Phoneme-Viseme Agreement](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Gupta_Perceptual_Synchronization_Scoring_of_Dubbed_Content_Using_Phoneme-Viseme_Agreement_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Gupta_Perceptual_Synchronization_Scoring_of_Dubbed_Content_Using_Phoneme-Viseme_Agreement_WACVW_2024_paper.pdf) | :heavy_minus_sign: |
| [AutoCaCoNet: Automatic Cartoon Colorization Network using Self-Attention GAN, Segmentation, and Color Correction](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Lee_AutoCaCoNet_Automatic_Cartoon_Colorization_Network_Using_Self-Attention_GAN_Segmentation_and_WACVW_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/dxlabskku/AutoCaCoNet?style=flat)](https://github.com/dxlabskku/AutoCaCoNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Lee_AutoCaCoNet_Automatic_Cartoon_Colorization_Network_Using_Self-Attention_GAN_Segmentation_and_WACVW_2024_paper.pdf) | :heavy_minus_sign: |
| [Enhancing Surveillance Camera FOV Quality via Semantic Line Detection and Classification with Deep Hough Transform](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Freeman_Enhancing_Surveillance_Camera_FOV_Quality_via_Semantic_Line_Detection_and_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Freeman_Enhancing_Surveillance_Camera_FOV_Quality_via_Semantic_Line_Detection_and_WACVW_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.09515-b31b1b.svg)](http://arxiv.org/abs/2401.09515) | :heavy_minus_sign: |
| [A Diffusion-based Method for Multi-Turn Compositional Image Generation](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Wang_A_Diffusion-Based_Method_for_Multi-Turn_Compositional_Image_Generation_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Wang_A_Diffusion-Based_Method_for_Multi-Turn_Compositional_Image_Generation_WACVW_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.02192-b31b1b.svg)](http://arxiv.org/abs/2304.02192) | :heavy_minus_sign: |
| [Inflation with Diffusion: Efficient Temporal Adaptation for Text-to-Video Super-Resolution](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Yuan_Inflation_With_Diffusion_Efficient_Temporal_Adaptation_for_Text-to-Video_Super-Resolution_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Yuan_Inflation_With_Diffusion_Efficient_Temporal_Adaptation_for_Text-to-Video_Super-Resolution_WACVW_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.10404-b31b1b.svg)](http://arxiv.org/abs/2401.10404) | :heavy_minus_sign: |
| [Super Efficient Neural Network for Compression Artifacts Reduction and Super Resolution](https://openaccess.thecvf.com/content/WACV2024W/VAQ/html/Ma_Super_Efficient_Neural_Network_for_Compression_Artifacts_Reduction_and_Super_WACVW_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024W/VAQ/papers/Ma_Super_Efficient_Neural_Network_for_Compression_Artifacts_Reduction_and_Super_WACVW_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.14641-b31b1b.svg)](http://arxiv.org/abs/2401.14641) | :heavy_minus_sign: |
