# WACV-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/2024/main/structural_engineering_civil_engineering.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/2024/workshops/tutorials.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Virtual / Augmented Reality

![Section Papers](https://img.shields.io/badge/Section%20Papers-7-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-5-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-7-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Leveraging Next-Active Objects for Context-Aware Anticipation in Egocentric Videos](https://openaccess.thecvf.com/content/WACV2024/html/Thakur_Leveraging_Next-Active_Objects_for_Context-Aware_Anticipation_in_Egocentric_Videos_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sanketsans.github.io/leverage-next-active-object-action-anticipation.html) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Thakur_Leveraging_Next-Active_Objects_for_Context-Aware_Anticipation_in_Egocentric_Videos_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.08303-b31b1b.svg)](http://arxiv.org/abs/2308.08303) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=AYqan2h5SV0) |
| [Volumetric Disentanglement for 3D Scene Manipulation](https://openaccess.thecvf.com/content/WACV2024/html/Benaim_Volumetric_Disentanglement_for_3D_Scene_Manipulation_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sagiebenaim.github.io/volumetric-disentanglement/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Benaim_Volumetric_Disentanglement_for_3D_Scene_Manipulation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.02776-b31b1b.svg)](http://arxiv.org/abs/2206.02776) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=9WTMPPjrShE) |
| [StyleAvatar: Stylizing Animatable Head Avatars](https://openaccess.thecvf.com/content/WACV2024/html/Perez_StyleAvatar_Stylizing_Animatable_Head_Avatars_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Perez_StyleAvatar_Stylizing_Animatable_Head_Avatars_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m0_jjBchn9w) |
| [Show Your Face: Restoring Complete Facial Images from Partial Observations for VR Meeting](https://openaccess.thecvf.com/content/WACV2024/html/Chen_Show_Your_Face_Restoring_Complete_Facial_Images_From_Partial_Observations_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_Show_Your_Face_Restoring_Complete_Facial_Images_From_Partial_Observations_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=2PqptkIDkuI) |
| [PressureVision++: Estimating Fingertip Pressure from Diverse RGB Images](https://openaccess.thecvf.com/content/WACV2024/html/Grady_PressureVision_Estimating_Fingertip_Pressure_From_Diverse_RGB_Images_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://pressurevision.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/pgrady3/pressurevision2?style=flat)](https://github.com/pgrady3/pressurevision2) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Grady_PressureVision_Estimating_Fingertip_Pressure_From_Diverse_RGB_Images_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.02310-b31b1b.svg)](http://arxiv.org/abs/2301.02310) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oJ0TPRDVo_o) |
| [A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth Draping](https://openaccess.thecvf.com/content/WACV2024/html/Laczko_A_Generative_Multi-Resolution_Pyramid_and_Normal-Conditioning_3D_Cloth_Draping_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://hunorlaczko.github.io/projects/pyramid-drape/) <br /> [![GitHub](https://img.shields.io/github/stars/HunorLaczko/pyramid-drape?style=flat)](https://github.com/HunorLaczko/pyramid-drape) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Laczko_A_Generative_Multi-Resolution_Pyramid_and_Normal-Conditioning_3D_Cloth_Draping_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.02700-b31b1b.svg)](http://arxiv.org/abs/2311.02700) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=L5mEUn7xqDs) |
| [Stereo Matching in Time: 100+ FPS Video Stereo Matching for Extended Reality](https://openaccess.thecvf.com/content/WACV2024/html/Cheng_Stereo_Matching_in_Time_100_FPS_Video_Stereo_Matching_for_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Cheng_Stereo_Matching_in_Time_100_FPS_Video_Stereo_Matching_for_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.04183-b31b1b.svg)](http://arxiv.org/abs/2309.04183) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=e9_bTDhuMvU) |
