# WACV-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/2024/main/oral_iv_ru_ll_pv.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Machine Learning: Architectures, Formulations, Algorithms

![Section Papers](https://img.shields.io/badge/Section%20Papers-12-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-9-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-6-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-9-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Asymmetric Image Retrieval with Cross Model Compatible Ensembles](https://openaccess.thecvf.com/content/WACV2024/html/Shoshan_Asymmetric_Image_Retrieval_With_Cross_Model_Compatible_Ensembles_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shoshan_Asymmetric_Image_Retrieval_With_Cross_Model_Compatible_Ensembles_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.17531-b31b1b.svg)](http://arxiv.org/abs/2303.17531) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jcVsshnciEo) |
| [Cross-Feature Contrastive Loss for Decentralized Deep Learning on Heterogeneous Data](https://openaccess.thecvf.com/content/WACV2024/html/Aketi_Cross-Feature_Contrastive_Loss_for_Decentralized_Deep_Learning_on_Heterogeneous_Data_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Aketi_Cross-Feature_Contrastive_Loss_for_Decentralized_Deep_Learning_on_Heterogeneous_Data_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.15890-b31b1b.svg)](http://arxiv.org/abs/2310.15890) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=sqjuLCQl75c) |
| [Learning Generalizable Perceptual Representations for Data-Efficient No-Reference Image Quality Assessment](https://openaccess.thecvf.com/content/WACV2024/html/Srinath_Learning_Generalizable_Perceptual_Representations_for_Data-Efficient_No-Reference_Image_Quality_Assessment_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/suhas-srinath/GRepQ?style=flat)](https://github.com/suhas-srinath/GRepQ) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Srinath_Learning_Generalizable_Perceptual_Representations_for_Data-Efficient_No-Reference_Image_Quality_Assessment_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.04838-b31b1b.svg)](http://arxiv.org/abs/2312.04838) | :heavy_minus_sign: |
| [Location-Aware Self-Supervised Transformers for Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Caron_Location-Aware_Self-Supervised_Transformers_for_Semantic_Segmentation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Caron_Location-Aware_Self-Supervised_Transformers_for_Semantic_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.02400-b31b1b.svg)](http://arxiv.org/abs/2212.02400) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Uok3MRYuvYc) |
| [Robust Feature Learning and Global Variance-Driven Classifier Alignment for Long-Tail Class Incremental Learning](https://openaccess.thecvf.com/content/WACV2024/html/Kalla_Robust_Feature_Learning_and_Global_Variance-Driven_Classifier_Alignment_for_Long-Tail_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/JAYATEJAK/GVAlign?style=flat)](https://github.com/JAYATEJAK/GVAlign) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kalla_Robust_Feature_Learning_and_Global_Variance-Driven_Classifier_Alignment_for_Long-Tail_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.01227-b31b1b.svg)](http://arxiv.org/abs/2311.01227) | :heavy_minus_sign: |
| [Wino Vidi Vici: Conquering Numerical Instability of 8-Bit Winograd Convolution for Accurate Inference Acceleration on Edge](https://openaccess.thecvf.com/content/WACV2024/html/Mori_Wino_Vidi_Vici_Conquering_Numerical_Instability_of_8-Bit_Winograd_Convolution_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Mori_Wino_Vidi_Vici_Conquering_Numerical_Instability_of_8-Bit_Winograd_Convolution_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Data-Centric Debugging: Mitigating Model Failures via Targeted Image Retrieval](https://openaccess.thecvf.com/content/WACV2024/html/Singla_Data-Centric_Debugging_Mitigating_Model_Failures_via_Targeted_Image_Retrieval_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Singla_Data-Centric_Debugging_Mitigating_Model_Failures_via_Targeted_Image_Retrieval_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aelq9I7zaxc) |
| [Distortion-Disentangled Contrastive Learning](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Distortion-Disentangled_Contrastive_Learning_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Distortion-Disentangled_Contrastive_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.05066-b31b1b.svg)](http://arxiv.org/abs/2303.05066) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zRYAQWVpn40) |
| [GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation](https://openaccess.thecvf.com/content/WACV2024/html/Xu_GTP-ViT_Efficient_Vision_Transformers_via_Graph-Based_Token_Propagation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Ackesnal/GTP-ViT?style=flat)](https://github.com/Ackesnal/GTP-ViT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Xu_GTP-ViT_Efficient_Vision_Transformers_via_Graph-Based_Token_Propagation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03035-b31b1b.svg)](http://arxiv.org/abs/2311.03035) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=iHmcodXeMf0) |
| [SequenceMatch: Revisiting the Design of Weak-Strong Augmentations for Semi-Supervised Learning](https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_SequenceMatch_Revisiting_the_Design_of_Weak-Strong_Augmentations_for_Semi-Supervised_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/beandkay/SequenceMatch?style=flat)](https://github.com/beandkay/SequenceMatch) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nguyen_SequenceMatch_Revisiting_the_Design_of_Weak-Strong_Augmentations_for_Semi-Supervised_Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.15787-b31b1b.svg)](http://arxiv.org/abs/2310.15787) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JQCG9PSJWPw) |
| [Stochastic Binary Network for Universal Domain Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Jain_Stochastic_Binary_Network_for_Universal_Domain_Adaptation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/saurabhkjain7/STUN?style=flat)](https://github.com/saurabhkjain7/STUN)  | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Jain_Stochastic_Binary_Network_for_Universal_Domain_Adaptation_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ntgfBoGRT1c) |
| [PECoP: Parameter Efficient Continual Pretraining for Action Quality Assessment](https://openaccess.thecvf.com/content/WACV2024/html/Dadashzadeh_PECoP_Parameter_Efficient_Continual_Pretraining_for_Action_Quality_Assessment_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Plrbear/PECoP?style=flat)](https://github.com/Plrbear/PECoP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Dadashzadeh_PECoP_Parameter_Efficient_Continual_Pretraining_for_Action_Quality_Assessment_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.07603-b31b1b.svg)](http://arxiv.org/abs/2311.07603) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_P5JpO465EQ) |
