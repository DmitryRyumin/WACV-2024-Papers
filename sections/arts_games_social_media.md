# WACV-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/animals_insects.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/autonomous_driving.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Arts / Games / Social Media

![Section Papers](https://img.shields.io/badge/Section%20Papers-15-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-10-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-6-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-12-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [The Paleographer's Eye ex machina: Using Computer Vision to Assist Humanists in Scribal Hand Identification](https://openaccess.thecvf.com/content/WACV2024/html/Grieggs_The_Paleographers_Eye_ex_machina_Using_Computer_Vision_To_Assist_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Grieggs_The_Paleographers_Eye_ex_machina_Using_Computer_Vision_To_Assist_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Let the Beat Follow You - Creating Interactive Drum Sounds from Body Rhythm](https://openaccess.thecvf.com/content/WACV2024/html/Liu_Let_the_Beat_Follow_You_-_Creating_Interactive_Drum_Sounds_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Let_the_Beat_Follow_You_-_Creating_Interactive_Drum_Sounds_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8vvlv0MuGu8) |
| [Interactive Segmentation for Diverse Gesture Types without Context](https://openaccess.thecvf.com/content/WACV2024/html/Myers-Dean_Interactive_Segmentation_for_Diverse_Gesture_Types_Without_Context_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/joshmyersdean/dig?style=flat)](https://github.com/joshmyersdean/dig) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Myers-Dean_Interactive_Segmentation_for_Diverse_Gesture_Types_Without_Context_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.10518-b31b1b.svg)](https://arxiv.org/abs/2307.10518) | :heavy_minus_sign: |
| [SemST: Semantically Consistent Multi-Scale Image Translation via Structure-Texture Alignment](https://openaccess.thecvf.com/content/WACV2024/html/Zhao_SemST_Semantically_Consistent_Multi-Scale_Image_Translation_via_Structure-Texture_Alignment_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhao_SemST_Semantically_Consistent_Multi-Scale_Image_Translation_via_Structure-Texture_Alignment_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.04995-b31b1b.svg)](https://arxiv.org/abs/2310.04995) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=t2YZxvSnzCY) |
| [Visual Narratives: Large-Scale Hierarchical Classification of Art-Historical Images](https://openaccess.thecvf.com/content/WACV2024/html/Springstein_Visual_Narratives_Large-Scale_Hierarchical_Classification_of_Art-Historical_Images_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Springstein_Visual_Narratives_Large-Scale_Hierarchical_Classification_of_Art-Historical_Images_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aLHBX0ZOLvo) |
| [Composite Diffusion: whole â‰¥ Î£parts](https://openaccess.thecvf.com/content/WACV2024/html/Jamwal_Composite_Diffusion_whole__Sparts_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Jamwal_Composite_Diffusion_whole__Sparts_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.13720-b31b1b.svg)](https://arxiv.org/abs/2307.13720) | :heavy_minus_sign: |
| [C-CLIP: Contrastive Image-Text Encoders to Close the Descriptive-Commentative Gap](https://openaccess.thecvf.com/content/WACV2024/html/Theisen_C-CLIP_Contrastive_Image-Text_Encoders_To_Close_the_Descriptive-Commentative_Gap_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Theisen_C-CLIP_Contrastive_Image-Text_Encoders_To_Close_the_Descriptive-Commentative_Gap_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03921-b31b1b.svg)](https://arxiv.org/abs/2309.03921) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f0nYR7CNRiE) |
| [CAD - Contextual Multi-Modal Alignment for Dynamic AVQA](https://openaccess.thecvf.com/content/WACV2024/html/Nadeem_CAD_-_Contextual_Multi-Modal_Alignment_for_Dynamic_AVQA_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nadeem_CAD_-_Contextual_Multi-Modal_Alignment_for_Dynamic_AVQA_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16754-b31b1b.svg)](https://arxiv.org/abs/2310.16754) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zMLPB2hrnvA) |
| [ArcAid: Analysis of Archaeological Artifacts using Drawings](https://openaccess.thecvf.com/content/WACV2024/html/Hayon_ArcAid_Analysis_of_Archaeological_Artifacts_Using_Drawings_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cgm.technion.ac.il/arcaid/) <br /> [![GitHub](https://img.shields.io/github/stars/offry/Arc-Aid?style=flat)](https://github.com/offry/Arc-Aid) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hayon_ArcAid_Analysis_of_Archaeological_Artifacts_Using_Drawings_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.09480-b31b1b.svg)](https://arxiv.org/abs/2211.09480) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=b12yIvt32Yg) |
| [Movie Genre Classification by Language Augmentation and Shot Sampling](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Movie_Genre_Classification_by_Language_Augmentation_and_Shot_Sampling_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Zhongping-Zhang/Movie-CLIP?style=flat)](https://github.com/Zhongping-Zhang/Movie-CLIP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_Movie_Genre_Classification_by_Language_Augmentation_and_Shot_Sampling_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2203.13281-b31b1b.svg)](https://arxiv.org/abs/2203.13281) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aQHQVnEcwe4) |
| [Few-Shot Event Classification in Images using Knowledge Graphs for Prompting](https://openaccess.thecvf.com/content/WACV2024/html/Tahmasebzadeh_Few-Shot_Event_Classification_in_Images_Using_Knowledge_Graphs_for_Prompting_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/TIBHannover/PromptImageEvent?style=flat)](https://github.com/TIBHannover/PromptImageEvent) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tahmasebzadeh_Few-Shot_Event_Classification_in_Images_Using_Knowledge_Graphs_for_Prompting_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=A-gHA58gLIo) |
| [Towards Diverse and Consistent Typography Generation](https://openaccess.thecvf.com/content/WACV2024/html/Shimoda_Towards_Diverse_and_Consistent_Typography_Generation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shimoda_Towards_Diverse_and_Consistent_Typography_Generation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02099-b31b1b.svg)](https://arxiv.org/abs/2309.02099) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ix5dZyh_BDA) |
| [NeRFEditor: Differentiable Style Decomposition for 3D Scene Editing](https://openaccess.thecvf.com/content/WACV2024/html/Sun_NeRFEditor_Differentiable_Style_Decomposition_for_3D_Scene_Editing_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Chuny1/NeRFEditor?style=flat)](https://github.com/Chuny1/NeRFEditor) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Sun_NeRFEditor_Differentiable_Style_Decomposition_for_3D_Scene_Editing_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.03848-b31b1b.svg)](https://arxiv.org/abs/2212.03848) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RoAtNc0ibbQ) |
| [FastCLIPstyler: Optimisation-Free Text-based Image Style Transfer using Style Representations](https://openaccess.thecvf.com/content/WACV2024/html/Suresh_FastCLIPstyler_Optimisation-Free_Text-Based_Image_Style_Transfer_Using_Style_Representations_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Suresh_FastCLIPstyler_Optimisation-Free_Text-Based_Image_Style_Transfer_Using_Style_Representations_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.03461-b31b1b.svg)](https://arxiv.org/abs/2210.03461) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IR-VHSiEezw) |
| [ArtQuest: Countering Hidden Language Biases in ArtVQA](https://openaccess.thecvf.com/content/WACV2024/html/Bleidt_ArtQuest_Countering_Hidden_Language_Biases_in_ArtVQA_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/bletib/artquest?style=flat)](https://github.com/bletib/artquest) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bleidt_ArtQuest_Countering_Hidden_Language_Biases_in_ArtVQA_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_Ne9dq9AjBw) |
