# WACV-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/ml_afa.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/adversarial_learning_adversarial_attack_defense_methods.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## 3D Computer Vision

![Section Papers](https://img.shields.io/badge/Section%20Papers-73-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-46-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-25-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-68-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Task-Oriented Human-Object Interactions Generation with Implicit Neural Representations](https://openaccess.thecvf.com/content/WACV2024/html/Li_Task-Oriented_Human-Object_Interactions_Generation_With_Implicit_Neural_Representations_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Li_Task-Oriented_Human-Object_Interactions_Generation_With_Implicit_Neural_Representations_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13129-b31b1b.svg)](http://arxiv.org/abs/2303.13129) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mm4hnbxwZgA) |
| [Depth from Asymmetric Frame-Event Stereo: A Divide-and-Conquer Approach](https://openaccess.thecvf.com/content/WACV2024/html/Chen_Depth_From_Asymmetric_Frame-Event_Stereo_A_Divide-and-Conquer_Approach_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_Depth_From_Asymmetric_Frame-Event_Stereo_A_Divide-and-Conquer_Approach_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=o4i1271gUY0) |
| [TriPlaneNet: An Encoder for EG3D Inversion](https://openaccess.thecvf.com/content/WACV2024/html/Bhattarai_TriPlaneNet_An_Encoder_for_EG3D_Inversion_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://anantarb.github.io/triplanenet) <br /> [![GitHub](https://img.shields.io/github/stars/anantarb/triplanenet?style=flat)](https://github.com/anantarb/triplanenet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bhattarai_TriPlaneNet_An_Encoder_for_EG3D_Inversion_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13497-b31b1b.svg)](http://arxiv.org/abs/2303.13497) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=gtir4PNDYD4) |
| [Attentive Prototypes for Source-Free Unsupervised Domain Adaptive 3D Object Detection](https://openaccess.thecvf.com/content/WACV2024/html/Hegde_Attentive_Prototypes_for_Source-Free_Unsupervised_Domain_Adaptive_3D_Object_Detection_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/deeptibhegde/AttentivePrototypeSFUDA?style=flat)](https://github.com/deeptibhegde/AttentivePrototypeSFUDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hegde_Attentive_Prototypes_for_Source-Free_Unsupervised_Domain_Adaptive_3D_Object_Detection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2111.15656-b31b1b.svg)](http://arxiv.org/abs/2111.15656) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=MpsJFc_r-Sw) |
| [FIRe: Fast Inverse Rendering using Directional and Signed Distance Functions](https://openaccess.thecvf.com/content/WACV2024/html/Yenamandra_FIRe_Fast_Inverse_Rendering_Using_Directional_and_Signed_Distance_Functions_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cvg.cit.tum.de/research/geometry/fire) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yenamandra_FIRe_Fast_Inverse_Rendering_Using_Directional_and_Signed_Distance_Functions_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2203.16284-b31b1b.svg)](http://arxiv.org/abs/2203.16284) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Qj0ymDlRYZs) |
| [A Generic and Flexible Regularization Framework for NeRFs](https://openaccess.thecvf.com/content/WACV2024/html/Ehret_A_Generic_and_Flexible_Regularization_Framework_for_NeRFs_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Ehret_A_Generic_and_Flexible_Regularization_Framework_for_NeRFs_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=G0be1gvg1gg) |
| [Multi-View 3D Object Reconstruction and Uncertainty Modelling with Neural Shape Prior](https://openaccess.thecvf.com/content/WACV2024/html/Liao_Multi-View_3D_Object_Reconstruction_and_Uncertainty_Modelling_With_Neural_Shape_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liao_Multi-View_3D_Object_Reconstruction_and_Uncertainty_Modelling_With_Neural_Shape_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.11739-b31b1b.svg)](http://arxiv.org/abs/2306.11739) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lrT5r8u_aww) |
| [Neural Textured Deformable Meshes for Robust Analysis-by-Synthesis](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Neural_Textured_Deformable_Meshes_for_Robust_Analysis-by-Synthesis_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Neural_Textured_Deformable_Meshes_for_Robust_Analysis-by-Synthesis_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.00118-b31b1b.svg)](http://arxiv.org/abs/2306.00118) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=qZVRJiiqLE0) |
| [Ray Deformation Networks for Novel View Synthesis of Refractive Objects](https://openaccess.thecvf.com/content/WACV2024/html/Deng_Ray_Deformation_Networks_for_Novel_View_Synthesis_of_Refractive_Objects_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Deng_Ray_Deformation_Networks_for_Novel_View_Synthesis_of_Refractive_Objects_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=zQ-j9EaD7aE) |
| [Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud](https://openaccess.thecvf.com/content/WACV2024/html/Henrich_Registered_and_Segmented_Deformable_Object_Reconstruction_From_a_Single_View_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Henrich_Registered_and_Segmented_Deformable_Object_Reconstruction_From_a_Single_View_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.07357-b31b1b.svg)](http://arxiv.org/abs/2311.07357) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Ir7GXjGWqtE) |
| [SupeRVol: Super-Resolution Shape and Reflectance Estimation in Inverse Volume Rendering](https://openaccess.thecvf.com/content/WACV2024/html/Brahimi_SupeRVol_Super-Resolution_Shape_and_Reflectance_Estimation_in_Inverse_Volume_Rendering_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Brahimi_SupeRVol_Super-Resolution_Shape_and_Reflectance_Estimation_in_Inverse_Volume_Rendering_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.04968-b31b1b.svg)](http://arxiv.org/abs/2212.04968) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3KpRB_fIoSo) |
| [RIMeshGNN: A Rotation-Invariant Graph Neural Network for Mesh Classification](https://openaccess.thecvf.com/content/WACV2024/html/Shakibajahromi_RIMeshGNN_A_Rotation-Invariant_Graph_Neural_Network_for_Mesh_Classification_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shakibajahromi_RIMeshGNN_A_Rotation-Invariant_Graph_Neural_Network_for_Mesh_Classification_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0s9Pp-1oLaI) |
| [OptFlow: Fast Optimization-based Scene Flow Estimation without Supervision](https://openaccess.thecvf.com/content/WACV2024/html/Ahuja_OptFlow_Fast_Optimization-Based_Scene_Flow_Estimation_Without_Supervision_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Ahuja_OptFlow_Fast_Optimization-Based_Scene_Flow_Estimation_Without_Supervision_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.02550-b31b1b.svg)](http://arxiv.org/abs/2401.02550) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=1eyvUmMqqYA) |
| [Point-DynRF: Point-based Dynamic Radiance Fields from a Monocular Video](https://openaccess.thecvf.com/content/WACV2024/html/Park_Point-DynRF_Point-Based_Dynamic_Radiance_Fields_From_a_Monocular_Video_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Park_Point-DynRF_Point-Based_Dynamic_Radiance_Fields_From_a_Monocular_Video_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.09647-b31b1b.svg)](http://arxiv.org/abs/2310.09647) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xRrHHHXrtN8) |
| [LensNeRF: Rethinking Volume Rendering based on Thin-Lens Camera Model](https://openaccess.thecvf.com/content/WACV2024/html/Kim_LensNeRF_Rethinking_Volume_Rendering_Based_on_Thin-Lens_Camera_Model_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_LensNeRF_Rethinking_Volume_Rendering_Based_on_Thin-Lens_Camera_Model_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Lii_0oiAKXY) |
| [Domain Adaptive 3D Shape Retrieval from Monocular Images](https://openaccess.thecvf.com/content/WACV2024/html/Pal_Domain_Adaptive_3D_Shape_Retrieval_From_Monocular_Images_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Pal_Domain_Adaptive_3D_Shape_Retrieval_From_Monocular_Images_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=p81NpFJMglU) |
| [HD-Fusion: Detailed Text-to-3D Generation Leveraging Multiple Noise Estimation](https://openaccess.thecvf.com/content/WACV2024/html/Wu_HD-Fusion_Detailed_Text-to-3D_Generation_Leveraging_Multiple_Noise_Estimation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wu_HD-Fusion_Detailed_Text-to-3D_Generation_Leveraging_Multiple_Noise_Estimation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.16183-b31b1b.svg)](http://arxiv.org/abs/2307.16183) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=3uPFCCaTIcQ) |
| [Sparse Convolutional Networks for Surface Reconstruction from Noisy Point Clouds](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Sparse_Convolutional_Networks_for_Surface_Reconstruction_From_Noisy_Point_Clouds_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Sparse_Convolutional_Networks_for_Surface_Reconstruction_From_Noisy_Point_Clouds_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RLBW3rJVzvg) |
| [Single Frame Semantic Segmentation using Multi-Modal Spherical Images](https://openaccess.thecvf.com/content/WACV2024/html/Guttikonda_Single_Frame_Semantic_Segmentation_Using_Multi-Modal_Spherical_Images_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/sguttikon/SFSS-MMSI?style=flat)](https://github.com/sguttikon/SFSS-MMSI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Guttikonda_Single_Frame_Semantic_Segmentation_Using_Multi-Modal_Spherical_Images_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.09369-b31b1b.svg)](http://arxiv.org/abs/2308.09369) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=n-_V-yJRIvE) |
| [Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting](https://openaccess.thecvf.com/content/WACV2024/html/Medina_Context-Based_Interpretable_Spatio-Temporal_Graph_Convolutional_Network_for_Human_Motion_Forecasting_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Medina_Context-Based_Interpretable_Spatio-Temporal_Graph_Convolutional_Network_for_Human_Motion_Forecasting_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=x3X7owVWXIc) |
| [GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo](https://openaccess.thecvf.com/content/WACV2024/html/Vats_GC-MVSNet_Multi-View_Multi-Scale_Geometrically-Consistent_Multi-View_Stereo_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/vkvats/GC-MVSNet?style=flat)](https://github.com/vkvats/GC-MVSNet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Vats_GC-MVSNet_Multi-View_Multi-Scale_Geometrically-Consistent_Multi-View_Stereo_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.19583-b31b1b.svg)](http://arxiv.org/abs/2310.19583) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RvgJoHZqsmo) |
| [SAM Fewshot Finetuning for Anatomical Segmentation in Medical Images](https://openaccess.thecvf.com/content/WACV2024/html/Xie_SAM_Fewshot_Finetuning_for_Anatomical_Segmentation_in_Medical_Images_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Xie_SAM_Fewshot_Finetuning_for_Anatomical_Segmentation_in_Medical_Images_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=dldQX3eywOs) |
| [MSCC: Multi-Scale Transformers for Camera Calibration](https://openaccess.thecvf.com/content/WACV2024/html/Song_MSCC_Multi-Scale_Transformers_for_Camera_Calibration_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Song_MSCC_Multi-Scale_Transformers_for_Camera_Calibration_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=8XLs7blQq9Y) |
| [A Geometry Loss Combination for 3D Human Pose Estimation](https://openaccess.thecvf.com/content/WACV2024/html/Matsune_A_Geometry_Loss_Combination_for_3D_Human_Pose_Estimation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Matsune_A_Geometry_Loss_Combination_for_3D_Human_Pose_Estimation_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=p7khqZyCwps) |
| [A Robust Diffusion Modeling Framework for Radar Camera 3D Object Detection](https://openaccess.thecvf.com/content/WACV2024/html/Wu_A_Robust_Diffusion_Modeling_Framework_for_Radar_Camera_3D_Object_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wu_A_Robust_Diffusion_Modeling_Framework_for_Radar_Camera_3D_Object_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PFzvCcYbGy0) |
| [WalkFormer: Point Cloud Completion via Guided Walks](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_WalkFormer_Point_Cloud_Completion_via_Guided_Walks_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_WalkFormer_Point_Cloud_Completion_via_Guided_Walks_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=eD6nFdJECWk) |
| [MGM-AE: Self-Supervised Learning on 3D Shape using Mesh Graph Masked Autoencoders](https://openaccess.thecvf.com/content/WACV2024/html/Yang_MGM-AE_Self-Supervised_Learning_on_3D_Shape_Using_Mesh_Graph_Masked_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yang_MGM-AE_Self-Supervised_Learning_on_3D_Shape_Using_Mesh_Graph_Masked_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fIkodIfGb6A) |
| [Unsupervised 3D Pose Estimation with Non-Rigid Structure-from-Motion Modeling](https://openaccess.thecvf.com/content/WACV2024/html/Ji_Unsupervised_3D_Pose_Estimation_With_Non-Rigid_Structure-From-Motion_Modeling_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Ji_Unsupervised_3D_Pose_Estimation_With_Non-Rigid_Structure-From-Motion_Modeling_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.10705-b31b1b.svg)](http://arxiv.org/abs/2308.10705) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fbch9djBYJM) |
| [Residual Graph Convolutional Network for Bird's-Eye-View Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Chen_Residual_Graph_Convolutional_Network_for_Birds-Eye-View_Semantic_Segmentation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_Residual_Graph_Convolutional_Network_for_Birds-Eye-View_Semantic_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.04044-b31b1b.svg)](http://arxiv.org/abs/2312.04044) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kcIH7Oc226E) |
| [3D Human Pose Estimation with Two-Step Mixed-Training Strategy](https://openaccess.thecvf.com/content/WACV2024/html/Wang_3D_Human_Pose_Estimation_With_Two-Step_Mixed-Training_Strategy_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_3D_Human_Pose_Estimation_With_Two-Step_Mixed-Training_Strategy_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=f7lphgSIUTk) |
| [RGB-D Mapping and Tracking in a Plenoxel Radiance Field](https://openaccess.thecvf.com/content/WACV2024/html/Teigen_RGB-D_Mapping_and_Tracking_in_a_Plenoxel_Radiance_Field_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ysus33/RGB-D_Plenoxel_Mapping_Tracking?style=flat)](https://github.com/ysus33/RGB-D_Plenoxel_Mapping_Tracking) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Teigen_RGB-D_Mapping_and_Tracking_in_a_Plenoxel_Radiance_Field_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.03404-b31b1b.svg)](http://arxiv.org/abs/2307.03404) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=WhhpoKa8aJ8) |
| [SOAP: Cross-Sensor Domain Adaptation for 3D Object Detection using Stationary Object Aggregation Pseudo-Labelling](https://openaccess.thecvf.com/content/WACV2024/html/Huang_SOAP_Cross-Sensor_Domain_Adaptation_for_3D_Object_Detection_Using_Stationary_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Huang_SOAP_Cross-Sensor_Domain_Adaptation_for_3D_Object_Detection_Using_Stationary_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.04230-b31b1b.svg)](http://arxiv.org/abs/2401.04230) | :heavy_minus_sign: |
| [BALF: Simple and Efficient Blur Aware Local Feature Detector](https://openaccess.thecvf.com/content/WACV2024/html/Zhao_BALF_Simple_and_Efficient_Blur_Aware_Local_Feature_Detector_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ericzzj1989.github.io/balf) <br /> [![GitHub](https://img.shields.io/github/stars/ericzzj1989/BALF?style=flat)](https://github.com/ericzzj1989/BALF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhao_BALF_Simple_and_Efficient_Blur_Aware_Local_Feature_Detector_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.14731-b31b1b.svg)](http://arxiv.org/abs/2211.14731) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=e6uDX_gKf-A) |
| [MACP: Efficient Model Adaptation for Cooperative Perception](https://openaccess.thecvf.com/content/WACV2024/html/Ma_MACP_Efficient_Model_Adaptation_for_Cooperative_Perception_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://purduedigitaltwin.github.io/MACP/) <br /> [![GitHub](https://img.shields.io/github/stars/PurdueDigitalTwin/MACP?style=flat)](https://github.com/PurdueDigitalTwin/MACP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Ma_MACP_Efficient_Model_Adaptation_for_Cooperative_Perception_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16870-b31b1b.svg)](http://arxiv.org/abs/2310.16870) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=6PfXbfo7Yb4) |
| [MAELi: Masked Autoencoder for Large-Scale LiDAR Point Clouds](https://openaccess.thecvf.com/content/WACV2024/html/Krispel_MAELi_Masked_Autoencoder_for_Large-Scale_LiDAR_Point_Clouds_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Krispel_MAELi_Masked_Autoencoder_for_Large-Scale_LiDAR_Point_Clouds_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.07207-b31b1b.svg)](http://arxiv.org/abs/2212.07207) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JGd4C5-gyfA) |
| [HDMNet: A Hierarchical Matching Network with Double Attention for Large-Scale Outdoor LiDAR Point Cloud Registration](https://openaccess.thecvf.com/content/WACV2024/html/Xue_HDMNet_A_Hierarchical_Matching_Network_With_Double_Attention_for_Large-Scale_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Xue_HDMNet_A_Hierarchical_Matching_Network_With_Double_Attention_for_Large-Scale_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.18874-b31b1b.svg)](http://arxiv.org/abs/2310.18874) | :heavy_minus_sign: |
| [SGRec3D: Self-Supervised 3D Scene Graph Learning via Object-Level Scene Reconstruction](https://openaccess.thecvf.com/content/WACV2024/html/Koch_SGRec3D_Self-Supervised_3D_Scene_Graph_Learning_via_Object-Level_Scene_Reconstruction_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://kochsebastian.com/sgrec3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Koch_SGRec3D_Self-Supervised_3D_Scene_Graph_Learning_via_Object-Level_Scene_Reconstruction_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.15702-b31b1b.svg)](http://arxiv.org/abs/2309.15702) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NcTd4LhhbnM) |
| [MPT: Mesh Pre-Training with Transformers for Human Pose and Mesh Reconstruction](https://openaccess.thecvf.com/content/WACV2024/html/Lin_MPT_Mesh_Pre-Training_With_Transformers_for_Human_Pose_and_Mesh_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lin_MPT_Mesh_Pre-Training_With_Transformers_for_Human_Pose_and_Mesh_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2211.13357-b31b1b.svg)](http://arxiv.org/abs/2211.13357) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=XRkOxGNgyQE) |
| [LInKs ''Lifting Independent Keypoints'' â€“ Partial Pose Lifting for Occlusion Handling with Improved Accuracy in 2D-3D Human Pose Estimation](https://openaccess.thecvf.com/content/WACV2024/html/Hardy_LInKs_Lifting_Independent_Keypoints_-_Partial_Pose_Lifting_for_Occlusion_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hardy_LInKs_Lifting_Independent_Keypoints_-_Partial_Pose_Lifting_for_Occlusion_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.07243-b31b1b.svg)](http://arxiv.org/abs/2309.07243) | :heavy_minus_sign: |
| [ECSIC: Epipolar Cross Attention for Stereo Image Compression](https://openaccess.thecvf.com/content/WACV2024/html/Wodlinger_ECSIC_Epipolar_Cross_Attention_for_Stereo_Image_Compression_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/mwoedlinger/ecsic?style=flat)](https://github.com/mwoedlinger/ecsic) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wodlinger_ECSIC_Epipolar_Cross_Attention_for_Stereo_Image_Compression_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.10284-b31b1b.svg)](http://arxiv.org/abs/2307.10284) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ss-3oGy0wmg) |
| [Robust Category-Level 3D Pose Estimation from Diffusion-Enhanced Synthetic Data](https://openaccess.thecvf.com/content/WACV2024/html/Yang_Robust_Category-Level_3D_Pose_Estimation_From_Diffusion-Enhanced_Synthetic_Data_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/YangYY06/synthetic_3d?style=flat)](https://github.com/YangYY06/synthetic_3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yang_Robust_Category-Level_3D_Pose_Estimation_From_Diffusion-Enhanced_Synthetic_Data_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xbS2UsiH6B4) |
| [Open-NeRF: Towards Open Vocabulary NeRF Decomposition](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_Open-NeRF_Towards_Open_Vocabulary_NeRF_Decomposition_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/haoz19/Open-NeRF?style=flat)](https://github.com/haoz19/Open-NeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_Open-NeRF_Towards_Open_Vocabulary_NeRF_Decomposition_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16383-b31b1b.svg)](http://arxiv.org/abs/2310.16383) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4_fv0DOO9cQ) |
| [HAMMER: Learning Entropy Maps to Create Accurate 3D Models in Multi-View Stereo](https://openaccess.thecvf.com/content/WACV2024/html/Weilharter_HAMMER_Learning_Entropy_Maps_To_Create_Accurate_3D_Models_in_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Weilharter_HAMMER_Learning_Entropy_Maps_To_Create_Accurate_3D_Models_in_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=VC6YCLeStLo) |
| [Polarimetric PatchMatch Multi-View Stereo](https://openaccess.thecvf.com/content/WACV2024/html/Zhao_Polarimetric_PatchMatch_Multi-View_Stereo_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://www.ok.sc.e.titech.ac.jp/res/PolarPMS/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhao_Polarimetric_PatchMatch_Multi-View_Stereo_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.07600-b31b1b.svg)](http://arxiv.org/abs/2311.07600) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=lq6QnKBPTAc) |
| [Solving the Plane-Sphere Ambiguity in Top-Down Structure-from-Motion](https://openaccess.thecvf.com/content/WACV2024/html/Haalck_Solving_the_Plane-Sphere_Ambiguity_in_Top-Down_Structure-From-Motion_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://top-down-sfm.cvmls.org/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Haalck_Solving_the_Plane-Sphere_Ambiguity_in_Top-Down_Structure-From-Motion_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jU9FtkDZu_s) |
| [Self-Annotated 3D Geometric Learning for Smeared Points Removal](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Self-Annotated_3D_Geometric_Learning_for_Smeared_Points_Removal_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/wangmiaowei/wacv2024_smearedremover?style=flat)](https://github.com/wangmiaowei/wacv2024_smearedremover) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Self-Annotated_3D_Geometric_Learning_for_Smeared_Points_Removal_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.09029-b31b1b.svg)](http://arxiv.org/abs/2311.09029) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KWLBUCTdif4) |
| [3D Face Style Transfer with a Hybrid Solution of NeRF and Mesh Rasterization](https://openaccess.thecvf.com/content/WACV2024/html/Feng_3D_Face_Style_Transfer_With_a_Hybrid_Solution_of_NeRF_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Feng_3D_Face_Style_Transfer_With_a_Hybrid_Solution_of_NeRF_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.13168-b31b1b.svg)](http://arxiv.org/abs/2311.13168) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=OzrjGQFZdG4) |
| [A Sequential Learning-based Approach for Monocular Human Performance Capture](https://openaccess.thecvf.com/content/WACV2024/html/Chen_A_Sequential_Learning-Based_Approach_for_Monocular_Human_Performance_Capture_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_A_Sequential_Learning-Based_Approach_for_Monocular_Human_Performance_Capture_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=JKgNqVef0dw) |
| [ScanEnts3D: Exploiting Phrase-to-3D-Object Correspondences for Improved Visio-Linguistic Models in 3D Scenes](https://openaccess.thecvf.com/content/WACV2024/html/Abdelreheem_ScanEnts3D_Exploiting_Phrase-to-3D-Object_Correspondences_for_Improved_Visio-Linguistic_Models_in_3D_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://scanents3d.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/ScanEnts3D/ScanEnts3D.github.io?style=flat)](https://github.com/ScanEnts3D/ScanEnts3D.github.io) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Abdelreheem_ScanEnts3D_Exploiting_Phrase-to-3D-Object_Correspondences_for_Improved_Visio-Linguistic_Models_in_3D_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2212.06250-b31b1b.svg)](http://arxiv.org/abs/2212.06250) | :heavy_minus_sign: |
| [Global Occlusion-Aware Transformer for Robust Stereo Matching](https://openaccess.thecvf.com/content/WACV2024/html/Liu_Global_Occlusion-Aware_Transformer_for_Robust_Stereo_Matching_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](http://www.ok.sc.e.titech.ac.jp/res/DeepSM/wacv2024.html) <br /> [![GitHub](https://img.shields.io/github/stars/Magicboomliu/GOAT?style=flat)](https://github.com/Magicboomliu/GOAT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_Global_Occlusion-Aware_Transformer_for_Robust_Stereo_Matching_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.14650-b31b1b.svg)](http://arxiv.org/abs/2312.14650) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=71JqEVLNg7w) |
| [MoRF: Mobile Realistic Fullbody Avatars from a Monocular Video](https://openaccess.thecvf.com/content/WACV2024/html/Bashirov_MoRF_Mobile_Realistic_Fullbody_Avatars_From_a_Monocular_Video_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bashirov_MoRF_Mobile_Realistic_Fullbody_Avatars_From_a_Monocular_Video_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.10275-b31b1b.svg)](http://arxiv.org/abs/2303.10275) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oCTA9BHl10Q) |
| [PointCT: Point Central Transformer Network for Weakly-Supervised Point Cloud Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Tran_PointCT_Point_Central_Transformer_Network_for_Weakly-Supervised_Point_Cloud_Semantic_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Tran_PointCT_Point_Central_Transformer_Network_for_Weakly-Supervised_Point_Cloud_Semantic_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=R4cmKznCTXI) |
| [Top-Down Beats Bottom-Up in 3D Instance Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Kolodiazhnyi_Top-Down_Beats_Bottom-Up_in_3D_Instance_Segmentation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/SamsungLabs/td3d?style=flat)](https://github.com/SamsungLabs/td3d) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kolodiazhnyi_Top-Down_Beats_Bottom-Up_in_3D_Instance_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.02871-b31b1b.svg)](http://arxiv.org/abs/2302.02871) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=B4Dsfc4EN84) |
| [Longformer: Longitudinal Transformer for Alzheimer's Disease Classification with Structural MRIs](https://openaccess.thecvf.com/content/WACV2024/html/Chen_Longformer_Longitudinal_Transformer_for_Alzheimers_Disease_Classification_With_Structural_MRIs_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Qybc/LongFormer?style=flat)](https://github.com/Qybc/LongFormer) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_Longformer_Longitudinal_Transformer_for_Alzheimers_Disease_Classification_With_Structural_MRIs_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.00901-b31b1b.svg)](http://arxiv.org/abs/2302.00901) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=FBWGZm0l_V8) |
| [TEGLO: High Fidelity Canonical Texture Mapping from Single-View Images](https://openaccess.thecvf.com/content/WACV2024/html/Vinod_TEGLO_High_Fidelity_Canonical_Texture_Mapping_From_Single-View_Images_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://teglo-nerf.github.io/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Vinod_TEGLO_High_Fidelity_Canonical_Texture_Mapping_From_Single-View_Images_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13743-b31b1b.svg)](http://arxiv.org/abs/2303.13743) | :heavy_minus_sign: |
| [DiffCLIP: Leveraging Stable Diffusion for Language Grounded 3D Classification](https://openaccess.thecvf.com/content/WACV2024/html/Shen_DiffCLIP_Leveraging_Stable_Diffusion_for_Language_Grounded_3D_Classification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/yiku-bit/DiffCLIP?style=flat)](https://github.com/yiku-bit/DiffCLIP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shen_DiffCLIP_Leveraging_Stable_Diffusion_for_Language_Grounded_3D_Classification_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.15957-b31b1b.svg)](http://arxiv.org/abs/2305.15957) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=chJNJV437y0) |
| [FocusTune: Tuning Visual Localization through Focus-Guided Sampling](https://openaccess.thecvf.com/content/WACV2024/html/Nguyen_FocusTune_Tuning_Visual_Localization_Through_Focus-Guided_Sampling_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/sontung/focus-tune?style=flat)](https://github.com/sontung/focus-tune) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nguyen_FocusTune_Tuning_Visual_Localization_Through_Focus-Guided_Sampling_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.02872-b31b1b.svg)](http://arxiv.org/abs/2311.02872) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=obf5SjBOHcY) |
| [Indoor Visual Localization using Point and Line Correspondences in Dense Colored Point Cloud](https://openaccess.thecvf.com/content/WACV2024/html/Matsumoto_Indoor_Visual_Localization_Using_Point_and_Line_Correspondences_in_Dense_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Matsumoto_Indoor_Visual_Localization_Using_Point_and_Line_Correspondences_in_Dense_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=mD4LtY2qNq4) |
| [Fast Sun-Aligned Outdoor Scene Relighting based on TensoRF](https://openaccess.thecvf.com/content/WACV2024/html/Chang_Fast_Sun-Aligned_Outdoor_Scene_Relighting_Based_on_TensoRF_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chang_Fast_Sun-Aligned_Outdoor_Scene_Relighting_Based_on_TensoRF_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03965-b31b1b.svg)](http://arxiv.org/abs/2311.03965) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=acNj3oQwYc8) |
| [MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty](https://openaccess.thecvf.com/content/WACV2024/html/Marsal_MonoProb_Self-Supervised_Monocular_Depth_Estimation_With_Interpretable_Uncertainty_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/CEA-LIST/MonoProb?style=flat)](https://github.com/CEA-LIST/MonoProb) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Marsal_MonoProb_Self-Supervised_Monocular_Depth_Estimation_With_Interpretable_Uncertainty_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.06137-b31b1b.svg)](http://arxiv.org/abs/2311.06137) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=l40Fpdu8SKI) |
| [AvatarOne: Monocular 3D Human Animation](https://openaccess.thecvf.com/content/WACV2024/html/Karthikeyan_AvatarOne_Monocular_3D_Human_Animation_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://aku02.github.io/projects/avatarone/) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Karthikeyan_AvatarOne_Monocular_3D_Human_Animation_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=E3i69m-nqgA) |
| [Deblur-NSFF: Neural Scene Flow Fields for Blurry Dynamic Scenes](https://openaccess.thecvf.com/content/WACV2024/html/Luthra_Deblur-NSFF_Neural_Scene_Flow_Fields_for_Blurry_Dynamic_Scenes_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Luthra_Deblur-NSFF_Neural_Scene_Flow_Fields_for_Blurry_Dynamic_Scenes_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=IuQ9x694zEA) |
| [SimpliMix: A Simplified Manifold Mixup for Few-Shot Point Cloud Classification](https://openaccess.thecvf.com/content/WACV2024/html/Yang_SimpliMix_A_Simplified_Manifold_Mixup_for_Few-Shot_Point_Cloud_Classification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/LexieYang/SimpliMix?style=flat)](https://github.com/LexieYang/SimpliMix) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yang_SimpliMix_A_Simplified_Manifold_Mixup_for_Few-Shot_Point_Cloud_Classification_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=PfCzND9Dnnc) |
| [PMVC: Promoting Multi-View Consistency for 3D Scene Reconstruction](https://openaccess.thecvf.com/content/WACV2024/html/Zhang_PMVC_Promoting_Multi-View_Consistency_for_3D_Scene_Reconstruction_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_PMVC_Promoting_Multi-View_Consistency_for_3D_Scene_Reconstruction_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-DtmwqrktnU) |
| [Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Hyb-NeRF_A_Multiresolution_Hybrid_Encoding_for_Neural_Radiance_Fields_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Hyb-NeRF_A_Multiresolution_Hybrid_Encoding_for_Neural_Radiance_Fields_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.12490-b31b1b.svg)](http://arxiv.org/abs/2311.12490) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=5tNF75c32Nc) |
| [Joint 3D Shape and Motion Estimation from Rolling Shutter Light-Field Images](https://openaccess.thecvf.com/content/WACV2024/html/McGriff_Joint_3D_Shape_and_Motion_Estimation_From_Rolling_Shutter_Light-Field_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ICB-Vision-AI/RSLF?style=flat)](https://github.com/ICB-Vision-AI/RSLF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/McGriff_Joint_3D_Shape_and_Motion_Estimation_From_Rolling_Shutter_Light-Field_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.01292-b31b1b.svg)](http://arxiv.org/abs/2311.01292) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=cuOWPXMqmTc) |
| [Sharp-NeRF: Grid-based Fast Deblurring Neural Radiance Fields using Sharpness Prior](https://openaccess.thecvf.com/content/WACV2024/html/Lee_Sharp-NeRF_Grid-Based_Fast_Deblurring_Neural_Radiance_Fields_Using_Sharpness_Prior_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://benhenryl.github.io/SharpNeRF/) <br /> [![GitHub](https://img.shields.io/github/stars/benhenryL/SharpNeRF?style=flat)](https://github.com/benhenryL/SharpNeRF) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Lee_Sharp-NeRF_Grid-Based_Fast_Deblurring_Neural_Radiance_Fields_Using_Sharpness_Prior_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.00825-b31b1b.svg)](http://arxiv.org/abs/2401.00825) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Z7hmtegSqCs) |
| [When 3D Bounding-Box Meets SAM: Point Cloud Instance Segmentation with Weak-and-Noisy Supervision](https://openaccess.thecvf.com/content/WACV2024/html/Yu_When_3D_Bounding-Box_Meets_SAM_Point_Cloud_Instance_Segmentation_With_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yu_When_3D_Bounding-Box_Meets_SAM_Point_Cloud_Instance_Segmentation_With_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.00828-b31b1b.svg)](http://arxiv.org/abs/2309.00828) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=HlneEvW9OeY) |
| [Auto-BPA: An Enhanced Ball-Pivoting Algorithm with Adaptive Radius using Contextual Bandits](https://openaccess.thecvf.com/content/WACV2024/html/Saffi_Auto-BPA_An_Enhanced_Ball-Pivoting_Algorithm_With_Adaptive_Radius_Using_Contextual_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/houda-pixel/Auto-BPA?style=flat)](https://github.com/houda-pixel/Auto-BPA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Saffi_Auto-BPA_An_Enhanced_Ball-Pivoting_Algorithm_With_Adaptive_Radius_Using_Contextual_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xqRKJxi8kMQ) |
| [Towards Realistic Generative 3D Face Models](https://openaccess.thecvf.com/content/WACV2024/html/Rai_Towards_Realistic_Generative_3D_Face_Models_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://aashishrai3799.github.io/Towards-Realistic-Generative-3D-Face-Models/) <br /> [![GitHub](https://img.shields.io/github/stars/aashishrai3799/Towards-Realistic-Generative-3D-Face-Models?style=flat)](https://github.com/aashishrai3799/Towards-Realistic-Generative-3D-Face-Models) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Rai_Towards_Realistic_Generative_3D_Face_Models_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.12483-b31b1b.svg)](http://arxiv.org/abs/2304.12483) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=bcFSl9pBPKc) |
| [Camera-Independent Single Image Depth Estimation from Defocus Blur](https://openaccess.thecvf.com/content/WACV2024/html/Wijayasingha_Camera-Independent_Single_Image_Depth_Estimation_From_Defocus_Blur_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/sleekEagle/defocus_camind?style=flat)](https://github.com/sleekEagle/defocus_camind) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wijayasingha_Camera-Independent_Single_Image_Depth_Estimation_From_Defocus_Blur_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.13045-b31b1b.svg)](http://arxiv.org/abs/2311.13045) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=l-LwOVy2dHw) |
| [U3DS<sup>3</sup>: Unsupervised 3D Semantic Scene Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Liu_U3DS3_Unsupervised_3D_Semantic_Scene_Segmentation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liu_U3DS3_Unsupervised_3D_Semantic_Scene_Segmentation_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=LiaMcyIkLM4) |
| [SSP: Semi-Signed Prioritized Neural Fitting for Surface Reconstruction from Unoriented Point Clouds](https://openaccess.thecvf.com/content/WACV2024/html/Zhu_SSP_Semi-Signed_Prioritized_Neural_Fitting_for_Surface_Reconstruction_From_Unoriented_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://runsong123.github.io/SSP/) <br /> [![GitHub](https://img.shields.io/github/stars/Runsong123/SSP?style=flat)](https://github.com/Runsong123/SSP) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Zhu_SSP_Semi-Signed_Prioritized_Neural_Fitting_for_Surface_Reconstruction_From_Unoriented_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2206.06715-b31b1b.svg)](http://arxiv.org/abs/2206.06715) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=9tOU0ZdbiyU) |
