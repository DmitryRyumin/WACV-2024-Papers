# WACV-2024-Papers

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/ml_afa.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/adversarial_learning_adversarial_attack_defense_methods.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## 3D Computer Vision

![Section Papers](https://img.shields.io/badge/Section%20Papers-10-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-7-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-3-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Task-Oriented Human-Object Interactions Generation with Implicit Neural Representations](https://openaccess.thecvf.com/content/WACV2024/html/Li_Task-Oriented_Human-Object_Interactions_Generation_With_Implicit_Neural_Representations_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Li_Task-Oriented_Human-Object_Interactions_Generation_With_Implicit_Neural_Representations_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13129-b31b1b.svg)](http://arxiv.org/abs/2303.13129) | :heavy_minus_sign: |
| [Depth from Asymmetric Frame-Event Stereo: A Divide-and-Conquer Approach](https://openaccess.thecvf.com/content/WACV2024/html/Chen_Depth_From_Asymmetric_Frame-Event_Stereo_A_Divide-and-Conquer_Approach_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_Depth_From_Asymmetric_Frame-Event_Stereo_A_Divide-and-Conquer_Approach_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [TriPlaneNet: An Encoder for EG3D Inversion](https://openaccess.thecvf.com/content/WACV2024/html/Bhattarai_TriPlaneNet_An_Encoder_for_EG3D_Inversion_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://anantarb.github.io/triplanenet) <br /> [![GitHub](https://img.shields.io/github/stars/anantarb/triplanenet?style=flat)](https://github.com/anantarb/triplanenet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bhattarai_TriPlaneNet_An_Encoder_for_EG3D_Inversion_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13497-b31b1b.svg)](http://arxiv.org/abs/2303.13497) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=NttXgBE12ec) |
| [Attentive Prototypes for Source-Free Unsupervised Domain Adaptive 3D Object Detection](https://openaccess.thecvf.com/content/WACV2024/html/Hegde_Attentive_Prototypes_for_Source-Free_Unsupervised_Domain_Adaptive_3D_Object_Detection_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/deeptibhegde/AttentivePrototypeSFUDA?style=flat)](https://github.com/deeptibhegde/AttentivePrototypeSFUDA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hegde_Attentive_Prototypes_for_Source-Free_Unsupervised_Domain_Adaptive_3D_Object_Detection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2111.15656-b31b1b.svg)](http://arxiv.org/abs/2111.15656) | :heavy_minus_sign: |
| [FIRe: Fast Inverse Rendering using Directional and Signed Distance Functions](https://openaccess.thecvf.com/content/WACV2024/html/Yenamandra_FIRe_Fast_Inverse_Rendering_Using_Directional_and_Signed_Distance_Functions_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cvg.cit.tum.de/research/geometry/fire) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yenamandra_FIRe_Fast_Inverse_Rendering_Using_Directional_and_Signed_Distance_Functions_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2203.16284-b31b1b.svg)](http://arxiv.org/abs/2203.16284) | :heavy_minus_sign: |
| [A Generic and Flexible Regularization Framework for NeRFs](https://openaccess.thecvf.com/content/WACV2024/html/Ehret_A_Generic_and_Flexible_Regularization_Framework_for_NeRFs_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Ehret_A_Generic_and_Flexible_Regularization_Framework_for_NeRFs_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Multi-View 3D Object Reconstruction and Uncertainty Modelling with Neural Shape Prior](https://openaccess.thecvf.com/content/WACV2024/html/Liao_Multi-View_3D_Object_Reconstruction_and_Uncertainty_Modelling_With_Neural_Shape_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Liao_Multi-View_3D_Object_Reconstruction_and_Uncertainty_Modelling_With_Neural_Shape_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.11739-b31b1b.svg)](http://arxiv.org/abs/2306.11739) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=N0lMUMJtA1M) |
| [Neural Textured Deformable Meshes for Robust Analysis-by-Synthesis](https://openaccess.thecvf.com/content/WACV2024/html/Wang_Neural_Textured_Deformable_Meshes_for_Robust_Analysis-by-Synthesis_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_Neural_Textured_Deformable_Meshes_for_Robust_Analysis-by-Synthesis_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.00118-b31b1b.svg)](http://arxiv.org/abs/2306.00118) | :heavy_minus_sign: |
| [Ray Deformation Networks for Novel View Synthesis of Refractive Objects](https://openaccess.thecvf.com/content/WACV2024/html/Deng_Ray_Deformation_Networks_for_Novel_View_Synthesis_of_Refractive_Objects_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Deng_Ray_Deformation_Networks_for_Novel_View_Synthesis_of_Refractive_Objects_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=EnBIWbdRQCE) |
| [Registered and Segmented Deformable Object Reconstruction from a Single View Point Cloud](https://openaccess.thecvf.com/content/WACV2024/html/Henrich_Registered_and_Segmented_Deformable_Object_Reconstruction_From_a_Single_View_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Henrich_Registered_and_Segmented_Deformable_Object_Reconstruction_From_a_Single_View_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.07357-b31b1b.svg)](http://arxiv.org/abs/2311.07357) | :heavy_minus_sign: |
| SupeRVol: Super-Resolution Shape and Reflectance Estimation in Inverse Volume Rendering |  |  |  |
| RIMeshGNN: A Rotation-Invariant Graph Neural Network for Mesh Classification |  |  |  |
| OptFlow: Fast Optimization-based Scene Flow Estimation without Supervision |  |  |  |
| Point-DynRF: Point-based Dynamic Radiance Fields from a Monocular Video |  |  |  |
| LensNeRF: Rethinking Volume Rendering based on Thin-Lens Camera Model |  |  |  |
| Domain Adaptive 3D Shape Retrieval from Monocular Images |  |  |  |
| HD-Fusion: Detailed Text-to-3D Generation Leveraging Multiple Noise Estimation |  |  |  |
| Sparse Convolutional Networks for Surface Reconstruction from Noisy Point Clouds |  |  |  |
| Single Frame Semantic Segmentation using Multi-Modal Spherical Images |  |  |  |
| Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting |  |  |  |
| GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo |  |  |  |
| SAM Fewshot Finetuning for Anatomical Segmentation in Medical Images |  |  |  |
| MSCC: Multi-Scale Transformers for Camera Calibration |  |  |  |
| A Geometry Loss Combination for 3D Human Pose Estimation |  |  |  |
| A Robust Diffusion Modeling Framework for Radar Camera 3D Object Detection |  |  |  |
| WalkFormer: Point Cloud Completion via Guided Walks |  |  |  |
| MGM-AE: Self-Supervised Learning on 3D Shape using Mesh Graph Masked Autoencoders |  |  |  |
| Unsupervised 3D Pose Estimation with Non-Rigid Structure-from-Motion Modeling |  |  |  |
| Residual Graph Convolutional Network for Bird's-Eye-View Semantic Segmentation |  |  |  |
| 3D Human Pose Estimation with Two-Step Mixed-Training Strategy |  |  |  |
| RGB-D Mapping and Tracking in a Plenoxel Radiance Field |  |  |  |
| SOAP: Cross-Sensor Domain Adaptation for 3D Object Detection using Stationary Object Aggregation Pseudo-Labelling |  |  |  |
| BALF: Simple and Efficient Blur Aware Local Feature Detector |  |  |  |
| MACP: Efficient Model Adaptation for Cooperative Perception |  |  |  |
| MAELi: Masked Autoencoder for Large-Scale LiDAR Point Clouds |  |  |  |
| HDMNet: A Hierarchical Matching Network with Double Attention for Large-Scale Outdoor LiDAR Point Cloud Registration |  |  |  |
| SGRec3D: Self-Supervised 3D Scene Graph Learning via Object-Level Scene Reconstruction |  |  |  |
| MPT: Mesh Pre-Training with Transformers for Human Pose and Mesh Reconstruction |  |  |  |
| LInKs ''Lifting Independent Keypoints'' â€“ Partial Pose Lifting for Occlusion Handling with Improved Accuracy in 2D-3D Human Pose Estimation |  |  |  |
| ECSIC: Epipolar Cross Attention for Stereo Image Compression |  |  |  |
| Robust Category-Level 3D Pose Estimation from Diffusion-Enhanced Synthetic Data |  |  |  |
| Open-NeRF: Towards Open Vocabulary NeRF Decomposition |  |  |  |
| HAMMER: Learning Entropy Maps to Create Accurate 3D Models in Multi-View Stereo |  |  |  |
| Polarimetric PatchMatch Multi-View Stereo |  |  |  |
| Solving the Plane-Sphere Ambiguity in Top-Down Structure-from-Motion |  |  |  |
| Self-Annotated 3D Geometric Learning for Smeared Points Removal |  |  |  |
| 3D Face Style Transfer with a Hybrid Solution of NeRF and Mesh Rasterization |  |  |  |
| A Sequential Learning-based Approach for Monocular Human Performance Capture |  |  |  |
| ScanEnts3D: Exploiting Phrase-to-3D-Object Correspondences for Improved Visio-Linguistic Models in 3D Scenes |  |  |  |
| Global Occlusion-Aware Transformer for Robust Stereo Matching |  |  |  |
| MoRF: Mobile Realistic Fullbody Avatars from a Monocular Video |  |  |  |
| PointCT: Point Central Transformer Network for Weakly-Supervised Point Cloud Semantic Segmentation |  |  |  |
| Top-Down Beats Bottom-Up in 3D Instance Segmentation |  |  |  |
| Longformer: Longitudinal Transformer for Alzheimer's Disease Classification with Structural MRIs |  |  |  |
| TEGLO: High Fidelity Canonical Texture Mapping from Single-View Images |  |  |  |
| DiffCLIP: Leveraging Stable Diffusion for Language Grounded 3D Classification |  |  |  |
| FocusTune: Tuning Visual Localization through Focus-Guided Sampling |  |  |  |
| Indoor Visual Localization using Point and Line Correspondences in Dense Colored Point Cloud |  |  |  |
| Fast Sun-Aligned Outdoor Scene Relighting based on TensoRF |  |  |  |
| MonoProb: Self-Supervised Monocular Depth Estimation with Interpretable Uncertainty |  |  |  |
| AvatarOne: Monocular 3D Human Animation |  |  |  |
| Deblur-NSFF: Neural Scene Flow Fields for Blurry Dynamic Scenes |  |  |  |
| SimpliMix: A Simplified Manifold Mixup for Few-Shot Point Cloud Classification |  |  |  |
| PMVC: Promoting Multi-View Consistency for 3D Scene Reconstruction |  |  |  |
| Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields |  |  |  |
| Joint 3D Shape and Motion Estimation from Rolling Shutter Light-Field Images |  |  |  |
| Sharp-NeRF: Grid-based Fast Deblurring Neural Radiance Fields using Sharpness Prior |  |  |  |
| When 3D Bounding-Box Meets SAM: Point Cloud Instance Segmentation with Weak-and-Noisy Supervision |  |  |  |
| Auto-BPA: An Enhanced Ball-Pivoting Algorithm with Adaptive Radius using Contextual Bandits |  |  |  |
| Towards Realistic Generative 3D Face Models |  |  |  |
| Camera-Independent Single Image Depth Estimation from Defocus Blur |  |  |  |
| U3DS3: Unsupervised 3D Semantic Scene Segmentation |  |  |  |
| SSP: Semi-Signed Prioritized Neural Fitting for Surface Reconstruction from Unoriented Point Clouds |  |  |  |
