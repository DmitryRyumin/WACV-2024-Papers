# WACV-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/explainable_fair_accountable-privacy-preserving.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/vision_language_and_other_modalities.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Generative Models for Image, Video, 3D, etc

![Section Papers](https://img.shields.io/badge/Section%20Papers-soon-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Spiking Denoising Diffusion Probabilistic Models |  |  |  |
| Improving the Effectiveness of Deep Generative Data |  |  |  |
| Customizing 360-Degree Panoramas through Text-to-Image Diffusion Models |  |  |  |
| Label Augmentation as Inter-Class Data Augmentation for Conditional Image Synthesis with Imbalanced Data |  |  |  |
| 3D-Aware Talking-Head Video Motion Transfer |  |  |  |
| GRIT: GAN Residuals for Paired Image-to-Image Translation |  |  |  |
| Multimodality-Guided Image Style Transfer using Cross-Modal GAN Inversion |  |  |  |
| ZIGNeRF: Zero-Shot 3D Scene Representation with Invertible Generative Neural Radiance Fields |  |  |  |
| GraphFill: Deep Image Inpainting using Graphs |  |  |  |
| PoseDiff: Pose-Conditioned Multimodal Diffusion Model for Unbounded Scene Synthesis from Sparse Inputs |  |  |  |
| Nested Diffusion Processes for Anytime Image Generation |  |  |  |
| Expanding Expressiveness of Diffusion Models with Limited Data via Self-Distillation based Fine-Tuning |  |  |  |
| One Style is All You Need to Generate a Video |  |  |  |
| Consistent Multimodal Generation via a Unified GAN Framework |  |  |  |
| Unsupervised Co-Generation of Foreground-Background Segmentation from Text-to-Image Synthesis |  |  |  |
| MotionGPT: Human Motion Synthesis with Improved Diversity and Realism via GPT-3 Prompting |  |  |  |
| Human Motion Aware Text-to-Video Generation with Explicit Camera Control |  |  |  |
| Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation |  |  |  |
| Second-Order Graph ODEs for Multi-Agent Trajectory Forecasting |  |  |  |
| Unified Concept Editing in Diffusion Models |  |  |  |
| SpectralCLIP: Preventing Artifacts in Text-Guided Style Transfer from a Spectral Perspective |  |  |  |
| Diffusion-based Generation of Histopathological whole Slide Images at a Gigapixel Scale |  |  |  |
| Painterly Image Harmonization via Adversarial Residual Learning |  |  |  |
| Training-Free Content Injection using H-Space in Diffusion Models |  |  |  |
| ENTED: Enhanced Neural Texture Extraction and Distribution for Reference-based Blind Face Restoration |  |  |  |
| PIDiffu: Pixel-Aligned Diffusion Model for High-Fidelity Clothed Human Reconstruction |  |  |  |
| PathLDM: Text Conditioned Latent Diffusion Model for Histopathology |  |  |  |
| Content-Aware Image Color Editing with Auxiliary Color Restoration Tasks |  |  |  |
| On Manipulating Scene Text in the Wild with Diffusion Models |  |  |  |
| CXR-IRGen: An Integrated Vision and Language Model for the Generation of Clinically Accurate Chest X-Ray Image-Report Pairs |  |  |  |
| Face Identity-Aware Disentanglement in StyleGAN |  |  |  |
| Text-to-Image Editing by Image Information Removal |  |  |  |
| Preserving Image Properties through Initializations in Diffusion Models |  |  |  |
| GC-VTON: Predicting Globally Consistent and Occlusion Aware Local Flows with Neighborhood Integrity Preservation for Virtual Try-On |  |  |  |
| Generation of Upright Panoramic Image from Non-Upright Panoramic Image |  |  |  |
| Fast Diffusion EM: A Diffusion Model for Blind Inverse Problems with Application to Deconvolution |  |  |  |
| Enforcing Sparsity on Latent Space for Robust and Explainable Representations |  |  |  |
| Diff2Lip: Audio Conditioned Diffusion Models for Lip-Synchronization |  |  |  |
| 3D Reconstruction of Interacting Multi-Person in Clothing from a Single Image |  |  |  |
| Revisiting Latent Space of GAN Inversion for Robust Real Image Editing |  |  |  |
| Soft Curriculum for Learning Conditional GANs with Noisy-Labeled and Uncurated Unlabeled Data |  |  |  |
| Bipartite Graph Diffusion Model for Human Interaction Generation |  |  |  |
| Training-Free Layout Control with Cross-Attention Guidance |  |  |  |
| Controllable Image Synthesis of Industrial Data using Stable Diffusion |  |  |  |
| Removing the Quality Tax in Controllable Face Generation |  |  |  |
| Hierarchical Diffusion Autoencoders and Disentangled Image Manipulation |  |  |  |
| FacadeNet: Conditional Facade Synthesis via Selective Editing |  |  |  |
| TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining and Object Detection in Rain |  |  |  |
| Common Diffusion Noise Schedules and Sample Steps are Flawed |  |  |  |
| Improving the Leaking of Augmentations in Data-Efficient GANs via Adaptive Negative Data Augmentation |  |  |  |
| P2D: Plug and Play Discriminator for Accelerating GAN Frameworks |  |  |  |
| Personalized Face Inpainting with Diffusion Models by Parallel Visual Attention |  |  |  |
| Semantic Generative Augmentations for Few-Shot Counting |  |  |  |
| StyleGAN-Fusion: Diffusion Guided Domain Adaptation of Image Generators |  |  |  |
