# WACV-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/navigation_and_autonomous_driving.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/WACV-2024-Papers/blob/main/sections/commercial_retail.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Biomedical / Healthcare / Medicine

![Section Papers](https://img.shields.io/badge/Section%20Papers-46-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-31-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-28-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-30-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [GazeGNN: A Gaze-Guided Graph Neural Network for Chest X-Ray Classification](https://openaccess.thecvf.com/content/WACV2024/html/Wang_GazeGNN_A_Gaze-Guided_Graph_Neural_Network_for_Chest_X-Ray_Classification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ukaukaaaa/GazeGNN?style=flat)](https://github.com/ukaukaaaa/GazeGNN) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_GazeGNN_A_Gaze-Guided_Graph_Neural_Network_for_Chest_X-Ray_Classification_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.18221-b31b1b.svg)](http://arxiv.org/abs/2305.18221) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jGSBemQG8tI) |
| [Learning Robust Deep Visual Representations from EEG Brain Recordings](https://openaccess.thecvf.com/content/WACV2024/html/Singh_Learning_Robust_Deep_Visual_Representations_From_EEG_Brain_Recordings_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/prajwalsingh/EEGStyleGAN-ADA?style=flat)](https://github.com/prajwalsingh/EEGStyleGAN-ADA) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Singh_Learning_Robust_Deep_Visual_Representations_From_EEG_Brain_Recordings_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16532-b31b1b.svg)](http://arxiv.org/abs/2310.16532) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=kXKTbls0XQU) |
| [Continual Atlas-based Segmentation of Prostate MRI](https://openaccess.thecvf.com/content/WACV2024/html/Ranem_Continual_Atlas-Based_Segmentation_of_Prostate_MRI_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/MECLabTUDA/Atlas-Replay?style=flat)](https://github.com/MECLabTUDA/Atlas-Replay) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Ranem_Continual_Atlas-Based_Segmentation_of_Prostate_MRI_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.00548-b31b1b.svg)](http://arxiv.org/abs/2311.00548) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=_145UKP4tiI) |
| [Brainomaly: Unsupervised Neurologic Disease Detection Utilizing Unannotated T1-Weighted Brain MR Images](https://openaccess.thecvf.com/content/WACV2024/html/Siddiquee_Brainomaly_Unsupervised_Neurologic_Disease_Detection_Utilizing_Unannotated_T1-Weighted_Brain_MR_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/mahfuzmohammad/Brainomaly?style=flat)](https://github.com/mahfuzmohammad/Brainomaly) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Siddiquee_Brainomaly_Unsupervised_Neurologic_Disease_Detection_Utilizing_Unannotated_T1-Weighted_Brain_MR_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2302.09200-b31b1b.svg)](http://arxiv.org/abs/2302.09200) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=RhRz3zeL8YE) |
| [PHG-Net: Persistent Homology Guided Medical Image Classification](https://openaccess.thecvf.com/content/WACV2024/html/Peng_PHG-Net_Persistent_Homology_Guided_Medical_Image_Classification_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Peng_PHG-Net_Persistent_Homology_Guided_Medical_Image_Classification_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.17243-b31b1b.svg)](http://arxiv.org/abs/2311.17243) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jfLTIH8afTY) |
| [AnyStar: Domain Randomized Universal Star-Convex 3D Instance Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Dey_AnyStar_Domain_Randomized_Universal_Star-Convex_3D_Instance_Segmentation_WACV_2024_paper.html) | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.neeldey.com/any-star/) <br /> [![GitHub](https://img.shields.io/github/stars/neel-dey/AnyStar?style=flat)](https://github.com/neel-dey/AnyStar) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Dey_AnyStar_Domain_Randomized_Universal_Star-Convex_3D_Instance_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.07044-b31b1b.svg)](http://arxiv.org/abs/2307.07044) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=0h9RUZB9Rds) |
| [Adaptive Latent Diffusion Model for 3D Medical Image to Image Translation: Multi-Modal Magnetic Resonance Imaging Study](https://openaccess.thecvf.com/content/WACV2024/html/Kim_Adaptive_Latent_Diffusion_Model_for_3D_Medical_Image_to_Image_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/jongdory/ALDM?style=flat)](https://github.com/jongdory/ALDM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_Adaptive_Latent_Diffusion_Model_for_3D_Medical_Image_to_Image_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.00265-b31b1b.svg)](http://arxiv.org/abs/2311.00265) | :heavy_minus_sign: |
| [Slice and Conquer: A Planar-to-3D Framework for Efficient Interactive Segmentation of Volumetric Images](https://openaccess.thecvf.com/content/WACV2024/html/Cho_Slice_and_Conquer_A_Planar-to-3D_Framework_for_Efficient_Interactive_Segmentation_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Cho_Slice_and_Conquer_A_Planar-to-3D_Framework_for_Efficient_Interactive_Segmentation_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Attention-Guided Prototype Mixing: Diversifying Minority Context on Imbalanced whole Slide Images Classification Learning](https://openaccess.thecvf.com/content/WACV2024/html/Raswa_Attention-Guided_Prototype_Mixing_Diversifying_Minority_Context_on_Imbalanced_Whole_Slide_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Raswa_Attention-Guided_Prototype_Mixing_Diversifying_Minority_Context_on_Imbalanced_Whole_Slide_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Are Natural Domain Foundation Models Useful for Medical Image Classification?](https://openaccess.thecvf.com/content/WACV2024/html/Huix_Are_Natural_Domain_Foundation_Models_Useful_for_Medical_Image_Classification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/joanaapa/Foundation-Medical?style=flat)](https://github.com/joanaapa/Foundation-Medical) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Huix_Are_Natural_Domain_Foundation_Models_Useful_for_Medical_Image_Classification_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.19522-b31b1b.svg)](http://arxiv.org/abs/2310.19522) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=a5KoHajwPyw) |
| [Unsupervised Exemplar-based Image-to-Image Translation and Cascaded Vision Transformers for Tagged and Untagged Cardiac Cine MRI Registration](https://openaccess.thecvf.com/content/WACV2024/html/Ye_Unsupervised_Exemplar-Based_Image-to-Image_Translation_and_Cascaded_Vision_Transformers_for_Tagged_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Ye_Unsupervised_Exemplar-Based_Image-to-Image_Translation_and_Cascaded_Vision_Transformers_for_Tagged_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [IR-FRestormer: Iterative Refinement with Fourier-based Restormer for Accelerated MRI Reconstruction](https://openaccess.thecvf.com/content/WACV2024/html/Darestani_IR-FRestormer_Iterative_Refinement_With_Fourier-Based_Restormer_for_Accelerated_MRI_Reconstruction_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Darestani_IR-FRestormer_Iterative_Refinement_With_Fourier-Based_Restormer_for_Accelerated_MRI_Reconstruction_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=HXD97uAQs9s) |
| [Constrained Probabilistic Mask Learning for Task-Specific Undersampled MRI Reconstruction](https://openaccess.thecvf.com/content/WACV2024/html/Weber_Constrained_Probabilistic_Mask_Learning_for_Task-Specific_Undersampled_MRI_Reconstruction_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/saiboxx/bernoulli-mri?style=flat)](https://github.com/saiboxx/bernoulli-mri) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Weber_Constrained_Probabilistic_Mask_Learning_for_Task-Specific_Undersampled_MRI_Reconstruction_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.16376-b31b1b.svg)](http://arxiv.org/abs/2305.16376) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=jlSdX4hkIxI) |
| [Automated Sperm Assessment Framework and Neural Network Specialized for Sperm Video Recognition](https://openaccess.thecvf.com/content/WACV2024/html/Fujii_Automated_Sperm_Assessment_Framework_and_Neural_Network_Specialized_for_Sperm_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/FTKR12/RoSTFine?style=flat)](https://github.com/FTKR12/RoSTFine) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Fujii_Automated_Sperm_Assessment_Framework_and_Neural_Network_Specialized_for_Sperm_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.05927-b31b1b.svg)](http://arxiv.org/abs/2311.05927) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=aUeNDAGR__U) |
| [Generalizing to Unseen Domains in Diabetic Retinopathy Classification](https://openaccess.thecvf.com/content/WACV2024/html/Galappaththige_Generalizing_to_Unseen_Domains_in_Diabetic_Retinopathy_Classification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/Chumsy0725/SPSD-ViT?style=flat)](https://github.com/Chumsy0725/SPSD-ViT) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Galappaththige_Generalizing_to_Unseen_Domains_in_Diabetic_Retinopathy_Classification_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.17255-b31b1b.svg)](http://arxiv.org/abs/2310.17255) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=V_0Y40l9tPk) |
| [Dynamic Multimodal Information Bottleneck for Multimodality Classification](https://openaccess.thecvf.com/content/WACV2024/html/Fang_Dynamic_Multimodal_Information_Bottleneck_for_Multimodality_Classification_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/ayanglab/DMIB?style=flat)](https://github.com/ayanglab/DMIB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Fang_Dynamic_Multimodal_Information_Bottleneck_for_Multimodality_Classification_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.01066-b31b1b.svg)](http://arxiv.org/abs/2311.01066) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=V3XD_lUDg4A) |
| [Hybrid Neural Diffeomorphic Flow for Shape Representation and Generation via Triplane](https://openaccess.thecvf.com/content/WACV2024/html/Han_Hybrid_Neural_Diffeomorphic_Flow_for_Shape_Representation_and_Generation_via_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Han_Hybrid_Neural_Diffeomorphic_Flow_for_Shape_Representation_and_Generation_via_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.01957-b31b1b.svg)](http://arxiv.org/abs/2307.01957) | :heavy_minus_sign: |
| [Unsupervised Domain Adaptation of MRI Skull-Stripping Trained on Adult Data to Newborns](https://openaccess.thecvf.com/content/WACV2024/html/Omidi_Unsupervised_Domain_Adaptation_of_MRI_Skull-Stripping_Trained_on_Adult_Data_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/abbasomidi77/DAUnet?style=flat)](https://github.com/abbasomidi77/DAUnet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Omidi_Unsupervised_Domain_Adaptation_of_MRI_Skull-Stripping_Trained_on_Adult_Data_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=vN7I1w1kavM) |
| [G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D Medical Image Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Rahman_G-CASCADE_Efficient_Cascaded_Graph_Convolutional_Decoding_for_2D_Medical_Image_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/SLDGroup/G-CASCADE?style=flat)](https://github.com/SLDGroup/G-CASCADE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Rahman_G-CASCADE_Efficient_Cascaded_Graph_Convolutional_Decoding_for_2D_Medical_Image_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16175-b31b1b.svg)](http://arxiv.org/abs/2310.16175) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=yXrubJ1cBWc) |
| [Bridging Generalization Gaps in High Content Imaging through Online Self-Supervised Domain Adaptation](https://openaccess.thecvf.com/content/WACV2024/html/Haslum_Bridging_Generalization_Gaps_in_High_Content_Imaging_Through_Online_Self-Supervised_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/cfredinh/coda?style=flat)](https://github.com/cfredinh/coda) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Haslum_Bridging_Generalization_Gaps_in_High_Content_Imaging_Through_Online_Self-Supervised_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.12623-b31b1b.svg)](http://arxiv.org/abs/2311.12623) | :heavy_minus_sign: |
| [DR10K: Transfer Learning using Weak Labels for Grading Diabetic Retinopathy on DR10K Dataset](https://openaccess.thecvf.com/content/WACV2024/html/ElHabebe_DR10K_Transfer_Learning_Using_Weak_Labels_for_Grading_Diabetic_Retinopathy_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/ElHabebe_DR10K_Transfer_Learning_Using_Weak_Labels_for_Grading_Diabetic_Retinopathy_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=4MBZX483K8c) |
| [SCUNet++: Swin-UNet and CNN Bottleneck Hybrid Architecture With Multi-Fusion Dense Skip Connection for Pulmonary Embolism CT Image Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Chen_SCUNet_Swin-UNet_and_CNN_Bottleneck_Hybrid_Architecture_With_Multi-Fusion_Dense_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/JustlfC03/SCUNet-plusplus?style=flat)](https://github.com/JustlfC03/SCUNet-plusplus) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Chen_SCUNet_Swin-UNet_and_CNN_Bottleneck_Hybrid_Architecture_With_Multi-Fusion_Dense_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.14705-b31b1b.svg)](http://arxiv.org/abs/2312.14705) | :heavy_minus_sign: |
| [SynergyNet: Bridging the Gap Between Discrete and Continuous Representations for Precise Medical Image Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Gorade_SynergyNet_Bridging_the_Gap_Between_Discrete_and_Continuous_Representations_for_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/CandleLabAI/SynergyNet-WACV-2024?style=flat)](https://github.com/CandleLabAI/SynergyNet-WACV-2024) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gorade_SynergyNet_Bridging_the_Gap_Between_Discrete_and_Continuous_Representations_for_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.17764-b31b1b.svg)](http://arxiv.org/abs/2310.17764) | :heavy_minus_sign: |
| [Reverse Knowledge Distillation: Training a Large Model using a Small One for Retinal Image Matching on Limited Data](https://openaccess.thecvf.com/content/WACV2024/html/Nasser_Reverse_Knowledge_Distillation_Training_a_Large_Model_Using_a_Small_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Nasser_Reverse_Knowledge_Distillation_Training_a_Large_Model_Using_a_Small_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.10698-b31b1b.svg)](http://arxiv.org/abs/2307.10698) | :heavy_minus_sign: |
| [Activity-based Early Autism Diagnosis using a Multi-Dataset Supervised Contrastive Learning Approach](https://openaccess.thecvf.com/content/WACV2024/html/Rani_Activity-Based_Early_Autism_Diagnosis_Using_a_Multi-Dataset_Supervised_Contrastive_Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/asharani97/MDSupCL?style=flat)](https://github.com/asharani97/MDSupCL) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Rani_Activity-Based_Early_Autism_Diagnosis_Using_a_Multi-Dataset_Supervised_Contrastive_Learning_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Convolutional Masked Image Modeling for Dense Prediction Tasks on Pathology Images](https://openaccess.thecvf.com/content/WACV2024/html/Yang_Convolutional_Masked_Image_Modeling_for_Dense_Prediction_Tasks_on_Pathology_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yang_Convolutional_Masked_Image_Modeling_for_Dense_Prediction_Tasks_on_Pathology_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QFKnDoHxujE) |
| [Real-Time Polyp Detection in Colonoscopy using Lightweight Transformer](https://openaccess.thecvf.com/content/WACV2024/html/Yoo_Real-Time_Polyp_Detection_in_Colonoscopy_Using_Lightweight_Transformer_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yoo_Real-Time_Polyp_Detection_in_Colonoscopy_Using_Lightweight_Transformer_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=m_ur33VZbM0) |
| [Self-Supervised Learning with Masked Autoencoders for Teeth Segmentation from Intra-Oral 3D Scans](https://openaccess.thecvf.com/content/WACV2024/html/Almalki_Self-Supervised_Learning_With_Masked_Autoencoders_for_Teeth_Segmentation_From_Intra-Oral_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Almalki_Self-Supervised_Learning_With_Masked_Autoencoders_for_Teeth_Segmentation_From_Intra-Oral_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ORAheA_Ibcg) |
| [Self-Supervised Edge Detection Reconstruction for Topology-Informed 3D Axon Segmentation and Centerline Detection](https://openaccess.thecvf.com/content/WACV2024/html/Xu_Self-Supervised_Edge_Detection_Reconstruction_for_Topology-Informed_3D_Axon_Segmentation_and_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Xu_Self-Supervised_Edge_Detection_Reconstruction_for_Topology-Informed_3D_Axon_Segmentation_and_WACV_2024_paper.pdf) | :heavy_minus_sign: |
| [Robust Source-Free Domain Adaptation for Fundus Image Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Li_Robust_Source-Free_Domain_Adaptation_for_Fundus_Image_Segmentation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/LinGrayy/PLPB?style=flat)](https://github.com/LinGrayy/PLPB) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Li_Robust_Source-Free_Domain_Adaptation_for_Fundus_Image_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.16665-b31b1b.svg)](http://arxiv.org/abs/2310.16665) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=-9RXe44lElY) |
| [I-AI: A Controllable and Interpretable AI System for Decoding Radiologists' Intense Focus for Accurate CXR Diagnoses](https://openaccess.thecvf.com/content/WACV2024/html/Pham_I-AI_A_Controllable__Interpretable_AI_System_for_Decoding_Radiologists_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/UARK-AICV/IAI?style=flat)](https://github.com/UARK-AICV/IAI) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Pham_I-AI_A_Controllable__Interpretable_AI_System_for_Decoding_Radiologists_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13550-b31b1b.svg)](http://arxiv.org/abs/2309.13550) | :heavy_minus_sign: |
| [FreMIM: Fourier Transform Meets Masked Image Modeling for Medical Image Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Wang_FreMIM_Fourier_Transform_Meets_Masked_Image_Modeling_for_Medical_Image_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://rubics-xuan.github.io/FreMIM) <br /> [![GitHub](https://img.shields.io/github/stars/Rubics-Xuan/FreMIM?style=flat)](https://github.com/Rubics-Xuan/FreMIM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Wang_FreMIM_Fourier_Transform_Meets_Masked_Image_Modeling_for_Medical_Image_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2304.10864-b31b1b.svg)](http://arxiv.org/abs/2304.10864) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Cg-N7X-RlzA) |
| [Med-DANet V2: A Flexible Dynamic Architecture for Efficient Medical Volumetric Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Shen_Med-DANet_V2_A_Flexible_Dynamic_Architecture_for_Efficient_Medical_Volumetric_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://sevenshr.github.io/Med-DANet_V2) <br /> [![GitHub](https://img.shields.io/github/stars/Rubics-Xuan/Med-DANet?style=flat)](https://github.com/Rubics-Xuan/Med-DANet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shen_Med-DANet_V2_A_Flexible_Dynamic_Architecture_for_Efficient_Medical_Volumetric_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.18656-b31b1b.svg)](http://arxiv.org/abs/2310.18656) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=xD2YYFVTI1A) |
| [Ordinal Classification with Distance Regularization for Robust Brain Age Prediction](https://openaccess.thecvf.com/content/WACV2024/html/Shah_Ordinal_Classification_With_Distance_Regularization_for_Robust_Brain_Age_Prediction_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/jaygshah/Robust-Brain-Age-Prediction?style=flat)](https://github.com/jaygshah/Robust-Brain-Age-Prediction) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shah_Ordinal_Classification_With_Distance_Regularization_for_Robust_Brain_Age_Prediction_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=dtJ3NdzRuI0) |
| [CryoRL: Reinforcement Learning Enables Efficient Cryo-EM Data Collection](https://openaccess.thecvf.com/content/WACV2024/html/Fan_CryoRL_Reinforcement_Learning_Enables_Efficient_Cryo-EM_Data_Collection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Fan_CryoRL_Reinforcement_Learning_Enables_Efficient_Cryo-EM_Data_Collection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2204.07543-b31b1b.svg)](http://arxiv.org/abs/2204.07543) | :heavy_minus_sign: |
| [Prototype Learning for Explainable Brain Age Prediction](https://openaccess.thecvf.com/content/WACV2024/html/Hesse_Prototype_Learning_for_Explainable_Brain_Age_Prediction_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/lindehesse/ExPeRT_Code?style=flat)](https://github.com/lindehesse/ExPeRT_Code) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Hesse_Prototype_Learning_for_Explainable_Brain_Age_Prediction_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.09858-b31b1b.svg)](http://arxiv.org/abs/2306.09858) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=fYSPovvHR9E) |
| [BigSmall: Efficient Multi-Task Learning for Disparate Spatial and Temporal Physiological Measurements](https://openaccess.thecvf.com/content/WACV2024/html/Narayanswamy_BigSmall_Efficient_Multi-Task_Learning_for_Disparate_Spatial_and_Temporal_Physiological_WACV_2024_paper.html) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://girishvn.github.io/BigSmall/) <br /> [![GitHub](https://img.shields.io/github/stars/girishvn/BigSmall?style=flat)](https://github.com/girishvn/BigSmall) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Narayanswamy_BigSmall_Efficient_Multi-Task_Learning_for_Disparate_Spatial_and_Temporal_Physiological_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.11573-b31b1b.svg)](http://arxiv.org/abs/2303.11573) | :heavy_minus_sign: |
| [Self-Sampling Meta SAM: Enhancing Few-Shot Medical Image Segmentation with Meta-Learning](https://openaccess.thecvf.com/content/WACV2024/html/Leng_Self-Sampling_Meta_SAM_Enhancing_Few-Shot_Medical_Image_Segmentation_With_Meta-Learning_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/DragonDescentZerotsu/SSM-SAM?style=flat)](https://github.com/DragonDescentZerotsu/SSM-SAM) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Leng_Self-Sampling_Meta_SAM_Enhancing_Few-Shot_Medical_Image_Segmentation_With_Meta-Learning_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2308.16466-b31b1b.svg)](http://arxiv.org/abs/2308.16466) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=QyOaZUPuUBQ) |
| [Controllable Text-to-Image Synthesis for Multi-Modality MR Images](https://openaccess.thecvf.com/content/WACV2024/html/Kim_Controllable_Text-to-Image_Synthesis_for_Multi-Modality_MR_Images_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Kim_Controllable_Text-to-Image_Synthesis_for_Multi-Modality_MR_Images_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=HvmfQxeoeUs) |
| [SC-MIL: Supervised Contrastive Multiple Instance Learning for Imbalanced Classification in Pathology](https://openaccess.thecvf.com/content/WACV2024/html/Juyal_SC-MIL_Supervised_Contrastive_Multiple_Instance_Learning_for_Imbalanced_Classification_in_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Juyal_SC-MIL_Supervised_Contrastive_Multiple_Instance_Learning_for_Imbalanced_Classification_in_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.13405-b31b1b.svg)](http://arxiv.org/abs/2303.13405) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=Y8WlAiXVeJQ) |
| [FATE: Feature-Agnostic Transformer-based Encoder for Learning Generalized Embedding Spaces in Flow Cytometry Data](https://openaccess.thecvf.com/content/WACV2024/html/Weijler_FATE_Feature-Agnostic_Transformer-Based_Encoder_for_Learning_Generalized_Embedding_Spaces_in_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/lisaweijler/FATE?style=flat)](https://github.com/lisaweijler/FATE) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Weijler_FATE_Feature-Agnostic_Transformer-Based_Encoder_for_Learning_Generalized_Embedding_Spaces_in_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.03314-b31b1b.svg)](http://arxiv.org/abs/2311.03314) | :heavy_minus_sign: |
| [Dual Domain Diffusion Guidance for 3D CBCT Metal Artifact Reduction](https://openaccess.thecvf.com/content/WACV2024/html/Choi_Dual_Domain_Diffusion_Guidance_for_3D_CBCT_Metal_Artifact_Reduction_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Choi_Dual_Domain_Diffusion_Guidance_for_3D_CBCT_Metal_Artifact_Reduction_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=ZJQ0eiiYsiM) |
| [AFTer-SAM: Adapting SAM with Axial Fusion Transformer for Medical Imaging Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Yan_AFTer-SAM_Adapting_SAM_With_Axial_Fusion_Transformer_for_Medical_Imaging_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Yan_AFTer-SAM_Adapting_SAM_With_Axial_Fusion_Transformer_for_Medical_Imaging_WACV_2024_paper.pdf) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KWondtdL-40) |
| [MEGANet: Multi-Scale Edge-Guided Attention Network for Weak Boundary Polyp Segmentation](https://openaccess.thecvf.com/content/WACV2024/html/Bui_MEGANet_Multi-Scale_Edge-Guided_Attention_Network_for_Weak_Boundary_Polyp_Segmentation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/UARK-AICV/MEGANet?style=flat)](https://github.com/UARK-AICV/MEGANet) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Bui_MEGANet_Multi-Scale_Edge-Guided_Attention_Network_for_Weak_Boundary_Polyp_Segmentation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03329-b31b1b.svg)](http://arxiv.org/abs/2309.03329) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=oy2uLObst20) |
| [Complex Organ Mask Guided Radiology Report Generation](https://openaccess.thecvf.com/content/WACV2024/html/Gu_Complex_Organ_Mask_Guided_Radiology_Report_Generation_WACV_2024_paper.html) | [![GitHub](https://img.shields.io/github/stars/GaryGuTC/COMG_model?style=flat)](https://github.com/GaryGuTC/COMG_model) | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Gu_Complex_Organ_Mask_Guided_Radiology_Report_Generation_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.02329-b31b1b.svg)](http://arxiv.org/abs/2311.02329) | [![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/watch?v=KrzRBAUNWWs) |
| [Improved Topological Preservation in 3D Axon Segmentation and Centerline Detection using Geometric Assessment-Driven Topological Smoothing (GATS)](https://openaccess.thecvf.com/content/WACV2024/html/Shamsi_Improved_Topological_Preservation_in_3D_Axon_Segmentation_and_Centerline_Detection_WACV_2024_paper.html) | :heavy_minus_sign: | [![thecvf](https://img.shields.io/badge/pdf-thecvf-7395C5.svg)](https://openaccess.thecvf.com/content/WACV2024/papers/Shamsi_Improved_Topological_Preservation_in_3D_Axon_Segmentation_and_Centerline_Detection_WACV_2024_paper.pdf) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.04116-b31b1b.svg)](http://arxiv.org/abs/2311.04116) | :heavy_minus_sign: |
